\newif\ifcomments     %% include author discussion
\newif\ifanonymous    %% include author identities
\newif\ifextended     %% include appendix
\newif\ifsubmission   %% prepare the submitted version
\newif\ifpublic       %% version available for posting / final version

\commentstrue         %% toggle comments here
\extendedfalse
\anonymoustrue

\submissionfalse     %% at most one of these must be true (neither for draft version)
\publicfalse         %% but if you want to see comments, these should both be off


% If we are going to make a version public, i.e. on arXiv, we should
% make sure that there are no comments and our names are on it.
\ifpublic
\submissionfalse
\commentsfalse
\anonymousfalse
\fi

%% If we are submission, make sure there are no comments and our names
%% are NOT on it.
\ifsubmission
\publicfalse
\commentsfalse
\anonymoustrue
\fi


%%
%% This is file `sample-acmsmall.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `acmsmall')
%%
%% IMPORTANT NOTICE:
%%
%% For the copyright see the source file.
%%
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-acmsmall.tex.
%%
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%%
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[acmsmall,screen=true,
\ifpublic review=false\else,review=true\fi
  ,anonymous=\ifanonymous true\else false\fi]{acmart}
\usepackage{ottalt}
\usepackage{minted}
\usepackage{xspace}
\usepackage{tcolorbox}
\usepackage[para]{footmisc}
\definecolor{lightgray}{gray}{0.85}
\newcommand{\dotv}[2]{\href{#1}{\texttt{#1}}{\texttt{:#2}}}
\newcommand{\lang}{$\lambda^H$\xspace}
\inputott{rules}
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

\usepackage{draft}

\ifcomments
\newnote{scw}{blue} % Stephanie Weirich
\newnote{yl}{purple} % Yiyun Liu
\else
\newcommand{\scw}[1]{}
\newcommand{\yl}[1]{}
\fi


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
\citestyle{acmauthoryear}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Short and Mechanized Logical Relation for Dependent Type Theory}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Yiyun Liu}
\orcid{0009-0006-8717-2498}
\affiliation{
  \institution{University of Pennsylvania}
  \city{Philadelphia}
  \country{USA}
}
\email{liuyiyun@seas.upenn.edu}

\author{Stephanie Weirich}
\orcid{0000-0002-6756-9168}
\affiliation{
  \institution{University of Pennsylvania}
  \city{Philadelphia}
  \country{USA}
}
\email{sweirich@seas.upenn.edu}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
% \renewcommand{\shortauthors}{Trovato et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
Proof by logical relation is a powerful technique that has been used
to derive metatheoretic properties of type systems, such as
consistency and parametricity. While there exists a
plethora of introductory materials about logical relation in the
context of simply typed or polymorphic lambda calculus, a streamlined
presentation of proof by logical relation for a dependently language
is lacking. In this paper, I present a short
consistency proof for a dependently typed language that contains a
rich set of features, including a full cumulative universe
hierarchy, booleans, and an intensional identity type. We have
fully mechanized the consistency proof using the Coq proof assistant
in under 1000 lines of code.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Logical Relation, Dependent Types, Logical Consistency, Coq}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
In this paper, we present a \emph{short}, \emph{mechanized} proof of logical
consistency for \lang{}, a Martin-LÃ¶f style dependent type theory with large
eliminations, a full predicative universe hierarchy, an intensional identity
type and a boolean base type, both of which are equipped with dependent
elimination forms.

Our goal with this work is to demonstrate how the proof technique of
\emph{logical relations} can be applied in dependently-typed setting.
Tutorial material on this topic~\cite{lr-tutorials} is primarily focussed on
languages with simple or polymorphic types. In that context, logical relations
can be define as simple recursive functions over the structure of types, or
(in the case of recursive types) defined over the evaluation steps of the
computation.

Neither of these techniques make sense for predicative dependent type theory,
so a young researcher might be excused for thinking that logical
relations-based arguments are not available.  \scw{Well, actually, we did use
  a step-indexed relation for Trellys\ldots} But this is not the case. Recent
authors have developed tour-de-force mechanizations for the metatheory of
modern proof
assistants~\citep{nbeincoq,decagda,martin-lof-a-la-coq,anand2014towards}, and
have used logical-relations-based reasoning as part of their
arguments. However, at the same time, these definitions have been overshadowed
by their magnitude of the surrounding developments. Because these proofs show
diverse results about real systems and algorithms, these developments range in
size from 20,000 to 400,000 lines of code, and the techniques are not
accessible to a casual reader.

Our proof, designed to capture the essence of this proof technique in this
setting, requires less than 1000 lines of code. We have achieved this
significant reduction through a number of means: the careful selection of the
features that we include in the object type type system and the results that
we prove about it, in addition to the judicious use of automation.  Our
language is small, but includes enough to be illustrative. For example, we
eschew inductive datatypes or W-types, the but we do include propositionality
equality and booleans in order to capture the challenges presented by indexed
types and dependent pattern matching. We do not show the decidability of type
checking, nor do we develop a PER semantics, but we do demonstrate how our
consistency proof can be extended (at a moderate cost of 500 lines of code) to
show the existence of $\beta\eta$-normal form for well-typed open \emph{and}
closed terms. We include a full predicative universe hiercharchy and
type-level computation, to demonstrate the logical strength of the
approach. \scw{Say that we don't have impredicativity, but neither does anyone
  else?}
%%
%% SCW: save specific comparisons with other systems for later
%%
% The big difference in the size of the developments does not
% necessarily imply that our proof technique leads to a more concise
% proof due to the differing expressiveness of the languages and the
% different metatheoretic results being established. For
% example, \citet{anand2014towards} mechanizes the metatheory of
% Nuprl~\citep{constable1986implementing}, which, on top of all the
% features that \lang{} supports, includes W-types and partial types and
% requires a PER semantics to model its extensional typed
% equality. The object language from \citet{decagda} does not support
% identity types and only has one predicative universe, but additionally
% supports $\Sigma$ types. However, for a researcher who wishes to learn
% the underlying techniques for mechanized logical relation for
% dependent type theory, a small development like ours is much easier to
% navigate and understand. Furthermore, we show how our simple
% consistency proof can be easily extended to show the existence of
% $\beta\eta$-normal form for well-typed open \emph{and} closed terms,
% giving us a metatheoretic result almost as strong as the one from
% \citet{decagda} at the moderate cost of around 500 lines of extra code.


The result of our work is a development that an interested researcher can
navigate and understand. We accompany this mechanized proof with an informal
description, presented here using set theory notation and terminology so that
the material is accessible to readers with general mathematical background,
That said, our explanations do not stray too far away from our proof scripts.
We label each lemma directly to their counterpart in the proof script,
anticipating that readers may wish to reference and validate our formalism.
Our typeset representation are purposefully made to directly follow our
mechanical proofs, while avoiding, as much as possible, the introduction 
of artifacts that are specific to certain theorem prover.

Not only does this connection aid readers that wish to, like us, adopt proof
assistants for their day-to-day use. We also find that this precision is
important for conveying the proof techique itself. Unlike properties that are
derivable through syntactic means, proofs by logical relation make demands on
the strength of the logic in which they are expressed. An informal proof that
attempts to be agnostic or ambiguous about the underlying
metatheory % may struggle to even
% convey the validity of their definition and
requires substantial
effort from the reader to even understand whether it is theoretically
possible to encode such proofs in a given ambient logic, such as those found 
in modern proof assistants.

% The close correspondence between a typeset proof and a mechanized
% proof comes at the potential risk that the artifacts specific to
% theorem provers may become visible in the presented proof.
%However, for proofs by logical relation for
%dependent types, we find our approach advantageous for a few reasons.
Furthermore, while a proof assistant may reject perfectly valid definitions,
it helps us keep our definition precise and unambiguous. A precise definition
is crucial as the reasoning principles we are allowed to use is directly tied
to the definition, which is sometimes obscured by concise notations that
diverge too far from a formal proof.

Finally, our approach does not result in a verbose proof on paper, thanks to
the already short mechanization. While we do make conservative simplifications
to our typeset proof, such as avoiding the clunky syntax for well-founded
recursion in Coq, we keep the overall structure of our typeset proofs
consistent with our mechanization.

In Section~\ref{sec:spec}, we introduce \lang{}, the object language
of interest, and establish some elementary properties about parallel
reduction, which will be used as the equational theory of our language
and play a central role in defining our logical relation. The design
of \lang{} is reminiscent of Martin-LÃ¶f style predicatvie type
systems. The untyped conversion rule of \lang{} is inspired by Pure
Type Systems~\citet{barendregt1991introduction}, though we discuss how
our proof can be easily adjusted for systems with typed judgmental
equality.  We design \lang{} to incorporate some of the most common
features of dependent type theory, including an intensional identity
type, a boolean type, large elimination, dependent elimination, and a
full universe hierarchy. We believe a good coverage of features will
make our proof applicable to a broad range of type systems.

In Section~\ref{sec:logreldep}, we formulate the consistency property
and motivate why proof by logical relation is needed to derive it.
We define our logical relation as an inductively defined relation. We first
show that the logical relation respects evaluation (referred to as the
irrelevance property in \citet{martin-lof-a-la-coq}), then proceed to
prove that the logical relation is a partial function; that is, each
type can have at most one unique interpretation.

In Section~\ref{sec:logrelproof}, we give the definition of semantic
typing in terms of our logical relation so we can state and prove the
fundamental theorem, which states that syntactic typing implies
semantic typing, from which consistency follows as a corollary.

In Section~\ref{sec:extension}, we extend our logical relation to
prove the stronger property that every well-typed term has a
$\beta\eta$-normal form. After laying the foundation for handling
type-level computation in Section~\ref{sec:logreldep}, the extension
to include open terms in the logical relation requries mechanical
changes that directly mirrors the same extension for a simply typed
language. We use this extension to demonstrate the idea that once we
have established the base technique for proof by logical relation for
dependent types, we can factor out the complexities of an extension
the are not specifically related to dependent types; such an
extension, if desired, may be studied in the context of a simply typed
language and later ported into a dependently typed setting. We believe
it is possible to extend our logical relation to a Kripke-style and
relational model in a similar fashion.

In Section~\ref{sec:logrelmech}, we discuss the details about our
mechanization, including our use of existing libraries such as
Autosubst 2~\citep{autosubst2} for handling bindings and
CoqHammer~\citep{czajka2018hammer} for general-purpose automation.

In Section~\ref{sec:relatedwork}, we discuss how our proof relates to
existing proofs by logical relations and other proof techniques for
proving consistency and normalization.

We hope our success at creating a short and mechanized proof for a
relatively feature-complete language will encourage future researchers
to leverage the tool of logical relation more often in mechanized
proofs for dependent types.
% % For
% % example, \citet{geuvers1994short} requires impredicativity to encode
% % Calculus of Constructions, an impredicative dependent type theory, but
% % also relies on the classification property to define the logical
% % relation over well-formed types and kinds. Their simple
% % presentation of the logical relation as an inductively defined
% % function over types, reminiscent of logical relations for simply typed
% % languages,








% However, we make the
% typeset definitions as close as possible to our mechanization so the
% definitions and the proofs can be easily encoded in a proof
% assistant.
% We find the close correspondence
% between our typeset presentation and the Coq development advantageous
% for a couple of reasons. First, compared to other proof techniques,
% such as the use of preservation and progress to derive syntactic
% soundness, defining a logical relation for a dependently typed
% language is demanding on the strength of the metatheory.



% % Depending on its application, we care about certain metatheoretic
% % properties about a type system. As a programming language, we may care
% % about type soundness, which states that a well-typed never gets stuck
% % during evaluation.
% When a dependently type system is used as a program logic where terms
% encode proofs, we want our type system to be logically consistent,
% meaning that the empty type is not inhabited.

% The consistency proofs of various dependently typed systems, including Martin-Lof's
% type theory and the Calculus of Constructions, have long been
% available in the literature. In particular, recent works such as \citet{nbeincoq},
% \citet{decagda}, and \citet{martin-lof-a-la-coq} mechanize the
% correctness of the NbE algorithm, the decidability of type
% conversion, decidability of type
% checking respectively for dependently typed systems. From these
% properties, consistency can be derived as a corollary.

% The underlying technique of the forementioned
% works is proof by logical relation,
% which involves interpreting types as reducibility predicates,
% representing sets of terms satisfying certain properties with respect
% to the reduction relation. While the proof technique and the
% consistency result for dependent types are both well-established,
% there is a lack of rigorous and accessible material that shows
% how proof by logical relation can be applied to dependently typed
% systems.
% \scw{You are choosing to focus on mechanized logical relations proofs for
% dependent type theories, not consistency proofs for dependent type theories.
% Why? (And your title shuld match}


% Introductory materials about logical relations or standard textbooks such as
% \citet{skorstengaard2019introduction}, \citet{harper2016practical},
% and \citet{pierce2002types}
% talk about logical relations for simply or polymorphically typed
% languages, proving results such as termination for closed terms and parametricity.
% \scw{Are there some OPLSS notes from Amal Ahmed to also cite? Other modern textbooks?
% Does Aspinall and Hofmann's chapter of ATTAPL include a logical
% relation?}
% \yl{skorstengaard is from the OPLSS notes. Cited ATTAPL}
% \yl{Don't have a copy of }
% \scw{Seems like you should also mention POPLmark reloaded somehere too?}
% \citet{pierce2004advanced}, \citet{harperkripke}, and \citet{abel2019poplmark} show how
% a Kripke-style logical relation can be used to include scoping
% information in the logical relation and
% derive properties such as the existence of normal form or strong
% normalization for open and closed terms in simply typed languages.
% Overall, the introductory texts about logical relations
% cover systems and properties with varying degrees of complexity, from
% simply typed to polymorphicly typed, logical predicate to logical
% equivalence, closed terms to open terms.

% The glaring gap here is the
% lack of fully dependently typed systems where computations may appear
% at the type-level. It is far from obvious why proof by
% logical relation is even applicable to dependent types, since the type
% may very well-be a computation that is yet to be evaluated.
% While it is assuring that proof by logical relations for dependent
% types is available in mechanized forms, % the key to address the
% % complexities of dependent types is obscured in
% \citet{nbeincoq,decagda,martin-lof-a-la-coq} all involve relational,
% Kripke-style models that obscure the technique for addressing
% type-level computation. The added complexivity is evident
% from the size of their code base. All three developments involve 20
% thousand to 30 thousand lines of Coq or Agda code.

% The goal of this paper is to give a tutorial on proof by logical relation for
% dependent types in a simple and digestable format. \scw{This sentence should come as
% early as possible.} Dependently typed systems comes in many flavors and
% vary greatly in their expressiveness.
% In Section~\ref{sec:spec}, we introduce \lang{}, a dependently typed
% language that is small but relatively complete in features \scw{list these features explicitly:
% large eliminations, indexed types, others? \ldots} related to
% dependently types, including large elimination, a full universe
% hierarchy, an intensional identity type and a boolean base type, both
% of which are equipped with dependent elimination forms (e.g. J eliminator
% for the identity type). In particular, the inclusion of identity
% types, which is absent from \citet{decagda}, \citet{nbeincoq},
% helps demonstrate how indexed types are handled when defining the
% logical relation.

% % We choose boolean
% % types over natural numbers as our base type for simplicity, but include an
% % intensional identity type in our type system to show how indexed
% % types are treated in a logical relational proof. \scw{Talk about
% % identity type first.} Unlike
% % \citet{nbeincoq,decagda,martin-lof-a-la-coq} but similar to
% % \citet{anand2014towards}, we include an infinite hierarchy of
% % universes to not only support type-level computations, but also avoid
% % the unnecessary code duplication pointed out by \citet{nbeincoq} when
% % big and small types are treated non-uniformly.

% In Section~\ref{sec:logrelproof}, we use the standard technique that
% is commonly seen in ...

% Our consistency proof is short and fully mechanized. The proof scripts
% involve less than 1000 lines of manually written Coq code. In fact, what we find
% encouraging is that among the 1000
% lines of Coq code, 400 lines are related to the specification of the
% type system, semantics, and properties related to untyped lambda
% terms. The semantic type soundness proof through logical relation
% takes almost the same amount of code as our syntactic type soundness
% proof!
% Thanks to the conciseness of
% the proof, we are able to present it in detail in
% Sections~\ref{sec:logreldep} and \ref{sec:logrelproof}. Moreover, the
% structure of our mechanization closely corresponds to the proof we
% present in the text, enabling us to label at the footnote each lemma
% directly to their counterpart in the proof script for the readers to
% reference and validate.

% The technique we use is most similar to the one from \citet{nbeincoq},
% which leverages impredicativity to define the logical
% relation as a partial function.
% Rather than framing impredicativity as a
% mechanism for encoding induction
% recursion~\citep{induction-recursion-dybjer}, a scheme in which
% semantic models (including logical relations) for dependent types can
% be defined, we opt for a direct explanation through the informal
% language of sets, where impredicativity manifests in the form of
% second-order logical formulas and thus more intuitive to grasp
% for readers with a general mathematical background.

% A naive attempt at proving consistency through induction over the
% typing derivation would fail since the inductive hypothesis is not
% strong enough to derive the consistency result. Instead, one typically
% relies on the technique referred to as proof by logical relation to
% interpret types as reducibility predicates to strengthen the inductive
% hypothesis.




% This paper is specifically
% about establishing logical consistency for a fully dependently typed
% system with an infinite universe hierarchy and support for large
% elimination .
% The type system, presented in Section~\ref{sec:spec}, is
% most similar to Martin-Lof's predicate type theory with the minor
% difference that type conversion is based on untyped equality.


% Rather,
% our goal is to present the proof in a form that is digestable by a
% working type theorist and can be more readily mechanized in a proof
% assistant. Compared to existing efforts at mechanizing logical
% consistency or stronger properties such as existence of normal
% form~\citep{nbeincoq},
% decidable type checking~\citep{decagda}, our work is minimal since it requires very
% little scaffolding and therefore results in an extremely succinct
% proof of under 1000 lines of manually written Coq code for a dependent
% type theory that is reasonably complete in its features.

% The key technique that underlies our consistency proof is proof by
% logical relation. In
% Section~\ref{sec:spec}, we present the dependent type theory of
% interest. In Section~\ref{sec:logreldep}, we give the definition
% of the logical relation for the dependent type theory. Rather than
% presenting the logical relation as an inductive-recursive definition,
% we use the more elementary concept of a partial function to capture
% the interpretation of types. The alternative representation requires us
% to show that the set of equations indeed defines a partial function;
% that is, for each input, there should always be a unique
% output.
% From the interpretation function, we can define the semantic
% typing judgment for the set of lambda terms.
% In Section~\ref{sec:logrelproof}, we prove the fundamental theorem,
% which states that syntactic typing implies semantic typing. Once the
% fundamental theorem is established, logical consistency follows as a
% trivial corollary. In Section~\ref{sec:logrelmech}, we point out the
% specifics related to the Coq mechanization of the proof described in earlier
% section.
% Finally, in Section~\ref{sec:relatedwork}, we give a short survey of
% existing literature related to logical consistency about dependent
% type theory.

\scw{The end of this section needs to include an explicit summar of the
contributions of the paper. }

\section{Specification of a Dependent Type Theory}
\label{sec:spec}

\begin{figure}[h]
\[
\begin{array}{lcll}
\mathit{Natural\ numbers}\\
[[i]],[[j]],[[n]] & \in &  [[SNat]] &  \\ \\

\mathit{Contexts}\\
[[G]]       & ::= & [[empty]]\ |\ [[G ++ A]] &  \\ \\
\mathit{Terms}\\
[[a]],[[b]],[[t]],[[p]],[[A]],[[B]] & ::= & [[Set i]]\ |\ [[var n]]\  |\ [[Void]]
                  & \mbox{universes, variables, empty type} \\
            & |   & [[Pi A B]]\ |\ [[\ A a]]\ |\ [[a b]]
                  & \mbox{function types, abstractions, applications} \\
            & |   & [[a ~ b : A ]]\ |\  [[refl]]\ |\ [[J t a b p]]
                  & \mbox{equality types, reflexivity proof, J eliminator} \\
            & |   & [[Bool]]\ |\  [[true]]\ |\  [[false]]\ % |\  [[if a b0 b1]]
                  & \mbox{boolean type, true, false} \\
            & |   & [[if a b0 b1]]
                  & \mbox{if} \\ \\
% \mathit{Renaming}\\
% [[xi]] & \in & [[SNat -> SNat]] & \\ \\
\mathit{Substitution}\\
[[rho]] & \in & [[SNat -> STm]] &
\end{array}
\]
  \caption{Syntax of \lang \scw{Where does the name come from?}}
  \label{fig:syntax}
\end{figure}

% \begin{figure}[h]
%     \[
%       \begin{array}{lll}
%         \mathit{Curried\ Addition} \\
%         add(n) & := & m \mapsto n + m \\ \\
%         \mathit{Extension ([[xi]])} \\
%         [[(xi .: j) 0]]  & := & 0 \\
%         [[(xi .: j) Suc i]]  & := & [[xi j]] \\ \\

%         \mathit{Extension ([[rho]])} \\
%         [[(rho .: a) 0]]  & := & [[a]] \\
%         [[(rho .: a) Suc i]]  & := & [[rho i]] \\ \\

%         \mathit{Up ([[xi]])} \\
%         [[up xi]] & := & (add(1) \circ [[xi]]) , 0 \\ \\

%         \mathit{Renaming} \\
%         [[var i {xi}]] & := & [[xi i]] \\
%         [[(Set i) {xi}]] & := & [[Set i]] \\
%         [[Void {xi}]] & := & [[Void]]\\
%         [[(Pi A B) {xi}]] & := & [[Pi A{xi} B{up xi}]] \\
%         [[(\ A a) {xi}]] & := & [[\ A {xi} (#a {up xi}#)]] \\
%         [[(a b) {xi}]] & := & [[a {xi} (# b {xi} #)]] \\
%         [[Bool {xi}]] & := & [[Bool]] \\
%         [[true {xi}]] & := & [[true]] \\
%         [[false {xi}]] & := & [[false]] \\
%         [[(if a b0 b1) {xi}]] & := & [[if a{xi} b0{xi} b1{xi}]] \\
%         [[(a ~ b : A) {xi}]] & := & [[ a{xi} ~ b{xi} : A{xi}]] \\
%         [[refl {xi}]] & := & [[refl]] \\
%         [[(J t a b p ) {xi}]] & := & [[J t {xi} a {xi} b {xi} p{xi}]] \\ \\

%         \mathit{Lookup} \\
%         [[(G ++ A) 0]] & := &  [[A]] \\
%         [[(G ++ A) Suc i]] & := & [[G i]] \\ \\

%         \mathit{Drop} \\
%         [[drop 0 G]] & := & [[G]] \\
%         [[drop Suc i (#G ++ A#)]] & := & [[drop i G]] \\ \\
%       \end{array}
%     \]
%   \caption{Auxiliary Functions over Syntax}
%   \label{fig:auxdef}
% \end{figure}


In this section, we present the dynamics and statics of the
dependent type theory whose logical consistency will be proven in
Section~\ref{sec:logrelproof}. For concision, we refer to this system
as \lang.

The syntax of \lang can be found in Figure~\ref{fig:syntax}.
\scw{Why so many metavariables for terms? Do you need $c$, $p$ and $t$?}
We use
the unscoped de Bruijn representation for both our Coq development and
the informal presentation in our paper since it is more amenable to
automation (Section~\ref{sec:automation}) and leaves no ambiguity
about variable freeness conditions.

 \scw{Give an overview of the figure}
\scw{Define a convention that separates your use of natural numbers. Sometimes they
are universe levels and sometimes they are de Bruijn indices. Better to have separate
metavariables for each. (And it is possible to generalize universe levels to structures other than natural numbers. Ask Jonathan.}
As a dependent type theory, terms and types are collapsed into the same
syntactic category. The type $[[Set i]]$ represent universe
types and $[[var n]]$ represent de Bruijn variables. While
$[[i]],[[j]],$ and $[[n]]$ are all metavariables representing natural
numbers, we always use $[[n]]$ to represent term variables that
participate in substitution and $[[i]],[[j]]$ to represent universe levels.
Dependent functions take the form $[[Pi A B]]$ and
we use the notation $[[A -> B]]$ when the output type $[[B]]$ is not
dependent on the input variable.
Finally, we include in \lang{} the intensional identity type $[[a ~ b : A]]$ whose
proofs can be eliminated by the J-eliminator $[[J t a b p]]$, where
$[[p]]$ is an equality proof between $[[a]]$ and $[[b]]$, and $[[t]]$
is the term whose type is to be casted.
\scw{Example of what you can use identity types for? Or an example of
a program that uses J?}

% We find de Bruijn
% representation advantageous for specification since it leaves very
% little ambiguity about the variable freeness side
% conditions, making our proof more easily reproducible. Furthermore, as we discuss in
% Section~\ref{sec:automation}, de Bruijn representation is much more
% amenable to automated reasoning in proof assistants.

\scw{Need to explain the notations in the text. What are these operations?
What do readers need to understand about them? Help me understand the figure}
\scw{As this is a tutorial paper, you'll need to explain more about how de Bruijn
indices work.}
% We omit most of the
% definitions of renaming and substitution and only show the definition
% of a few representative cases of substitution.
\begin{figure}[ht]
  \begin{equation*}
    \begin{split}
      \begin{array}{lll}
        % \mathit{IdentityRen} \\
        % [[id i]] & := & [[i]] \\ \\
        \mathit{IdentityTm} \\
        [[idtm n]] & := & [[var n]] \\ \\
        % \mathit{ConsRen ([[xi .: n]])} \\
        % ([[xi .: n]])([[0]]) & := & [[n]] \\
        % ([[xi .: n]])([[Suc i]]) & := & [[xi i]] \\ \\
        \mathit{ConsSubst ([[rho .: a]])} \\
        ([[rho .: a]])([[0]]) & := & [[a]] \\
        ([[rho .: a]])([[Suc n]]) & := & [[rho n]] \\ \\
        \mathit{Curried\ Add} \\
        [[up n m]] & := & \ottkw{v}_{[[n]] + [[m]]}
      \end{array}
    \end{split}
    \qquad \qquad
    \begin{split}
      \begin{array}{lll}
        % \mathit{UpRen} \\
        % [[( up xi ) 0]] & := & [[0]] \\
        % [[( up xi ) Suc i]] & := & [[ Suc ren xi i ]] \\ \\
        % \mathit{Renaming ([[a < xi >]])} \\
        % [[(Pi A B) < xi >]] & := & [[Pi A < xi > B < up xi >]] \\
        % [[(a b) < xi >]] & := & [[a < xi > (# b < xi > #)]] \\
        % \ldots \\ \\
        \mathit{Lifting} \\
        [[( up rho ) 0]] & := & [[var 0]] \\
        [[( up rho ) Suc n]] & := & [[ rho n < up 1 > ]] \\ \\
        \mathit{Substitution ([[ a { rho }  ]])} \\
        [[var n { rho }  ]] & := &  [[rho n]] \\
        [[(Pi A B) { rho }]] & := & [[Pi A { rho } B { up rho }]] \\
        [[(a b) { rho }]] & := & [[a { rho } (# b { rho } #)]] \\
        [[(\ a) { rho }]] & := & [[\ (a { up rho })]] \\
        \ldots
      \end{array}
    \end{split}
  \end{equation*}
  \caption{Auxiliary Functions over Syntax}
  \label{fig:auxdef}
\end{figure}


% Without providing
% the full definition of the renaming and substitution functions, it is
% impossible to tell the binding structure from the syntax
% alone. Therefore, we annotate the syntax in Figure~\ref{fig:syntax}
% with the de Bruijn depth of each term, though we note that the
% syntax we work with is unscoped and the choice does matter when
% we extend our logical relation to open terms in Section~\ref{sec:extension}.

% Figure~\ref{fig:auxdef} shows the auxiliary definitions over the term
% syntax, including renaming, substitution, and operations over
% the typing context or substitution.

The \lang language is expressive enough to support large
eliminations, the ability to compute a type using a term as input. For
example, the function $[[\ Bool if var 0 Bool Bool -> Bool]]$ returns
either $[[Bool]]$ or $[[Bool -> Bool]]$ depending on whether the input
is $[[true]]$ or $[[false]]$.

We adapt from \citet{autosubst2} the notations for simultaneous
renaming, substitution, and other auxiliary definitions used in
our paper, summarized in Figure~\ref{fig:auxdef}. We need those
definitions to specify the reduction relation and the typing relation
for \lang{}. The metavariable $[[rho]]$ represents substitutions,
mappings from de Bruijn indices to terms.
One example of a substitution is
the function $\ottkw{id}_{tm}$, which takes a de Bruijn index directly
injects it as a term variable. The $\uparrow^{[[n]]}$ operator is
more general and adds $[[n]]$ to the index before injecting it as a
term. The $[[(rho .: a)]]$ operation allows us to extend a substitution
$[[rho]]$ with an extra element $[[a]]$; the extended substitution maps the variable
$[[var 0]]$ to $[[a]]$ and variables $[[var Suc i]]$ to $[[rho i]]$.

The substitution operator, which takes the form $[[a {rho}]]$,
traverses the syntax of $[[a]]$ and replaces each variable $[[var i]]$
with the term $[[rho i]]$. When traversing under binders (e.g. in the
$[[(\ a) { rho }]]$ case), the $\Uparrow$ operator prevents $[[var
0]]$, the bound variable, from being replaced by
$[[rho]]$. From the definition of $[[up rho]]$, we see that it keeps
$[[var 0]]$ unchanged during substitution and replaces each $[[var
Suc i]]$ with $[[rho i {up 1}]]$. The extra shifting with $[[up 1]]$
is required so the variables in terms from the codomain of $[[rho]]$ skip over
the newly introduced binder to refer to the correct binding
location. The substitution operator is referred to as simultaneous
substitution as it substitutes all variables at once. It is possible
to recover single substitution by composing the extension operator and
the identity substitution: $[[a { b }]] := [[a { idtm .: b }]]$.

\begin{figure}[h]
\begin{minipage}{0.9\textwidth}
\drules[P]{$[[a => b]]$}{Parallel Reduction}{Var, Set, Void, Pi, Abs, App, AppAbs, True, False, If, IfTrue, IfFalse,
  Bool, Eq, Refl, J, JRefl}
\drules[PS]{$[[a =>+ b]]$}{Transitive Closure of Parallel Reduction}{Refl, Step}
\drules[C]{$[[a <=> b]]$}{Coherence}{Intro}
\end{minipage}
\caption{Parallel reduction and coherence}
\label{fig:par}
\end{figure}

\scw{motivate parallel reduction. Why are you telling us this now. Is this
  an explanation of definitional equality and its properties?}
Before we specify the typing rules, we need to first specify its
untyped equational theory. We choose to represent the untyped
equational theory in an algorithmic style using the notion of parallel
reduction, defined in Figure~\ref{fig:par}. Parallel reduction takes
the form $[[a => b]]$ and we denote its transitive as $[[a =>+
b]]$. We say that two terms $[[a0]]$ and $[[a1]]$ are convertible,
denoted by the notation $[[a0 <=> a1]]$, if there exists some term
$[[b]]$ such that $[[a0 =>+ b]]$ and $[[a1 =>+ b]]$. The symmetric
notation of convertibility suggests that it is an equivalence
relation. We sketch out the sequence of lemmas required to derive this
property below and omit the details. Our technique for proving the
properties about parallel reduction is based on
\citet{takahashi-parallel-reduction}. A modern exposition of the
same technique can be found in \citet{plfa22.08}.
\begin{lemma}[Par Refl\footnote{\dotv{join.v}{Par\_refl}}]
  \label{lemma:parrefl}
  For all terms $[[a]]$, $[[a => a]]$.
\end{lemma}
\begin{lemma}[Par cong\footnote{\dotv{join.v}{par\_cong}}]
  \label{lemma:parcong}
  If $[[a0 => a1]]$ and $[[b0 => b1]]$, then $[[a0 { b0 } => a1 { b1 }]]$.
\end{lemma}
\begin{corollary}[Par subst\footnote{\dotv{join.v}{par\_subst}}]
  \label{lemma:parsubst}
  If $[[a0 => a1]]$, then $[[a0 {b} => a1 {b}]]$ for arbitrary $[[b]]$.
\end{corollary}
\begin{lemma}[Par diamond\footnote{\dotv{join.v}{par\_confluent}}]
  \label{lemma:pardiamond}
  If $[[a => b0]]$ and $[[a => b1]]$, then there exists some term
  $[[c]]$ such that $[[b0 => c]]$ and $[[b1 => c]]$.
\end{lemma}
\begin{lemma}[Coherence refl\footnote{\dotv{join.v}{Coherent\_reflexive}}]
  \label{lemma:coherencerefl}
  For all terms $[[a]]$, $[[a <=> a]]$.
\end{lemma}
\begin{lemma}[Coherence sym\footnote{\dotv{join.v}{Coherent\_symmetric}}]
  \label{lemma:coherencesym}
  If $[[a <=> b]]$, then $[[b <=> a]]$.
\end{lemma}
\begin{lemma}[Coherence trans\footnote{\dotv{join.v}{Coherent\_transitive}}]
  \label{lemma:coherencetrans}
  If $[[a0 <=> a1]]$ and $[[a1 <=> a2]]$, then $[[a0 <=> a2]]$.
\end{lemma}
From Lemma~\ref{lemma:coherencerefl}, \ref{lemma:coherencesym}, and
\ref{lemma:coherencetrans}, we conclude that coherence is indeed an
equivalence relation. It is then trivial to show that all untyped
$\beta$-equivalence rules are admissible, though we omit this proof
from our mechanization and will from now on focus on parallel
reduction since the diamond property (Lemma~\ref{lemma:pardiamond})
makes it easier to work with. A detailed argument of the equivalence
between $[[a <=> b]]$ and untyped $\beta$-equivalence can be found in
\citet{barendregt:lambda-calculi-with-types} and
\citet{takahashi-parallel-reduction}.

\begin{figure}[h]
\begin{minipage}{0.9\textwidth}
\drules[Ctx]{$[[ |- G]]$}{Context Well-Formedness}{Empty, Cons}
\drules[T]{$[[G |-  a : A]]$}{Typing}{Var, Set, Pi, Abs, App, Conv,
  Refl, Eq, J, If, Bool, True, False, Void}
\end{minipage}
\caption{Syntactic typing for \lang}
\label{fig:typing}
\end{figure}
% Figure~\ref{fig:par} shows the definition of the parallel reduction
% relation, which takes the form $[[a => b]]$. We use $[[a =>+ b]]$ to
% represent its transitive and reflexive closure, which in turn allows us to define
% the coherence relation $[[a <=> b]]$.\scw{where is the terminology ``coherence''
% from? I'm not familiar with it. Maybe you can replace it with ``definitional
% equivalence'' as that is how it is used in \lang?}
% We say that two terms $[[a]]$
% and $[[b]]$ are coherent if they can eventually reduce to some common
% term $[[c]]$ through parallel reduction. The symmetric notation of
% coherence suggests\scw{but you prove it below?} it is an equivalence relation.

% We sketch out some key properties about parallel reduction and
% coherence without giving their proofs. Our technique for establishing
% those results is based on

% \scw{cite barendregt?}
% \yl{resolved}

% TODO: remove the lengthy discussion below

% Now, we prove that coherence is indeed an equivalence relation.

% First, we show that coherence is reflexive through the following
% sequence of lemmas.


% Lemma~\ref{lemma:parrefl} can be proven by structural induction over
% the term $[[a]]$. Lemmas~\ref{lemma:parsrefl} and \ref{lemma:coherencerefl}
% immediately follow as corollaries of Lemma~\ref{lemma:parrefl}.

% The reflexivity of parallel reduction enables us to embed rules from
% call-by-name semantics into parallel reduction, as the following lemma
% shows.
% \begin{lemma}[Par AbsCbn\footnote{\dotv{join.v}{P\_AppAbs\_cbn}}] For all $[[A]], [[a]],$ and $[[b]]$,
%   \label{lemma:parabscbn}
%   $[[(\ A a) b => b {a}]]$
% \end{lemma}
% \begin{proof}
%   Immediate from Lemma~\ref{lemma:parrefl} and \rref{P-AppAbs}.
% \end{proof}

% Symmetry of coherence immediately falls from its definition.

% Before we can prove transitivity, we need to show that parallel
% reduction satisfies the diamond property.


% The congruence property (Lemma~\ref{lemma:parcong}) can be proven by
% structural induction over the derivation of $[[a0 => a1]]$.
% Likewise, Lemma~\ref{lemma:pardiamond} can be proven by structural induction
% over the derivation of $[[a => b0]]$. The \rref{P-AppAbs} case requires
% the use of Lemma~\ref{lemma:parcong}.

% From Lemma~\ref{lemma:parcong} and \ref{lemma:parrefl}, we recover the
% single substitution property as a simple corollary.


% A relation that satisfies the
% diamond property must also be confluent, meaning that its transitive
% and reflexive closure is confluent.
% \begin{lemma}[Par confluent\footnote{\dotv{join.v}{pars\_confluent}}]
%   \label{lemma:parconfluent}
%   If $[[a =>+ b0]]$ and $[[a =>+ b1]]$, then there exists some term
%   $[[c]]$ such that $[[b0 =>+ c]]$ and $[[b1 =>+ c]]$.
% \end{lemma}
% While $[[a =>+ b]]$ is defined as the transitive closure of $[[a => b]]$,
% it coincides with the transitive and reflexive closure of $[[a => b]]$ since $[[a => b]]$ is reflexive (Lemma~\ref{lemma:parrefl}).

% The transitivity of the coherence relation follows as a corollary of
% Lemma~\ref{lemma:parconfluent}.
% By the definition of coherence, there exists some term $[[b]]$ such that $[[a0 =>+ b0]]$,
% $[[a1 =>+ b0]]$ and some term $[[b1]]$ such that $[[a1 =>+ b1]]$ and
% $[[a2 =>+ b1]]$. By Lemma~\ref{lemma:parconfluent}, there exists some
% term $[[c]]$ such that $[[b0 =>+ c]]$ and $[[b1 =>+ c]]$. It sufficies
% to show that $[[a0 =>+ c]]$ and $[[a2 =>+ c]]$, both of which
% trivially hold since the transitive closure $[[a =>+ b]]$ is transitive.
% This concludes the proof that coherence is an equivalence relation.
% \begin{lemma}[Coherence Equivalence]
%   \label{lemma:coherenceequiv}
%   The relation $[[a <=> b]]$ satisfies reflexivity, symmetry, and
%   transitivity and therefore is an equivalence relation.
% \end{lemma}


Figure~\ref{fig:typing} gives the full typing rules for
\lang{}. The premises wrapped in \colorbox{lightgray}{gray} boxes can be shown to be
admissible syntactically, though some of them are required to
strengthen the inductive hypothesis of the fundamental theorem.
% \scw{Is the precondition for T-ABS really admissible? Isn't it required
% to ensure predicativity? Have you proved it? Have you proved regularity?}
% \yl{I proved regularity. \Rref{T-Abs} is admissible if cumulativity
%   was formulated correctly (which wasn't the case in the version
%   of the paper you read). I revised \rref{T-Univ} so the premise is
%   not admissible }
% \scw{Do you have a formation rule for identity types?}
% \yl{Added}

In \rref{T-Var}, $[[G n]]$ is the partial function defined
by the equations $[[ (G ++ A)  0 ]] := [[A]]$ and $[[ (G ++ A) Suc
n ]] := [[G n]]$.
The precondition $[[n < | G | ]]$, where $[[ | G |
]]$ represents the length of the context $[[G]]$, ensures that $[[G
n]]$ has a defined output. The type $[[G n]]$ needs to be shifted
by $[[Suc n]]$ since the types stored in the context $[[G]]$ are
scoped differently. In the typing judgment $[[G |- a : A]]$, we want
both $[[a]]$ and $[[A]]$ to have the same scope. However, the closer a
type is to the head of $[[G]]$, the smaller de Bruijn it has since
there is less variables in the context it can refer to (see \rref{Ctx-Cons}). Shifting $[[G
n]]$ by $[[Suc n]]$ weakens the type so it is scoped consistently with
the full context $[[G]]$ rather than a truncated version of $[[G]]$.

\Rref{T-Conv} uses the convertibility relation from earlier
as our equality judgment for type conversion. The use of an untyped
relation for type conversion is reminiscent of Barendregt's Pure Type
Systems~\citet{barendregt1991introduction} and makes our formulation different
from languages such as MLTT~\citep{Martin-Lof-1973}, where the judgmental equality
takes the form $\Gamma \vdash a \equiv b : A$, from which one can
usually derive  $[[G |- a : A]]$ and $[[G |- b : A]]$ after proving
subject reduction.

\citet{siles2012pure} shows the equivalence of Barendregt's
Pure Type System~\citep{barendregt1991introduction}, which employs
untyped equality, and its variant that uses typed judgmental
equality. This assures us that we do not lose much generality working
with a system with untyped conversion. We include a detailed
discussion in Section~\ref{sec:relatedwork} on how type-directed and
untyped equality affect the applicability of our technique.

% As a result, there is no loss of generality from

% It is trivial to embed a system with judgmental
% equality to a system with untyped equality by erasing typing
% information. As a result, it is easy to port our consistency result from our
% type system to a variant with typed judgmental equality
% as long as the typed system does not include $\eta$ laws
% that would require type annotations (e.g. the $\eta$-law for unit
% types).
% and we discuss in Section~\ref{sec:extension} how we can extend
% our proof to handle those rules.
\yl{Unresolved: is it ok to say our system's conversion rule is untyped like
Coq?}
% \scw{Maybe move more of this paragraph and the next to the discussion/related
%   work section, and add a forward pointer here.}
% \scw{Just say that like Coq, the definition of the system uses untyped
% equality}

% Working with a system with untyped equality has the huge benefit that
% the confluence result for untyped parallel reduction
% (Lemma~\ref{lemma:pardiamond}) is easily derivable without having to
% resort to the complex syntatic (resp. semantic) technique from
% \citet{siles2012pure} (resp. \citet{decagda}) to resolve
% the circularity of subject reduction and $\Pi$-injectivity.
% Section~\ref{sec:extension} explains how we
% generalize our technique to include $\eta$-law for functions and
% show the existence of normal form for well-typed (open and closed)
% terms, achieving a similar level of expressiveness of the type system
% and strength of metatheoretic property as \citet{decagda}.

% Finally, since our system has an infinite universe hierarchy, we can
% present the system Ã  la Russell by using the same judgment form
%$[[G |- a : A]]$ regardless of whether $[[a]]$ is a term or a type. There
% is no need to distinguish between big types and small types
% and duplicate our typing specification.
% \scw{Is there an advantage for Tarski universes even with infinite
% hierarchy? or no?}


% , the
% statement that $\Gamma \vdash [[Pi A0 B0]] \equiv [[Pi A1 B1]]$
% implies $\Gamma \vdash [[A0]] \equiv [[A1]]$ and
% $\Gamma, [[A0]]\vdash [[B0]] \equiv [[B1]]$.



% working with a system with untyped equality not only preserves the
% same level of generality,
% Of course,
% but also enables us to derive confluence
% (Lemma~\ref{lemma:parconfluent}) early on without having to use the
% intricate techniques from \citet{lemma:}







% TODO, where terms ... and ... are known to be
% well-typed. The equivalence of such systems and a system that uses
% untyped equality are explored in detail in ...

% Without fancy eta laws, it is easy to embed a typed language into an
% untyped language.


% We note that a more conventional presentation of
% \rref{T-Conv} would instead use full beta reduction as the base for
% the definition of coherence. However, since full beta reduction
% doesn't satisfy the diamond property, one typically needs parallel
% reduction as an auxilliary definition to derive the confluence of full
% beta reduction. Our formulation of \lang through parallel reduction
% is slightly more economical.

\section{Logical Relation}
% \scw{This section pre-supposes that we want to define a logical relation,
% but doesn't precisely state what we want to use it to prove, and why a logical
% relation is suitable. (And why the property you want to prove is difficult to
% show!) Should add more motivation here.}
Before we define our logical relation, we first formally specify the
consistency property that we want to prove.
\begin{theorem}[Logical Consistency]
  \label{theorem:consistency}
  The judgment $[[empty |- a : Void ]]$ is not derivable.
\end{theorem}
The property can be formulated in a simply typed language, where
$[[Void]]$ is similarly defined as a type that has no term. A related
property, referred to as the termination property (for closed terms),
is commonly used in introductory materials such as
\citet{skorstengaard2019introduction}, \citet{pierce2002types}, and
\citet{harpertait} to motivate the need for a logical relation.

A naive attempt to proving Theorem~\ref{theorem:consistency} by
induction on the derivation $[[empty |- a : Void]]$ would succeed at
almost all cases except for \rref{T-App}. In the application
case, we are given $[[empty |- b : Pi A B]]$ and $[[empty |- a : A]]$, and
the equality that $[[B {a} = Bool]]$. Our goal is to show that
$[[empty |- b a : Void]]$ is not possible. However, note that there is
nothing we know of $[[b]]$ or $[[a]]$ from the induction hypothesis
because neither $[[Pi A B]]$ nor $[[A]]$ is equal to $[[Bool]]$.
We have no way of deriving a contradiction from $[[empty |- b a :
Void]]$. The takeaway from this failed attempt is that, in order to
derive the consistency, we need to know something about types other
than $[[Void]]$. From a pragmatic point of view, proof by logical
relation can be seen as a sophisticated way of strengthening the
induction hypothesis. From the strengthened property, the fundamental
theorem, we will be able to derive consistency as a corollary.

The complexity of applying proof by logical relation to dependent types stem
from the fact that the logical relation is much harder to define. In
simply typed languages, the logical relation is defined as a recursive
function over the type $[[A]]$. In dependent types, the type
$[[A]]$ can take the form $[[(\ var 0) Bool]]$. To assign meaning to
this type, we need to first reduce it to $[[Bool]]$. However, we
cannot write a function that performs the reduction because we do not
know the termination of well-typed terms a priori. As a result, we
define the logical relation as an inductively defined relation,
reminiscent of how we specify the reduction graph of a partial
function; the functionality of the relation can later be recovered in Lemma~\ref{lemma:logreldeter}.

\label{sec:logreldep}
\begin{figure}[h]
\drules[I]{$[[Interp I i A S]]$}{Logical Relation}{Void, Bool, Eq, Pi, Set, Red}
\caption{Logical relation for \lang}
\label{fig:logrel}
\end{figure}
The logical relation for \lang{}, which takes the form $[[Interp I i A
S]]$, is defined as an inductively generated relation (Figure~\ref{fig:logrel}).
% The logical relation takes the form $[[Interp I i A S]]$.
Metavariables $[[A]]$ and $[[i]]$ stand for terms and natural
numbers respectively, as introduced earlier in
Figure~\ref{fig:syntax}.
\scw{Many introductory texts define the relation as a recursive function
over type structure, or step-indices. You use an inductive relation instead, why?}
\scw{Can we view this inductive relation as the graph of the partial function
that is defined recursively over types?}
\scw{What is this form extensible too? impredicative quantification? recursive
types? }
\scw{Is it worth observing here that this definition is not over sets of typed
terms. That it characterizes all terms that look like booleans (i.e. evaluate to
true or false) or all terms that look like proofs (i.e. evaluate to refl). The
fact that there is no connection between p and a and b in the I-Eq case is strange
looking. Need to explain.  }
The metavariables $[[I]]$ and $[[S]]$ are
sets with the following signatures.
\begin{equation*}
  \begin{split}
    [[I]] &\in [[ { j | j < i  } ->  PowerSet STm ]] \\
    [[S]] &\in [[PowerSet STm]]
  \end{split}
\end{equation*}
The notation $[[PowerSet STm]]$ denotes the powerset of the set of
\lang{} terms.
The function $[[I]]$ is a family of sets of terms indexed by
natural numbers strictly less than the parameter $[[i]]$, which
represents the current universe level.  In \rref{I-Set}, function
$[[I]]$ is used to define the meaning of
universes that are strictly smaller than the current level $[[i]]$. The
restriction $[[j < i]]$ in \rref{I-Set} is crucial for our system to
be predicative and we will explain the reason shortly.

To tie the knot and obtain an interpretation of all universe levels,
we define in Figure~\ref{fig:logrelrec} the final version of our interpretation judgment recursively
using the well-foundedness of $<$ relation on natural
numbers (recall that
the parameter $[[I]]$ of $[[Interp I i A S]]$ takes only natural
numbers strictly less than $[[i]]$ as its input).
The judgment $[[InterpR i A S]]$ now reads that the type $[[A]]$ is a
level-$[[i]]$ type \emph{semantically} inhabited by terms from the set
$[[S]]$.

\begin{figure}[h]
\begin{equation*}
    [[InterpR i A S]] := [[ Interp I i A S  ]], \text{where } [[I i]] := [[{A | exists S , InterpR i A S}]]
\end{equation*}
\caption{Logical relation for all universe levels}
\label{fig:logrelrec}
\end{figure}
The definition of in Figure~\ref{fig:logrelrec} explains how the $[[j
< i]]$ constraint in \rref{I-Set} makes our system predicative; the
interpretation of the $[[i]]_{th}$ universe is only dependent on
universes at strictly lower than $[[i]]$, which have been defined earlier.
Removing the ordering constraint would result in a
system where one can encode Girard's
paradox~\citep{girard-thesis}. Our proof would no longer work with the
restriction removed since the definition of $[[InterpR i A S]]$ would
not be well-founded when $[[Interp I i A S]]$ calls $[[I]]$ on
universe levels greater than or equal to $[[i]]$, which are yet to be defined.

By unfolding the definition in Figure~\ref{fig:logrelrec}, we
show that the same introduction rules for $[[Interp I i A S]]$ are
admissible for $[[InterpR i A S]]$, by
instantiating $[[I]]$ with $[[I i]] := [[{A | exists S , InterpR i A
  S}]]$, the same function $[[I]]$ used in the definition of $[[InterpR i A
S]]$. We give as example the following rules.
\begin{center}
\drule[]{IR-Void} \qquad \drule[]{IR-Set}
\end{center}

In most informal presentations, instead of defining the logical
relation in two steps as we have shown above, the rules for $[[InterpR
i A S]]$ are given directly, with the implicit understanding that the
relation is an inductive definition nested inside a recursive
function over the universe level $[[i]]$. We choose
the more explicit definition not only because it is directly definable
in existing proof assistants where inductive definitions must appear
at the top level, but also because it makes clear the induction
principle we are allowed to use when reasoning about $[[InterpR i A
S]]$.

% The paragraph below might be useful but I don't know how to phrase
% it well

% The most general format of the induction principle over
% $[[InterpR i A S]]$ is first by strong induction over the universe level $[[i]]$
% followed by structural induction over $[[Interp I i A S]]$. As
% examples, ... (\rref{I-Set} and \rref{I-Red}).

For the majority of the properties we are about to prove in this section, we
do not need any information about the parameterized function $[[I]]$.
Each property about $[[InterpR i A S]]$ follows as a corollary of
a property about $[[Interp I i A S]]$ with no or few assumptions imposed on
$[[I]]$. As a result, we usually state our lemmas in terms of
$[[Interp I i A S]]$ without duplicating them in terms of $[[InterpR i
A S]]$.

To derive consistency, it suffices to restrict $[[S]]$ to the set of
terms that reduce to closed terms. \Rref{I-Void, I-Bool} are
unsurprising; when considering only closed terms, the empty type
should not be inhabited and therefore corresponds to the empty set,
whereas the boolean type is semantically inhabited by terms that
evaluate to the boolean values $[[true]]$ or $[[false]]$. \Rref{I-Eq}
says that an equality type $[[a ~ b : A]]$ corresonds to the
set of terms that evaluate to $[[refl]]$ when $[[a <=> b]]$ holds and
otherwise corresponds to the empty set. Side conditions like $[[a <=>
b]]$ are typically required for indexed types, of which equality types
are an instance. \Rref{I-Par} enables us to reduce our types in order
to assign meanings. Recall the type expression $[[(\ var 0)
Bool]]$. \Rref{I-Par} says to know that
$[[Interp I i  (\ var 0) Bool S ]]$ for some $[[S]]$, it suffices to
show that $[[Interp I i Bool S]]$ since $[[(\var 0) Bool =>
Bool]]$. The derivation that $[[Interp I i (\ var 0) Bool { a | a =>+
  true \/ a =>+ false }]]$ therefore follows by composing \rref{I-Par}
and \rref{I-Bool}.


\Rref{I-Pi} is the most interesting. To explain what it means, we
need to perform a few steps of transformations to its precondition.
The precondition consists of a
mysterious relation $[[R]]$ over the set $[[S]]$, an interpretation
of the type $[[A]]$, and returns a subset of terms. $[[R]]$ is further
subject to the following two constraints:
\begin{itemize}
\item $[[forall a, (# exists S0  , ( a , S0 ) in R #)]]$
\item $[[forall a, forall S0, (# ( a , S0 ) in R implies Interp I i B { a } S0 #)]]$
\end{itemize}
The first condition allows us to induce a function $[[F in S ->
PowerSet STm]]$ such that $[[(a , F a) in R]]$. Then we can easily
show that $[[forall a, (# a in S implies Interp I i B { a } F a #)]]$.

For the other direction, given a function $[[F]]$ satisfying the
property $[[forall a, (# a in S implies Interp I i B { a } F a #) ]]$, it
is possible to go in the other direction and define a relation $[[R]]=[[
{ ( a , F a )  | a in S }]]$. It is easy to verify that $[[R]]$ satisfy
the the constraint required in the precondition of \rref{I-Pi}.

Furthermore, the skolemization process allows us to conclude the
following equivalence:
\[ \exists F, [[forall a, (# a in S implies Interp I i B { a } F a #)]] \iff [[forall a, (# a in S implies (# exists S0 , Interp I i B {a} S0 #) #)]]  \]
% Ignoring the content below the horizontal bar of
% the derivation, we claim the statements from the precondition are equivalent to
% the conjunction of the following statements:
% \begin{itemize}
% \item $[[Interp I i A S]]$
% \item $\forall [[a]], \text{ if }[[a in S]]\text{, then } \exists
%   [[S0]]\text{, } [[Interp I i B { a } S0 ]] $
% \end{itemize}
% In general, let $R$ be a binary relation over the sets $[[A]]$ and
% $[[B]]$, it easy to verify the following equivalence, which is used to
% justify the skolemization process~\citep{skolemization}.
% \scw{Is this true constructively? If not, is that ok?}
% \[\forall a \in A, \exists b \in B \text{ such that } (a,b) \in R
%   \iff \exists F \in A \rightarrow B \text, \forall a \in A, (a, F(a))
%   \in R\]
% The left-hand side is equivalent to the right-hand side, but has no
% mentioning of any functions.
The precondition of \rref{I-Pi} therefore can be formulated as the
following statements:
\begin{itemize}
\item $[[Interp I i A S]]$
\item $[[forall a, (# a in S implies (# exists S0 , Interp I i B {a} S0 #) #)]]$
\end{itemize}
From this alternative formulation, we can more easily tell what is
happening in \rref{I-Pi}: the
function type $[[Pi A B]]$ has an interpretation if its input
type $[[A]]$ can be
interpreted as some set $[[S]]$, and for all terms $[[a in S]]$, the
type $[[B {a}]]$, obtained by substituing $[[a]]$ into the output type
$[[B]]$, has some semantic interpretation.

If we look at $[[Interp I i Pi A B { b | forall a, forall S0, (# ( a , S0 ) in R implies b a in S0 #) }]]$, the conclusion of \rref{I-Pi}, we see why the
presentation with an explicit $[[R in S * PowerSet STm]]$ is
useful. We want to state the fact that $[[B {a}]]$ has a semantic
interpretation of some set $[[S0]]$, but we also want to refer to the
set $[[S0]]$ when we talk about the set that $[[Pi A B]]$ corresponds
to. With the relation $[[R]]$ in scope, we can refer to the
witness sets $[[S0]]$ such that $[[Interp I i B {a} S0]]$ for $[[a in S]]$.
With the alternative representation that is free of the relation $[[R]]$, we
might want to reformulate our logical relation in the following more
concise but equivalent form, whose admissibility follows directly from
\rref{I-Pi}.
\begin{center}
  \drule[]{I-PiAlt}
\end{center}
\begin{lemma}
  \label{lemma:piintroalt}
  \Rref{I-PiAlt} is admissible.
\end{lemma}
\begin{proof}
Immediate from \rref{I-Pi} with $[[R]]$ instantiated to the relation $[[{ (a
, S0 ) | a in S , Interp I i B { a } S0 }]]$.
\end{proof}

Unfortunately, \rref{I-PiAlt} not only violates the syntactic strict
positivity constraint required in proof assistants, but
is genuinely non-monotone when written as an endofunction over the
domain of relations.
Intuitively, the failure of monotonicity stems from the fact
that the witness picked in the precondition is not necessarily the
same witness being referred to in the post condition. While it might
be possible to restrict the domain with additional constraints such as
functionality and inversion properties, we opt for our current
formulation of \rref{I-Pi} so we immediately obtain a
well-defined inductive relation and a usable induction principle. The
slight disadvantage of \rref{I-Pi} is that we need to construct the
function $[[R]]$ each time we apply it, though this is mitigated by
the immediate admissibility of \rref{I-PiAlt}.

In the rest of the section, we prove four important facts about
our logical relation: irrelevance (Lemma~\ref{lemma:logrelcoherence}),
functionality (Lemma~\ref{lemma:logreldeter}), cumulativity
(Lemma~\ref{lemma:logrelcumulativity}), and the backward closure
property (Lemma~\ref{lemma:logrelNbackclos}).

First, we prove a family of simple properties, which we refer to as
inversion principles for our logical relation. Given $[[Interp I i A
S]]$ where $[[A]]$ is in some head form such as $[[Bool]]$ or $[[Pi A0
B0]]$, the inversion lemma allows us to say something about the set
$[[S]]$. Its proof is simple, but we sketch out the case for
functions to help readers confirm their understanding of \rref{I-Pi}.
\begin{lemma}[Inversion of the logical relation]
  \label{lemma:interpinv}\leavevmode
  \begin{enumerate}
  \item\footnote{\dotv{semtyping.v}{InterpExt\_Void\_inv}} If $[[Interp I i Void S]]$, then $[[S = emptyset]]$.
  \item\footnote{\dotv{semtyping.v}{InterpExt\_Bool\_inv}} If $[[Interp I i Bool S]]$, then $[[S = { a | a =>+ true \/ a =>+ false   }]]$.
  \item\footnote{\dotv{semtyping.v}{InterpExt\_Eq\_inv}} If $[[Interp I i a ~ b : A S]]$, then $[[S = { p | p =>+ refl , a <=> b  }]]$.
  \item\footnote{\dotv{semtyping.v}{InterpExt\_Fun\_inv}} If $[[Interp I i Pi A B S1]]$, then there exists $[[S]],[[R]]$ such that:
    \begin{itemize}
    \item $[[Interp I i A S ]]$
    \item $[[R in S * PowerSet STm]]$
    \item $[[forall a, (# a in S implies (# exists S0 , (a , S0) in R #) #)]]$
    \item $[[forall a, forall S0, (# ( a , S0 ) in R implies Interp I i B { a } S0 #)]]$
    \item $[[S1 = { b | forall a, forall S0, (# ( a , S0 ) in R implies b a in S0 #) }]]$
    \end{itemize}
  \item\footnote{\dotv{semtyping.v}{InterpExt\_Univ\_inv}} If $[[Interp I i Set j S]]$, then $[[j < i]]$ and $[[S = I j]]$.
  \end{enumerate}
\end{lemma}
\begin{proof}
  As mentioned earlier, we only show the inversion property for the
  function type.
  We start by inducting over the derivation of $[[Interp I i Pi A B S]]$. There
  are only two possible cases we need to consider.
  \begin{description}
  \item[\Rref{I-Pi}:] Immediate.
  \item[\Rref{I-Red}:] We are given that $[[Interp I i Pi A B S1]]$.
    We know that there exists some $[[A0]]$ and
    $[[B0]]$ such that $[[Pi A B => Pi A0 B0]]$ and $[[Interp I i Pi
    A0 B0 S1]]$. From the
    induction hypothesis, there exists $[[S]]$ and $[[R]]$ such that :
    \begin{itemize}
    \item $[[Interp I i A0 S ]]$
    \item $[[R in S * PowerSet STm]]$
    \item $[[forall a, (# a in S implies (# exists S0 , (a , S0) in R #) #)]]$
    \item $[[forall a, forall S0, (# ( a , S0 ) in R implies Interp I i B0 { a } S0 #)]]$
    \item $[[S1 = { b | forall a, forall S0, (# ( a , S0 ) in R implies b a in S0 #) }]]$
    \end{itemize}
    By inverting the derivation of $[[Pi A B => Pi A0 B0]]$, we derive $[[A => A0]]$ and
    $[[B => B0]]$. By Lemma~\ref{lemma:parsubst}, we have $[[B {a} => B0 {a} ]]$ for all
    $[[a]]$. As a result, by \rref{I-Red}, the same $[[S]]$ and
    $[[R]]$ additionally satisfies the following properties:
    \begin{itemize}
    \item $[[Interp I i A S ]]$
    \item $[[forall a, forall S0, (# ( a , S0 ) in R implies Interp I i B { a } S0 #)]]$
    \end{itemize}
    These properties are exactly what we need to finish the proof.
  \end{description}
\end{proof}

\Rref{I-Red} bakes into the logical relation the backward preservation
property. That is, given $[[Interp I i A S]]$, if $[[B =>+ A]]$, then
$[[Interp I i B S]]$ also holds. The following property shows that
preservation holds in the usual forward direction too.
\begin{lemma}[Preservation of the logical relation\footnote{\dotv{semtyping.v}{InterpExt\_preservation}}]
  \label{lemma:interppreservation}
  If $[[Interp I i A S]]$ and $[[A => B]]$, then $[[Interp I i B S]]$.
\end{lemma}
\begin{proof}
  We carry out the proof by induction over the derivation of $[[Interp
  I i A S]]$.

  The only interesting case is \Rref{I-Red}. Given that
  $[[A => B0]]$ and $[[Interp I i B0 S]]$, we need to show
  for all  $[[B]]$ such that $[[A => B1]]$, we have $[[Interp I i B1
  S]]$. By the diamond property of parallel reduction
  (Lemma~\ref{lemma:pardiamond}), there exists some term $[[B]]$ such
  that $[[B0 => B]]$ and $[[B1 => B]]$. By the induction hypothesis,
  we deduce $[[Interp I i B S]]$ from $[[B0 => B]]$ and $[[Interp I i
  B0 S]]$. By \rref{I-Par} and $[[B1 => B]]$, we conclude that
  $[[Interp I i B S]]$.

  The remaining cases all fall from induction hypotheses and basic
  properties about convertibility and parallel reduction we have
  established in Section~\ref{sec:spec}.
\end{proof}
From Lemma~\ref{lemma:interppreservation} and \rref{I-Red}, we can easily
derive the following corollary that two convertible types can always interpret
into the same set. We adopt the terminology from \citet{martin-lof-a-la-coq}
and refer to this property as irrelevance.
\begin{corollary}[Irrelevance of logical relation\footnote{\dotv{semtyping.v}{InterpUnivN\_Coherent}}]
  \label{lemma:logrelcoherence}
  If $[[Interp I i A S]]$ and $[[A <=> B]]$, then $[[Interp I i B S]]$.
\end{corollary}
% \scw{Need a transition here}

Since the definition of our logical relation is an inductive relation,
it is not immediately obvious why each type $[[A]]$ can only uniquely
corresponds to one set $[[S]]$. The following lemma shows that our
logical relation is indeed functional.
\begin{lemma}[Logical relation is functional\footnote{\dotv{semtyping.v}{InterpExt\_deterministic}}]
  \label{lemma:logreldeter}
  If $[[Interp I i A S0]]$ and $[[Interp I i A S1]]$, then $[[S0 = S1]]$.
\end{lemma}
\begin{proof}
  The proof proceeds by induction over the derivation of the first
  premise $[[Interp I i A S0]]$.
  All cases that are not \rref{I-Red} follow immediately from the
  Lemma~\ref{lemma:interpinv}.

  For \rref{I-Red}, we are given that there exists some $[[B]]$ such
  that $[[A => B]]$ and $[[Interp I i B S0]]$. Our goal is to show
  that given $[[Interp I i A S1]]$ for some $[[S1]]$, we have $[[S0 =
  S1]]$. By the preservation property
  (Lemma~\ref{lemma:interppreservation}),
  we know that $[[Interp I i B S1]]$ since $[[A => B]]$. The statement
  $[[S0 = S1]]$ then immediately follows from the induction hypothesis.
\end{proof}

Lemma~\ref{lemma:logreldeter} enables us to show the following
improved inversion lemma for function types whose statement is free of
the relation $[[R]]$, analogous to the admissible rule \rref{I-PiAlt}.
\begin{lemma}[Pi Inv Alt\footnote{\dotv{semtyping.v}{InterpExt\_Fun\_inv\_nopf}}]
  \label{lemma:piinvalt}
  Suppose $[[Interp I i Pi A B S]]$, then there exists some $[[S0]]$
  such that the following constraints hold:
  \begin{itemize}
  \item $[[Interp I i A S0]]$
  \item $[[forall a, (# a in S0 implies (# exists S1 , Interp I i B {a}
    S1 #) #)]]$
  \item $[[S = { b | forall a, (# a in S0 , forall
    S1, (# Interp I i B {a} S1,  b a in S1 #) #) }]]$
  \end{itemize}
\end{lemma}
\begin{proof}
  Immediate from Lemmas~\ref{lemma:interpinv} and \ref{lemma:logreldeter}.
\end{proof}

The next lemma shows that our logical relation satisfies
cumulativity. That is, if a type has an interpretation at a lower
universe level, then we can obtain the same interpretation at a higher
universe level.
\begin{lemma}[Logical relation cumulativity\footnote{\dotv{semtyping.v}{InterpExt\_cumulative}}]
  \label{lemma:logrelcumulativity}
  If $[[Interp I i0 A S]]$ and $[[i0 < i1]]$, then $[[Interp I i1 A S]]$.
\end{lemma}
\begin{proof}
  Trivial by structural induction over the derivation of $[[Interp I
  i0 A S]]$.
\end{proof}
Note that in the statement of Lemma~\ref{lemma:logrelcumulativity}, we
implicitly assume that $[[I]]$ is defined on the set of natural
numbers less than $[[i1]]$.

\begin{corollary}[Logical relation is functional with different levels\footnote{\dotv{semtyping.v}{InterpExt\_deterministic'}}]
  \label{lemma:logreldeterhet}
  If $[[Interp I i0 A S0]]$ and $[[Interp I i1 A S1]]$, then $[[S0 = S1]]$.
\end{corollary}
\begin{proof}
  Immediate from Lemma~\ref{lemma:logreldeter} and
  \ref{lemma:logrelcumulativity}.
\end{proof}

We say that a set of terms $[[S]]$ is closed under expansion if given
$[[a in S]]$, then $[[b in S]]$ for all $[[b => a]]$.
The final property we want to show is that the output set $[[S]]$ from
the logical relation is closed under expansion. Unlike the previous
lemmas, we directly state the lemma
in terms of $[[InterpR i A S]]$ rather than $[[Interp I i A S]]$
because we need to know something about $[[I]]$ for this property to
hold in the \rref{I-Set} case.

\yl{Can lift this lemma somewhere earlier in the section since it doesn't really
  depend on anything}
\begin{lemma}[Interpreted sets are closed under expansion\footnote{\dotv{semtyping.v}{InterpExt\_back\_clos}}]
  \label{lemma:logrelbackclos}
  If $[[InterpR i A S]]$, then the set $[[S]]$ is closed under expansion.
\end{lemma}
\begin{proof}
  By the definition of $[[InterpR i A S]]$ from
  Figure~\ref{fig:logrelrec}, we unfold $[[InterpR i A S]]$ by one
  step into $[[ Interp I i A S  ]]$ where $[[I i]] := [[{A | exists S
    , InterpR i A S}]]$.
  We then proceed by induction over the derivation of $[[Interp I i A S]]$.

  All cases are trivial except for the \rref{I-Set} case, where we
  want to show that the set $[[I j]]$ is closed under expansion for
  all $[[j < i]]$. However, by the definition of $[[I]]$, we know that
  $[[A in I j]]$ if only if there exists some $[[S]]$ such that
  $[[Interp I i A S]]$. By \rref{I-Par}, we must also have $[[B in I
  j]]$ for all $[[B => A]]$.
\end{proof}

\section{Semantic Typing and Consistency}
\label{sec:logrelproof}
\begin{figure}[h]
\[
\begin{array}{lcl}

      [[rho |= G]] &:= & \forall i\ j\ S, \text{ if }[[i < |G|]]\text{ and
                     } [[InterpR j (G i < up Suc i > ) { rho } S ]] \text{, then } [[rho i in S]] \\
      [[G |= a : A]] &:= & \forall [[rho]], \text{ if }[[rho |=
                       G]]\text{ then there exists some } [[j]] \text{
                       and } [[S]] \text{ such that } [[InterpR j A
                       {rho} S]] \text{ and } [[a {rho} in S]] \\
      [[|= G]] &:= & \forall [[i < |G|]], \exists [[j]], [[drop Suc i G |= G i : Set j]]
\end{array}
\]
  \caption{Semantic Typing for \lang}
  \label{fig:semtyping}
\end{figure}

The logical relation we define in Figure~\ref{fig:logrel} does not
include cases for variables. Likewise, for the base types such as
boolean and equality, the output set $[[S]]$ contains only terms that
evaluate to closed terms.

\scw{What is the motivation for this section? Why do we want to generalize
the logical relation?}
To generalize our logical relation to open
terms, we define the semantic typing judgment by closing the open
terms with a substitution whose codomain consists of terms that
respect the interpretation of the types from the context. The full
definitions of well-formed substitution ($[[rho |= G]]$), semantic
typing ($[[ G |= a : A]]$), and semantic context well-formedness
($[[|= G]]$) are presented in Figure~\ref{fig:semtyping}.
\scw{explain all parts of this figure. it's pretty intimidating.}
In the
definition of $[[|= G]]$, we use the notation $[[drop i G]]$ to denote
the typing context obtained by dropping the last $[[i]]$ elements of
$[[G]]$. When $[[G]]$ has less than $[[i]]$ elements, $[[drop i G]]$
returns the empty list.

The following lemma makes the statement $[[G |= A : Set i]]$ easier to
work with.
\begin{lemma}[Set Inv\footnote{\dotv{soundness.v}{SemWt\_Univ}}\scw{spell out the whole word}]
  \label{lemma:setinv}
  The following two statements are equivalent:
  \begin{itemize}
  \item $[[G |= A : Set i]]$
  \item $\forall$ $[[rho]]$, if $[[rho |= G]]$, then there exists
    $[[S]]$ such that $[[InterpR i (A {rho}) S]]$
  \end{itemize}
\end{lemma}
\begin{proof}
  The forward direction is immediate by
  Lemma~\ref{lemma:interpinv}. We now consider the backward direction
  and show that $[[G |= A : Set i]]$ given the second bullet.

  Suppose $[[rho |= G]]$, then we know that there exists some $[[S]]$
  such that $[[InterpR i (A {rho}) S]]$. By the definition of semantic
  typing, it suffices to show that there exists some $[[j]]$ and
  $[[S0]]$ such that  $[[InterpR j Set i S0]]$ and $[[A {rho} in
  S0]]$.
  Pick $[[Suc i]]$ for $[[j]]$ and $[[ { A | exists S , InterpR i A S }
  ]]$ for $[[S0]]$ and it is trivial to verify the conditions hold.
\end{proof}

The semantic context well-formedness judgment ($[[|= G]]$), unlike its syntactic
counterpart $[[|- G]]$, is defined through a $\forall$ quantified statement rather
than inductively over the context. \scw{why is that the case?} It is easy to recover the same
structural rules:
\begin{lemma}[Semantic context well-formedness cons]
  \label{lemma:semwffcons}
  If $[[|= G]]$ and $[[G |= A : Set i]]$, then $[[|= G ++ A]]$.
\end{lemma}
\scw{point out that this lemma is the semantic analogue to Ctx-Cons. What about
Ctx-empty?}
\begin{proof}
  By the definition of semantic context well-formedness, the goal is
  to show that given $[[i < | G ++ A |]] = [[Suc |G|]]$, $[[drop Suc i
  (G ++ A) |= (G ++ A) i : Set j]]$. The statement can be easily
  proven by case analysis on whether $[[i]]$ is zero.
\end{proof}

Likewise, the semantic well-formendness judgment for substitutions
satisfies similar structural rules.
\begin{lemma}[Well-formed $[[rho]]$ cons\footnote{\dotv{soundness.v}{$\gamma$\_ok\_cons}}]
  If $[[InterpR i A S]]$, $[[a in S]]$, and $[[rho |= G]]$, then
  $[[rho .: a |= G ++ A]]$.
\end{lemma}
\begin{proof}
  Start by unfolding the definition of $[[rho .: a |= G ++ A]]$ and
  performing a case analysis similar to the proof of
  Lemma~\ref{lemma:semwffcons}.  The case where the number is $[[0]]$
  requires Lemma~\ref{lemma:logreldeterhet} to finish the proof.
\end{proof}

Next, we show some non-trivial cases of the fundamental theorem as
top-level lemmas and leave the remaining cases as exercises for the
reader.\scw{I dislike leaving ``exercises to the reader''}

First, we formulate the definition of valid renamings and prove that
semantic typing satisfies renaming so we can weaken the context when
reasoning about the variable case of the fundamental lemma
(Lemma~\ref{lemma:stvar}). Intuitively, given a valuation $[[rho |= G
++ D]]$, it is easy to show that we can extract some valuation
$[[rho0]]$ such that $[[rho0 |= G]]$, where $[[rho0]]$ is obtained by
``truncating'' $[[rho]]$. As a result, if we know that $[[G |= a :
A]]$, then we can conclude that $[[G ++ D |= a0 : A0 ]]$, where
$[[a0]]$ and $[[A0]]$ are obtained by shifting $[[a]]$ and $[[A]]$
after weakening the context; this implication holds because $[[rho |=
G ++ D]]$ induces a context $[[rho0]]$ such that $[[rho0 |= G]]$ so we
can make use of the premise $[[G |= a : A]]$ to derive what we need
for the conclusion. We recommend the readers to skip the proofs of
Lemmas~\ref{lemma:validtruncate} through \ref{lemma:semrenaming}
during the first read as long as they have an intuitive understanding
of what the renaming property is meant to capture.

\scw{Make this a definition? Would it be useful to create notation
  for the relation, such as $[[xi]]:[[G]]\Rightarrow[[D]]$? }
We say that $[[xi]]$ is
valid from the context $[[G]]$ to the context $[[D]]$ if the
following condition holds.
\[ \forall i \text{, if } i < | [[G]] |\text{, then }[[ ren xi i < |D| ]] \text{ and }
  [[D ren xi
  i < up Suc ren xi i > = G i < up Suc i > < xi >]] \]

\begin{lemma}[Truncate is valid]
  \label{lemma:validtruncate}
  If $[[i < |G|]]$, then $[[up i]]$ is a valid renaming from $[[drop i
  G]]$ to $[[G]]$.
\end{lemma}
\begin{proof}
  By the definition of a valid renaming, we must show that given $[[j
  < |drop i G|]] = [[|G|]] - [[i]]$, then the following conditions hold:
  \begin{itemize}
  \item $[[ren up i j]] = i + j  < [[| G | ]]$
  \item $[[G ren up i j < up Suc ren up i j > = drop i G j < up Suc j > < up i >]]$
  \end{itemize}
  The first bullet point is immediate from the fact that $[[j]] <
  [[|G|]] - [[i]]$. The second bullet follows from unfolding the
  definitions, and the fact that $[[drop i G j]] = [[G]](i + j)$ when
  $[[i]] + [[j]] < [[|G|]]$.
\end{proof}

\begin{lemma}[Renaming for $[[rho |= G]]$]
  \label{lemma:renamingval}
  If $[[rho |= D]]$ and $[[xi]]$ is a valid renaming from $[[G]]$ to
  $[[D]]$, then we have $[[rho0 |= G]]$ where $[[rho0 i = rho ren xi i]]$.
\scw{could you use $[[rho]]\circ[[xi]]$ for $[[rho0]]$?}
\end{lemma}
\begin{proof}
  Unfolding the definition of $[[rho0 |= G]]$, the goal is to show
  that for all $i,j,$ and $S$, if $[[i < |G|]]$ and $[[InterpR j (G i
  < up Suc i > ) { rho0 } S ]] \text{, then } [[rho0 i]] = [[rho ren xi i in S]]$.

  By the definition of $[[rho0]]$ and the validity of $[[xi]]$, we
have $[[G i < up Suc i > { rho0 }]] = [[G i < up Suc i > < xi > { rho
} ]] = [[D ren xi i < up Suc ren xi i > { rho }]]$. From $[[rho |=
D]]$ and $[[ren xi i < | D |]]$, we have $[[InterpR j D ren xi i < up Suc ren xi i > { rho }
S]]$ and $[[rho ren xi i in S]]$.
\end{proof}

\begin{lemma}[Renaming for $[[G |= a : A]]$]
  \label{lemma:semrenaming}
  If $[[G |= a : A]]$ and $[[xi]]$ is a valid renaming from $[[G]]$ to
  $[[D]]$, then $[[D |= a < xi > : A < xi > ]]$.
\end{lemma}
\begin{proof}
  Immediate from the definition of semantic typing and Lemma~\ref{lemma:renamingval}.
\end{proof}

\scw{Need a transition here that you are starting to explain the semantic typing
rules.}

\begin{lemma}[ST-Var]
  \label{lemma:stvar}
  If $[[|= G]]$ and $[[i < |G|]]$, then $[[G |= var i : G i < up Suc i  >]]$.
\end{lemma}
\begin{proof}
  Suppose $[[rho |= G]]$. By the definition of semantic typing, we
need to show that there exists some $[[j]]$ and $[[S]]$ such that
  \begin{itemize}
  \item $[[InterpR j G i < up Suc i > { rho } S]]$
  \item $[[rho i in S]]$
  \end{itemize}
  From the definition of $[[|= G]]$, we know that there exists some
  $[[j]]$ such that $[[drop Suc i G |= G i : Set j]]$. By
  Lemma~\ref{lemma:validtruncate}, we know that $[[up Suc i]]$ is a
  valid renaming from $[[drop Suc i G]]$ to $[[G]]$. By
  Lemma~\ref{lemma:semrenaming}, we deduce $[[G |= G i < up Suc
  i > : Set j]]$. By the identity from Lemma~\ref{lemma:setinv}, we
  know that $[[InterpR j G i < up Suc i > { rho } S]]$. It now
  suffices to show $[[rho i in S]]$, but that is immediate from the
  definition of $[[rho |= G]]$.
\end{proof}

\begin{lemma}[ST-Set]
  \label{lemma:stset}
  If $[[i < j]]$, then $[[G |= Set i : Set j]]$.
\end{lemma}
\begin{proof}
  Immediate by Lemma~\ref{lemma:setinv} and \rref{I-Set}.
\end{proof}

\begin{lemma}[ST-Pi]
  \label{lemma:stpi}
  If $[[G |= A : Set i]]$ and $[[G ++ A |= B : Set i]]$, then $[[G |= Pi
  A B : Set i]]$.
\end{lemma}
\begin{proof}
  Applying Lemma~\ref{lemma:setinv} to the
  conclusion, it now suffices to show that given $[[rho |= G]]$, there
  exists some $[[S]]$ such that $[[InterpR i Pi A{rho} B{up rho} S]]$.
  From Lemma~\ref{lemma:setinv} and $[[G |= A : Set i]]$, we know that
  there exists some set $[[S0]]$ such that $[[InterpR i A {rho} S0]]$.
From $[[G ++ A |= B : Set i]]$, we know that there must
exists $[[S]]$ such that $[[InterpR i B {rho .: a} S]]$ for every $[[a
in S0]]$. The conclusion immediately follows from Lemma~\ref{lemma:piintroalt}.
\end{proof}

\begin{lemma}[ST-Abs]
  \label{lemma:stabs}
  If $[[G |= Pi A B : Set i]]$ and $[[G ++ A |= b : B]]$, then $[[G |=
  \ A b : Pi A B]]$.
\end{lemma}
\begin{proof}
  By unfolding the definition of $[[G |= \ A b : Pi A B]]$, we need to
  show that given some $[[rho |= G]]$, there exists some $[[i]]$ and
  $[[S]]$ such that $[[InterpR i Pi A {rho} B {up rho} S]]$ and $[[\
  A{rho} b{up rho} in S]]$.

  By Lemma~\ref{lemma:setinv} and the premise $[[G |= Pi A B : Set
  i]]$, there exists some set $[[S]]$ such that
  $[[InterpR i Pi A {rho} B {up rho} S]]$. It now suffices to show that
  $[[\A{rho} b{up rho} in S
  ]]$. By Lemma~\ref{lemma:piinvalt}, there exists some $[[S0]]$ such
  that all following conditions hold:
  \begin{itemize}
  \item $[[InterpR i A{rho} S0]]$
  \item $[[forall a, (# a in S0 implies (# exists S1 , InterpR i B
    {rho .: a}
    S1 #) #)]]$
  \item $[[S = { b | forall a, (# a in S0 , forall
      S1, (# InterpR i B {rho .: a} S1,  b a in S1 #) #) }]]$
  \end{itemize}
  To show that $[[\A{rho} b{up rho} in S]]$, we need to prove
  that given $[[a in S0]]$,
  $[[Interp I i B {rho .: a} S1]]$, we have  $[[( \A{rho} b{up rho} )
  a in S1]]$.
  By Lemma~\ref{lemma:logrelbackclos}, the set $[[S1]]$ is closed
  under expansion. By Lemma~\ref{lemma:parabscbn}, since $[[( \A{rho} b{up rho} )
  a => b {up rho} {a}]] = [[b {rho .: a}]]$, it suffices to show that
  $[[b {rho .: a} in S1]]$, which is immediate from $[[G ++ A |= b :
  B]]$ and the fact that the logical relation is deterministic and
  cumulative (Lemma~\ref{lemma:logreldeterhet}).
\end{proof}

\begin{lemma}[ST-App]
  \label{lemma:stapp}
  If $[[G |= b : Pi A B]]$ and $[[G |= a : A]]$, then $[[G |= b a : B {a}]]$.
\end{lemma}
\begin{proof}
Suppose $[[rho |= G]]$. The goal is to show that there exists some
$[[i]]$ and $[[S1]]$
such that  $[[b {rho} a {rho} in S1 ]]$ and $[[InterpR i B {a} {rho}
S1]]$, or equivalently, $[[InterpR i B {rho .: a {rho}} S1]]$ since
$[[B {a}{rho}]] = [[B {rho .: a {rho}}]]$. By the premise $[[G |= b :
Pi A B]]$, Lemma~\ref{lemma:setinv}, and Lemma~\ref{lemma:piinvalt},
there exists some $[[i]]$ and $[[S0]]$ such that:
  \begin{itemize}
  \item $[[InterpR i A{rho} S0]]$
  \item $[[forall a0, (# a0 in S0 implies (# exists S1 , InterpR i B
    {rho .: a0}
    S1 #) #)]]$
  \item $[[forall a0, (# a0 in S0 , forall
      S1, (# InterpR i B {rho .: a0} S1,  b {rho} a0 in S1 #) #)]]$
  \end{itemize}
  Instantiating the variable $[[a0]]$ from the last two bullets with
  the term $[[a {rho}]]$, the conclusion immediately follows.
\end{proof}

\begin{theorem}[The Fundamental Theorem\footnote{\dotv{soundness.v}{soundness}}]
  \label{theorem:soundness}\leavevmode
  \begin{itemize}
  \item If $[[G |- a : A]]$, then $[[G |= a : A]]$.
  \item If $[[|- G]]$, then $[[|= G]]$.
  \end{itemize}
\end{theorem}
\begin{proof}
  Proof by mutual induction over the derivation of $[[G |- a :
  A]]$ and $[[|- G]]$.   The cases related to context well-formedness immediately follows
  from Lemma~\ref{lemma:semwffcons}.
Lemmas~\ref{lemma:stvar},~\ref{lemma:stset},~\ref{lemma:stpi},~\ref{lemma:stabs},~\ref{lemma:stapp}
  can be used to discharge their syntactic counterpart
  (e.g. Lemma~\ref{lemma:stabs} for case \rref{T-Abs}). The remaining
  cases not covered by the lemmas are similar to the ones already
  shown or simpler and therefore omitted from the text.

\end{proof}

\scw{Spell this out in a little more detail.}

\begin{proof}
  Immediate from Theorem~\ref{theorem:soundness} and the $[[Void]]$ case of Lemma~\ref{lemma:interpinv}.
\end{proof}

\section{Toward Decidability of Type Conversion and $\eta$ laws}
\label{sec:extension}
In this section, we sketch out how the logical relation from
Section~\ref{sec:logreldep} can be extended show the existence of
$\beta\eta$ normal forms for (open and closed) well-typed terms. We
first extend parallel reduction to include $\eta$ reduction for
functions.
\begin{center}
  \drule[width=2.5in]{P-AbsEta}
\end{center}

\Rref{P-AbsEta} effectively adds $\eta$ laws for functions to our
equational theory since coherence, the untyped relation used for type
conversion, is built on top of parallel reduction. We can recover the
same confluence result about parallel reduction using the standard
techniques from \citet{barendregt:lambda-calculi-with-types,
takahashi-parallel-reduction}, though specifically for the de Bruijn
representation, we need the following anti-renaming lemma about
parallel reduction.
\begin{lemma}[Par anti-renaming]
  \label{lemma:parantirenaming} If $[[a < xi > => b0]]$, then there
exists some $[[b]]$ such that $[[b < xi > = b0]]$ and $[[a => b]]$.
\end{lemma}

\begin{figure}[h]
  \[
    \begin{array}{lcl}
      % \beta\text{-}\mathit{neutral\ terms}\\
      [[e]] & ::= & [[i]]\ |\ [[e f]]\ |\ [[J e f f f]]\ |\ [[if e f
                    f]] \\ \\
      % \beta\text{-}\mathit{normal\ terms} \\
      [[f]] & ::= & [[e]]\ |\ [[Set i]]\ |\ [[Void]]\ |\ [[Pi f f]]\
                    |\ [[f ~ f : f]]\\
            & |   & [[\ f]]\ |\ [[refl]]\ |\ [[Bool]]\ |\ [[true]]\ |\ [[false]]
    \end{array}
  \]
  \caption{$\beta$-neutral and normal forms}
  \label{fig:nenf}
\end{figure}


The syntactic forms $[[e]]$ and $[[f]]$ (Figure~\ref{fig:nenf}) capture the neutral terms
and normal forms with respect to $\beta$-reduction, but can still take
$\eta$ reduction steps. We sometimes use the judgment forms $[[ne a]]$
and $[[nf a]]$ to indicate that there exists $[[e]]$ or $[[f]]$ such
that $[[a = e]]$ or $[[a = f]]$.

We can show that parallel reduction preserves $\beta$-normal and
neutral forms.
\begin{lemma}[Par preserves $\beta$-neutral and normal forms]
  \label{lemma:parnenf}
  If $[[a => b]]$, then
  \begin{itemize}
  \item $[[ne a]]$ implies $[[ne b]]$
  \item $[[nf a]]$ implies $[[nf b]]$
  \end{itemize}
\end{lemma}
This lemma is mainly to show that \rref{P-AbsEta} does not introduce
any new $\beta$ redex because $\eta$ reduction is the only real step
we can take.

The predicates $[[wne a]]$ and $[[wn
a]]$ describe terms that can evaluate into $\beta$-neutral or
$\beta$-normal form through parallel reduction and are defined as
follows.\scw{What does $wne$ stand for?}
\[ [[wne a]] \iff \exists [[e]], [[a =>+ e]] \]
\[ [[wn a]] \iff \exists [[f]], [[a =>+ f]] \]

\begin{figure}[h]
  \drules[I]{$[[Interp I i A S]]$}{Logical Relation}{Ne, VoidNew, BoolNew, EqNew}
  \caption{Extended logical relation}
  \label{fig:logrelopen}
\end{figure}

The updated logical relation and its auxiliary definitions are shown
in Figure~\ref{fig:logrelopen}.

% The idea of a term blocked from $\beta$ reduction is
% captured by $[[e]]$, the set of neutral terms. We augment the
% interpretation of booleans and the empty types with terms that
% evaluate to neutral terms. Furthermore, types that are neutral terms
% can also be assigned a meaning since they may be inhabited by other
% neutral terms.

In the definition of the logical relation, we omit the rules for
the function and universe cases since they remain identical to the
original version in Figure~\ref{fig:logrel}.
The changes to \rref{I-Bool} and \rref{I-Void} follow the exact same pattern.
An open term of type $[[Bool]]$ does
not necessarily reduce to $[[true]]$ or $[[false]]$, but may reduce to
a variable, or more generally, a neutral term. Likewise, the
$[[Void]]$ type, while remains uninhabited under an empty context, may
be inherited by the set of neutral terms when there is a variable in
the context that allows us to inhabit $[[Void]]$.

The rule for equality type $[[a ~ b : A]]$ is augmented with the preconditions that
$[[a]]$, $[[b]]$, and $[[A]]$ are all in their normal forms since
otherwise our model would include equality types that are themselves
not normalizing. Furthermore, the side condition $[[a <=> b]]$ is only
available when the equality proof reduces to $[[refl]]$. If the proof
term reduces to a neutral term, then there is nothing we can learn
about the relationship between $[[a]]$ and $[[b]]$.

Finally, in a
non-empty context, a type itself may evaluate to a neutral term and in
turn can only inhabited by neutral terms, thus the addition of \rref{I-Ne}.

Interestingly, all the properties we have shown in
Section~\ref{sec:logreldep} and \ref{sec:logrelproof} before the
fundamental lemma can be proven in the exact same order, where the new
cases due to \rref{I-Ne} and the augmentation of neutral terms
to \rref{I-Void, I-Eq, I-Bool} can be immediately discharged by
Lemma~\ref{lemma:parnenf}.

Before we can prove the fundamental theorem and derive the
normalization property as its corollary, we need to additionally
formulate and prove the adequacy property.

Let us first start with some auxiliary lemmas and definitions.
\begin{lemma}[Ext Wn]
  \label{lemma:extwn}
  If $[[wn a var i]]$, then $[[wn a]]$.
\end{lemma}
\begin{proof}
  By induction over the length of the reduction sequence in $[[wn a
  var i]]$. The proof relies on Lemma~\ref{lemma:parantirenaming} and
  \ref{lemma:parnenf}.
\end{proof}

\begin{lemma}[wne wn]
  \label{lemma:wnewn}
  If $[[wne a]]$ and $[[wn b]]$, then $[[wne a b]]$.
\end{lemma}
\begin{proof}
  Immediate by lexicographical induction over the length of the reduction sequences in
  $[[wne a]]$ and $[[wn b]]$.
\end{proof}

\scw{What does CR stand for?}
\begin{definition}[CR]
  Let $[[S]]$ be a set of lambda terms. We say that
  \begin{itemize}
  \item $[[S]] \in CR_1 \iff $  $[[forall a, (#  wne a implies a in S #)]]$
  \item $[[S]] \in CR_2 \iff$ $[[forall a, (# a in S implies wn a #)]]$
  \item $[[S]] \in CR \iff $ $[[S]] \in CR_1$ and $[[S]] \in CR_2$
  \end{itemize}
\end{definition}

\begin{lemma}[$CR_1$ for type]
  \label{lemma:cr1ty}
  If $[[wne A]]$, then we have $[[Interp I i A {a | wne a }]]$.
\end{lemma}
\begin{proof}
  Immediately from \rref{I-Ne} and \rref{I-Par}.
\end{proof}

\begin{lemma}[$CR$ for interpreted sets]
  \label{lemma:crel}
  If $[[I]](j) \in CR$ for all $[[j < i]]$ and $[[Interp I i A S]]$, then $[[S]] \in CR$.
\end{lemma}
\begin{proof}
  By induction over the derivation of $[[Interp I i A S]]$. The base
  cases are all immediate.

  In the function case ($[[Pi A B]]$), we use the induction
  hypothesis to show that variables, which are special cases of
  neutral terms, semantically inhabit the input type $[[A]]$. We apply the
  function to an arbitrary variable and we can then use
  Lemma~\ref{lemma:extwn} to conclude the $CR_2$ property.

  To show
  the $CR_1$ property, we need to prove that given a neutral term $[[b]]$
  such that $[[wne b]]$,
  and a term $[[a]]$ that semantically inhabits $[[A]]$, $[[b a]]$ gives
  us a term that semantically inhabits $[[B {a}]]$. From the induction
  hypothesis, $[[A]]$ also satisfies $CR_2$ and therefore $[[wn a]]$
  holds. By Lemma~\ref{lemma:wnewn}, we have $[[wne b a]]$. By $CR_2$
  from the induction hypothesis, since every term that evaluates to
  some neutral form semantically inhabits $[[B {a}]]$. Done.
\end{proof}


\begin{lemma}[$CR_2$ for type]
  \label{lemma:cr2ty}
  If $[[I]](j) \in CR$ for all $[[j < i]]$ and $[[Interp I i A S]]$, then $[[wn A]]$ holds.
\end{lemma}
\begin{proof}
  By induction over the derivation of $[[Interp I i A S]]$. The
  function case uses Lemma~\ref{lemma:crel} and Lemma~\ref{lemma:extwn}.
\end{proof}

\begin{lemma}[$CR_2$ for types (Rec)]
  \label{lemma:cr2tyrec}
  If $[[InterpR i A S]]$, then $[[wn A]]$.
\end{lemma}
\begin{proof}
  By strong induction over $[[i]]$ and Lemma~\ref{lemma:cr2ty}.
\end{proof}

\begin{lemma}[$CR$ for terms (Rec)]
  \label{lemma:crelrec}
  If $[[InterpR i A S]]$, then $[[S]] \in CR$.
\end{lemma}
\begin{proof}
  After unfolding the definition of $[[InterpR i A S]]$, trivial by
  Lemmas~\ref{lemma:cr1ty}, \ref{lemma:crel} and \ref{lemma:cr2tyrec}.
\end{proof}

The formulation of the valuation and semantic well-typedness from
Figure~\ref{fig:semtyping} and the fundamental lemma remains
unchanged.
The proof of the fundamental lemma is still carried out by induction
over the typing derivation, where the additional neutral term related
cases are handled by Lemmas~\ref{lemma:cr2tyrec} and
\ref{lemma:crelrec}.

The normalization property then follows as a corollary of the
fundamental theorem.
\begin{corollary}[Existence of $\beta$-normal form]
  \label{corollary:exbetanf}
  If $[[G |- a : A]]$, then $[[wn a]]$ and $[[wn A]]$.
\end{corollary}
\begin{proof}
  By the fundamental lemma, we know that $[[G |= a : A]]$. That is,
  for all $[[rho |= G]]$, there exists some $[[i]]$ and $[[S]]$ such
  that $[[InterpR i A {rho} S]]$ and $[[a {rho} in S]]$.
  We pick the valuation $[[rho]] = [[idtm]]$ (defined in Figure~\ref{fig:auxdef}), which injects
  natural numbers as term variables. The side condition $[[idtm |=
  G]]$ is satisfied since Lemma~\ref{lemma:crelrec} says neutral terms,
  including variables, semantically inhabit any $[[S0]]$ where
  $[[S0]]$ is the interpretation of some type. With our choice of
  $[[rho]]$, we have $[[A {rho}]] = [[A {idtm}]] = [[A]]$ and $[[a {rho}]] = [[a{idtm}]] = [[a]]$. Then we
  know that $[[InterpR i A S]]$ and $[[a in S]]$ for some $[[i]]$ and
  $[[S]]$. By Lemmas~\ref{lemma:crelrec} and \ref{lemma:cr2tyrec}, we
  conclude that $[[wn a]]$ and $[[wn A]]$ respectively.
\end{proof}
From Corollary~\ref{corollary:exbetanf}, we can show that there exists
$\beta\eta$-normal forms for well-typed terms, since $\eta$ reduction
preserves $\beta$-normal form (implied by Lemma~\ref{lemma:parnenf})
and also strictly decreases the size of the term.

Due to the non-deterministic nature of parallel reduction, we need to
take a few more steps to convert the existence of $\beta\eta$-normal
form into a decision procedure for type conversion. More specifically,
we can show that a deterministic evaluation strategy such as
leftmost-outermost reduction can always find the $\beta\eta$-normal
form if there exists one. However, we omit such proofs since they can
can be formulated on untyped lambda terms and thus orthogonal to the
specifics of dependently typed systems. Instead, we redirect readers
to \citet{factorization-essentially, takahashi-parallel-reduction} for
the details.

\scw{Name and foreshadow these lemmas when they are introduced so that
it is easier to refer to them in the discussion.}
Finally, we want to point out that
Lemmas~\ref{lemma:cr1ty},~\ref{lemma:cr2tyrec}, and
\ref{lemma:crelrec}, often referred to as adequacy of the logical
relation, are in fact required in the normalization proof for simply
typed languages~\citep{abel2019poplmark}. Similar to the simply typed
scenario, adequacy needs to be proven before the fundamental theorem
so we can handle rules such as \rref{T-If} where the scrutinee is a
neutral term. In \citet{abel2019poplmark}, a variant of
Lemma~\ref{lemma:extwn} is used in the exact same way to show that
lambda terms are themselves normalizing as we have done in
Lemma~\ref{lemma:crel}.

Dependent types make the proof slightly more complicated
as we also need to know that every type has a normal form. Whereas the
$CR_1$ property for types (Lemma~\ref{lemma:cr1ty}) is directly
derivable, the $CR_2$ property for types (Lemma~\ref{lemma:cr2ty})
requires the $CR_1$ property about the interpreted sets
(Lemma~\ref{lemma:crel}).

Overall, despite the dependently typed setting,
the extension of our logical relation to prove normalization of open
\emph{and} closed terms closely mirrors the progression from
normalization of closed terms~\citep{harpertait} to normalization of
open terms~\citep{harperkripke} in the simply typed lambda calculus.
It is in fact reassuring that once we have laid the foundational
technique for handling dependent types in our logical relation, the
further extensions more or less boil down to properties that can be
derived through syntactic means, which tend to not get in the way of
GÃ¶del's second incompleteness theorem.

\section{Mechanization}
\label{sec:logrelmech}
\begin{figure}[h]
  \begin{tabular}{ c |  c  | c  }
    & Consistency & Normalization \\
    \hline
    Library (Autosubst 2)  & 491 & - \\
    Syntactic typing (specification) &  69 & - \\
    Renaming (common)  & 46 & -  \\
    Syntactic soundness & 660 &  - \\
    Untyped reduction & 350 & 834 \\
    Logical relation & 342 & 515 \\
    Semantic typing and soundness & 169 & 197 \\
  \end{tabular}
  \caption{Statistics of the Coq Development}
  \label{fig:linecount}
\end{figure}

Figure~\ref{fig:linecount} shows the statics of our
development, including the base consistency proof from
Section~\ref{sec:logreldep} and \ref{sec:logrelproof} and the
extension to normalization for open and closed terms from
Section~\ref{sec:extension}.

Since the normalization and the consistency development share the same
syntactic and typing specification, they differ in only the categories
that are related to the logical relation. We use - as a marker that
the line count is the same.

Autosubst 2 takes our syntax specification in higher-order abstract
syntax and generates Coq syntax specification, renaming and
substitution functions, and lemmas and tactics that allow reasoning
about those functions. The auto-generated files and the library header
files are counted toward the \emph{Library (Autosubst 2)} category.

Orthogonal to the development of our consistency and normalization
proof, we prove the syntactic soundness of our system through subject
reduction and progress. The syntactic soundness proof shares the
definition of renaming with our semantic soundness proof, which is
factored out as a separate file under the Renaming (common) category.

\subsection{Artifacts Specific to Coq}
In this section, we discuss the Coq encoding of the definitions and proofs presented
in Section~\ref{sec:logrelproof}  and the artifacts that are
specific to Coq and may not appear in other proof assistants.

The powerset $[[PowerSet STm]]$ is encoded as the type \texttt{tm ->
Prop}, a predicate over \lang{} terms.
The inductive
definition of the logical relation in Figure~\ref{fig:logrel} requires
the impredicativity of Coq's \texttt{Prop} sort since\scw{or ``so that''?} in \rref{I-Pi},
the function $[[F]]$ can be later instantiated into the logical
relation itself (e.g. in the proof of Lemma~\ref{lemma:piintroalt}).

In Coq, there is a distinction between computable functions and
relations that can later be proven to be functional. The former can be
viewed as a strict subset of the latter in axiom-free Coq. To be more
precise, given a relation \texttt{R : A -> B -> Prop} subject to the
totality and functionality constraints ($\forall$ \texttt{a} $\in$
\texttt{A}, there exists a unique \texttt{b} $\in$ \texttt{B} such
that \texttt{R a b} is inhabited), we do not immediately obtain a function
\texttt{F : A -> B} such that $\forall$ \texttt{a} $\in$ \texttt{A},
\texttt{R a (F a)} is inhabited. However, the functional side
conditions of a relation is clunky to express and tend to block
automation. A simple workaround is to assume the axiom of unique choice, which
is known to be consistent with Coq and allows us to induce a function \texttt{F
: A -> B} once we have shown the relation \texttt{R : A -> B -> Prop}
is functional. This approach would make our Coq development match
the text version of our proof from Section~\ref{sec:logrelproof} more
closely.

However, we choose instead an axiom-free workaround and define
\rref{I-Pi} as follows in our Coq mechanization.
\begin{center}
  \drule[]{I-PiCoq}
\end{center}
It should be easy to verify that the preconditions of
\rref{I-Pi}, \rref{I-PiAlt}, and \rref{I-PiCoq} are all
equivalent. After establishing Lemma~\ref{lemma:logreldeter}, it is
possible to further show that the conclusions of the rules are
equivalent, too.\scw{If it is easy, you should have already done it.
Unless it is really long and boring.}

% This formulation allows us to derive Lemma~\ref{lemma:piintroalt}
% before we even show that our logical relation is
% functional/deterministic, but does not affect the proof structure
% otherwise.
We choose to keep this discrepancy between the Coq development and the
description of the logical relation presented in Section~\ref{sec:logreldep} since the
skolemization process is more intuitively expressed in terms of
function symbols rather than relation symbols. Otherwise, we do not
see a clear advantage of \rref{I-PiCoq} over \rref{I-Pi} in set
theory, where there is no distinction between computable functions and
functions in general. \scw{not sure I follow this last bit}

\subsection{Automation}
\label{sec:automation}
Our Coq mechanization heavily uses automation, though instead of
defining custom tactics, we rely mostly on off-the-shelf tools such as
Autosubst 2~\citep{autosubst2} and CoqHammer~\citep{czajka2018hammer}.

We use the Autosubst 2 framework to specify our syntax in HOAS and
produce Coq syntax files in de Bruijn representation. Additionallly,
Autosubst 2 provides a powerful tactic \texttt{asimpl} that
can be used to prove the equivalence of two terms constructed using
the primitive operators provided by the framework. This greatly
simplifies the reasoning about substitution in our development as
almost all substitution related properties are immediately discharged
by \texttt{asimpl} without having to manually prove or even directly invoke any
substitution related lemmas. \scw{You are only referring to lemmas about
how substitution relates to syntax, right? You still need to manually
invoke lemmas about substitution and judgements.}

For other automation tasks that are not specific to binding, we use
the powerful \texttt{sauto} tactic provided by CoqHammer to write
short and declarative proofs. For example, here is a one-line proof of
the triangle property about parallel reduction, from which the diamond
property (Lemma~\ref{lemma:pardiamond}) follows as a corollary.
\scw{you have space, so repeat the mathematical statement of the lemma}
\begin{minted}{coq}
Lemma par_triangle a : forall b, Par a b ->  Par b (tstar a).
Proof.
  apply tstar_ind; hauto lq:on inv:Par use:Par_refl,par_cong ctrs:Par.
Qed.
\end{minted}
In prose, the triangle property can be proven by induction over the
graph of the \texttt{tstar} function, which stands for the Takahashi
translation~\citep{takahashi-parallel-reduction}. Options \texttt{inv:Par} and
\texttt{ctrs:Par} say that the proof involves inverting and
constructing of the derivations of parallel
reduction. The option \texttt{use:Par\_refl,par\_cong} allows the
automation tactic to use
the reflexivity and congruence properties of parallel
reduction as lemmas.
\scw{What does \texttt{lq:on} and \texttt{hauto} mean?}

The automation here not only gives us a proof that is shorter and more
resiliant to changes in definition, but also gives useful
documentation for readers who wish to understand how the underlying
proof works since the automation tactic is guaranteed to not use
lemmas or invert derivations that are not specified in the
\texttt{use} or \texttt{inv} flag.


\section{Related Work and Discussion}
\label{sec:relatedwork}

\scw{Maybe it would be useful to include a chart here, so that readers can
  easily keep track of the features of the various languages.  i.e. which ones
  include large eliminations? type-directed equivalence? impredicative prop?
  inductive datatypes? what are their line counts?}

\citet{Martin-Lof-1973}, \citet{geuvers1994short}, and
\citet{barendregt:lambda-calculi-with-types} are some of the earlier
works that establish metatheoretic results strong enough to derive
consistency for dependently typed systems.
\scw{Should give Martin L\"of credit for first consistency proof.}
\scw{What techniques do these three proofs use? How is it different from
your proof? What about Luo, which
introduced a universe hierarchy? What about categories with families, or
other ways of showing consistency?}
Some of these techniques
are still in use in more recent works. For example, the technique for
proving strong normalization by \citet{geuvers1994short} is adapted by
\citet{moon2021graded} to show the same property to a dependently
typed system extended with modalities.

\citet{decagda} mechanizes in Agda the decidability of type
conversion rule for a dependently typed language with one predicative
universe level and typed judgmental equality with function
$\eta$-law. Unlike our logical relation for \lang{}, \citet{decagda}
uses a Kripke-style logical relation parameterized over an
type-directed equivalence relation satisfying certain
properties. Their logical relation is defined using the
induction-recursion scheme, which is available in Agda but not in Coq.
\citet{martin-lof-a-la-coq} manages to encode the logical relation
from \citet{decagda} in the predicative fragment of Coq using a
special way of encoding induction recursion. Their work further
extends the decidability of type conversion result from~\citet{decagda} to the decidability
type checking of a bidrectional type system.

\citet{anand2014towards} mechanizes the metatheory of
Nuprl~\citep{constable1986implementing} in Coq. The metatheory is an
extensional type theory with features such as dependent functions,
inductive types, and a full universe hierarchy. \citet{nbeincoq}
mechanizes the normalization-by-evaluation algorithm in Coq for a
dependently typed language with one predicative universe, similar to
\citet{decagda} and \citet{martin-lof-a-la-coq}. Both
\citet{anand2014towards} and \citet{nbeincoq} leverage the
impredicative \texttt{Prop} sort of Coq to define the interpretation
of dependent function types and thus are closely related to our
mechanization. However, instead of explaining the purely inductive
logical relation as a convoluted workaround to the lack of
induction-recursion in Coq, we give a self-contained explanation of
our logical relation.

Finally, it is worth pointing out that all systems we have discussed
so far builds a relational model for their logical relation. Recall
that our logical relation takes the form $[[InterpR i A S]]$ where
$[[S]]$ is a set of terms. In a relational model, each type is
interpreted as a partial equivalence relation over terms rather than a
set. A relational model is necessary for an extensional type theory
such as Nuprl, though \citet{nbeincoq,decagda,martin-lof-a-la-coq} all
use a relational model either to justify the function $\eta$-law or to
derive $\Pi$-injectivity. In Section~\ref{sec:extension}, our $\eta$
law for function is baked into the untyped reduction
relation and therefore a relational model is not needed.
\scw{would it be difficult to extend your proof to be a PER?}

The dependently typed systems we have discussed so far also vary
greatly in expressiveness. For example, the Calculus of
Constructions~\citep{CoC} and MLTT without universe levels are unable
to encode large elimination. \citet{decagda} and \citet{nbeincoq} lack
identity types. \citet{nbeincoq} lacks $\eta$-law for functions. Among
the mechanized systems we have discussed so far, only
\citet{anand2014towards} has a full universe hierarchy.
Our object language \lang{}, while small, has a decent coverage of
features commonly seen in dependently typed languages, including
dependent pattern matching, dependent function types, a full universe
hierarchy, an intensional identity type. We hope features such as
type-directed reduction (necessary for unit $\eta$-law) and
impredicative sorts can be implemented in a similarly streamlined
fashion and we will leave those extensions as part of our future work.

% To end this section, we
\scw{should this be a new subsection?}
The final question we want to address is: why is our proof,
even with the extension from Section~\ref{sec:extension}, so much
shorter than the proofs from \citet{decagda, nbeincoq,
  martin-lof-a-la-coq}?
First, unlike developments that mechanize the correctness of a clever
type conversion algorithm, we only show the existence of
normal form for open and closed terms and state our properties in
terms of the untyped small-step reduction relation. This removes a lot
of scaffolding in the specification of our type system and our logical
relation.

This contrasts our development with
\citet{martin-lof-a-la-coq}, where the irrelevance property turns out to be the most
difficult property to prove due to the complexity of the equality
judgment used to define the logical relation. In our system, the
irrelevance property (Corollary~\ref{lemma:logrelcoherence}) is a
direct consequence of Lemma~\ref{lemma:interppreservation},\scw{refer to
lemma name} which is
straightforward after we prove the results about parallel
reduction in Section~\ref{sec:spec}. In other words, we keep the
the logical relation itself minimal at the cost of extra lemmas that can be proven
through syntactic means independently from the logical relation.
For example, as commented near the end of Section~\ref{sec:extension},
our normalization property (Corollary~\ref{corollary:exbetanf})
% can induce a decision procedure for type conversion by reducing two
% terms to $\beta\eta$-normal form and check for their syntactic
% equivalence. This decision procedure would be inefficient compared to
% NbE or the algorithm from \citet{martin-lof-a-la-coq} that reduces terms
% to weak head normal and checks for the equivalence of subterms
% recursively
does not immediately induce an efficient decision procedure, but it is
possible to recover an efficient algorithm by reasoning about untyped
lambda terms.

% the concision of
% our proof can be largely attributed to the fact that we bake into the
% logical relation only the minimum amount of information that is the
% most conducive to the proof of the metatheoretic result.

Another key to our proof is the very early establishment of the confluence
property of the paralell reduction relation
(Lemma~\ref{lemma:pardiamond}). This property is used in
Lemma~\ref{lemma:interppreservation} to show that the interpretation
of a type is preserved under evaluation. That is, if $[[InterpR i A
S]]$ and $[[A => B]]$, then we also have $[[InterpR i B S]]$.
In a system with typed directed reduction, the confluence result is
harder to establish since confluence requires subject reduction, which
circularly depends on $\Pi$-injectivity, a consequence of
confluence~\citep{siles2012pure}. There are different workarounds to
this problem. \citet{siles2012pure} proposes a syntactic approach by
defining a type system where the confluence result is
directly provable and later show that the system of interest is
equivalent to the system with the confluence property.
\citet{decagda} uses a relational model and the relational counterpart
of Lemma~\ref{lemma:extwn} to derive $\Pi$-injectivity. The relational
model is parameterized by a typed indexed equivalence relation and
is reused to prove derive different properties in their
development. Another perhaps simpler approach is to simply
extend the judgmental equality with rules about
$\Pi$-injectivity~\citep{weirich:systemd}. This allows subject
reduction to be proven independently from confluence and
$\Pi$-injectivity can later be shown to be admissible. We find the
approach from \citep{weirich:systemd} the most lightweight as it
allows us to derive confluence early on even in systems with typed
conversion. \scw{Maybe mention my $\eta$-equivalence paper here somewhere?}

In cases where the judgmental equality does not leverage type information heavily
(e.g. $\eta$-law for the unit type), it might be possible to show that
$\Gamma \vdash a \equiv b : A$ is equivalent to the conjunction of
$[[G |- a : A]]$, $[[G |- b : A ]]$, and $[[a <=> b]]$. If such a
property holds (we believe this is likely true for both
\citet{decagda} and \citet{martin-lof-a-la-coq}), we can reuse our existing logical relation in
terms of untyped parallel reduction to show the decidability of type
conversion. Otherwise, to fully model the system, we need to bake
typing information into our logical relation and we need to redefine
our logical relation in Kripke-style so we can relax the scoping
constraint in order to prove adequacy, though a relational model would
still be unnecessary as long as the $\eta$ laws are baked into the
typed directed relation. \scw{not sure I understand this last bit}

Since confluence plays such as key role in our proof, we are uncertain
how to generalize our technique to systems where confluence does not
hold, and we will investigate those scenarios in our future work.
\scw{What systems are you thinking of? Or do you mean more generally
that this technique only works for languages where the definition of
equality is based on joinability of parallel reduction?}

% We are able to avoid the complexivity of a Kripke-style logical relation
% by defining our logical relation in terms of untyped parallel
% reduction, which does not impose any scoping constraint on the
% terms.


% Why is it that the justification of $\eta$ law
% requires a Kripke-style relational model in all three developments
% but not ours? Are we ``cheating'' by defining \lang{}'s equational
% theory using an untyped conversion rule? Instead of answering the
% questions one by one, we clarify the design of our type system and our
% proof technique so the answers to those questions are self-evident.

% The key to the shortness of

\section{Conclusion}
\label{sec:conclusion}


% Type soundness can be proven through a syntactic
% approach~\citep{syntacticsoundness} as a corollary of two properties:
% progress and preservation. % The syntactic type soundness proof
% % varies in complexity depending on the underlying type
% % system. For example, a type system that tracks information flow would
% % require additional structural rules related to security levels. In
% % this paper, we focus on one specific type of complexity: the
% In Figure~\ref{fig:stlcsoundness}, we summarize the structure of the
% syntactic type soundness proof for the simply typed lambda
% calculus. Each lemma can be proven by structural induction over the
% typing derivation, while using the previous established results as
% lemmas for specific cases that do not immediately follow from the
% induction hypothesis. If we make our language more complex by adding
% full dependent type support, the overall structure remains almost
% identical.


% NbE in Coq

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{refs}

%%
%% If your work has an appendix, this is the place to put it.

\end{document}
\endinput
%%
%% End of file `sample-acmsmall.tex'.
