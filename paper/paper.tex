\newif\ifcomments     %% include author discussion
\newif\ifanonymous    %% include author identities
\newif\ifextended     %% include appendix
\newif\ifsubmission   %% prepare the submitted version
\newif\ifpublic       %% version available for posting / final version

\commentstrue         %% toggle comments here
\extendedfalse
\anonymoustrue

\submissionfalse     %% at most one of these must be true (neither for draft version)
\publicfalse         %% but if you want to see comments, these should both be off


% If we are going to make a version public, i.e. on arXiv, we should
% make sure that there are no comments and our names are on it.
\ifpublic
\submissionfalse
\commentsfalse
\anonymousfalse
\fi

%% If we are submission, make sure there are no comments and our names
%% are NOT on it.
\ifsubmission
\publicfalse
\commentsfalse
\anonymoustrue
\fi


%%
%% This is file `sample-acmsmall.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `acmsmall')
%%
%% IMPORTANT NOTICE:
%%
%% For the copyright see the source file.
%%
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-acmsmall.tex.
%%
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%%
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[acmsmall,screen=true,
\ifpublic review=false\else,review=true\fi
  ,anonymous=\ifanonymous true\else false\fi]{acmart}
\usepackage{fontspec}
\newfontfamily\boxedsymbols{DejaVu Sans}
\usepackage{ottalt}
\usepackage{minted}
\usepackage{xspace}
\usepackage{tcolorbox}
\usepackage[para]{footmisc}
\definecolor{lightgray}{gray}{0.85}
\newcommand{\dotv}[2]{\href{#1}{\texttt{#1}}{\texttt{:#2}}}
\newcommand{\lang}{$\lambda^{U\mathbb{B}\ottkw{Id}}$\xspace}
\inputott{rules}
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% to allow unicode characters in minted code
\usepackage{newunicodechar}
\newunicodechar{â‡’}{$\Rightarrow$}

\usepackage{draft}

\ifcomments
\newnote{scw}{blue} % Stephanie Weirich
\newnote{yl}{purple} % Yiyun Liu
\else
\newcommand{\scw}[1]{}
\newcommand{\yl}[1]{}
\fi


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
\citestyle{acmauthoryear}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Functional Pearl: Short and Mechanized Logical Relation for Dependent Type Theories}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Yiyun Liu}
\orcid{0009-0006-8717-2498}
\affiliation{
  \institution{University of Pennsylvania}
  \city{Philadelphia}
  \country{USA}
}
\email{liuyiyun@seas.upenn.edu}

\author{Stephanie Weirich}
\orcid{0000-0002-6756-9168}
\affiliation{
  \institution{University of Pennsylvania}
  \city{Philadelphia}
  \country{USA}
}
\email{sweirich@seas.upenn.edu}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
% \renewcommand{\shortauthors}{Trovato et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
Proof by logical relation is a powerful technique that has been used
to derive metatheoretic properties of type systems, such as
consistency and parametricity. While there exists a
plethora of introductory materials about logical relation in the
context of simply typed or polymorphic lambda calculus, a streamlined
presentation of proof by logical relation for a dependently typed language
is lacking. In this paper, we present a short
consistency proof for a dependently typed language that contains a
rich set of features, including a full universe
hierarchy, booleans, and an intensional identity type. We show that
the logical relation can be easily extended to prove the existence of
$\beta\eta$-normal forms.
We have
fully mechanized the consistency proof using the Coq proof assistant
in under 1000 lines of code, with 500 lines of additional code for the
$\beta\eta$-normal form extension.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Logical Relation, Dependent Types, Logical Consistency, Coq}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
In this paper, we present a \emph{short} and \emph{mechanized} proof of
logical consistency for \lang{}, a dependent type theory with a full
predicative universe hierarchy, large eliminations, an intensional identity
type, a boolean base type, and dependent elimination forms.

Our goal with this work is to demonstrate how the proof technique of
\emph{syntactic logical relations} can be applied to reason about dependent
type theories.  Logical relations are a powerful proof technique for reasoning
about lambda calculi and their operational semantics. They have been used to
show diverse properties such as strong normalization, contextual equivalence,
representation independence, noninterference, compiler correctness, and the
decidability of conversion algorithms. \scw{add citations? emphasize that we are working
with syntactic logical relations.}

Tutorial material on logical relations~\citep{skorstengaard2019introduction,
  harpertait, harperkripke, pierce2002types,
  pierce2004advanced,harper2016practical} is primarily focused on systems
with simple or polymorphic types. In that context, syntactic logical relations
can be define as simple recursive functions over the structure of types, or
(in the case of recursive types) defined over the evaluation steps of the
computation. However, neither of these techniques can be used to define a
logical relation in the context of a predicative dependent type theory, so a
young researcher might be excused for thinking that proofs that use logical
relations are not applicable for such languages.

But this is not the case. \scw{Add a sentence about pen-and-paper LR proofs for dependent type theories}
Recent authors have developed tour-de-force
mechanizations for the metatheory of modern proof
assistants~\citep{nbeincoq,decagda,martin-lof-a-la-coq,anand2014towards}, and
have relied on logical relations defined as part of their
developments. However, because these proofs show diverse results about real
systems and algorithms, these developments range in size from 20,000 to
400,000 lines of code. As a result, their use of logical relations arguments
difficult to isolate from their surrounding contexts, and thus, not accessible
to casual readers.

Thus, our paper provides a gentle and accessible introduction to a powerful
technique for dependent type theories. To promote the use of machine-assisted
reasoning, our development is accompanied by a short mechanized proof script,
of less than 1000 lines of code, developed using the Coq/Rocq proof
assistant~\cite{coq}.

We have streamlined our proof through a number of means: the careful selection
of the features that we include in the object type system and the results
that we prove about it, in addition to the judicious use of automation.  Our
language is small, but includes enough to be illustrative. For example, we
eschew inductive datatypes or W-types, but we do include propositional
equality and booleans in order to capture the challenges presented by indexed
types and dependent pattern matching. We do not show the decidability of type
checking, nor do we develop a PER semantics, but we do demonstrate how our
consistency proof can be extended (at a moderate cost of 500 lines of code) to
show the existence of $\beta\eta$-normal form for well-typed open \emph{and}
closed terms. We include a full predicative universe hierarchy and
type-level computation, to demonstrate the logical strength of the
approach. % \scw{Say that we don't have impredicativity, but neither does anyone
  % else?}\yl{Nobody else but Barras. I'll find the citation}
%%
%% SCW: save specific comparisons with other systems for later
%%
% The big difference in the size of the developments does not
% necessarily imply that our proof technique leads to a more concise
% proof due to the differing expressiveness of the languages and the
% different metatheoretic results being established. For
% example, \citet{anand2014towards} mechanizes the metatheory of
% Nuprl~\citep{constable1986implementing}, which, on top of all the
% features that \lang{} supports, includes W-types and partial types and
% requires a PER semantics to model its extensional typed
% equality. The object language from \citet{decagda} does not support
% identity types and only has one predicative universe, but additionally
% supports $\Sigma$ types. However, for a researcher who wishes to learn
% the underlying techniques for mechanized logical relation for
% dependent type theory, a small development like ours is much easier to
% navigate and understand. Furthermore, we show how our simple
% consistency proof can be easily extended to show the existence of
% $\beta\eta$-normal form for well-typed open \emph{and} closed terms,
% giving us a metatheoretic result almost as strong as the one from
% \citet{decagda} at the moderate cost of around 500 lines of extra code.


The result of our work is a development that an interested researcher can
navigate and understand. We accompany this mechanized proof with an informal
description, presented here using set theory notation and terminology so that
the material is accessible to readers with general mathematical background,
That said, our explanations do not stray too far away from our proof scripts.
We label each lemma directly to its counterpart in the proof script,
anticipating that readers may wish to reference and validate our formalism.
Our typeset representations are purposefully made to directly follow our
mechanical proofs, while avoiding, as much as possible, the introduction
of artifacts that are specific to theorem provers.

Not only does this connection aid readers that wish to, like us, adopt proof
assistants for their day-to-day use. We also find that this precision is
important for conveying the proof technique itself. Unlike properties that are
derivable through syntactic means, proofs by logical relation make demands on
the strength of the logic in which they are expressed. An informal proof that
attempts to be agnostic or ambiguous about the underlying
metatheory % may struggle to even
% convey the validity of their definition and
requires substantial
effort from the reader to even understand whether it is theoretically
possible to encode such proofs in a given ambient logic, such as those found
in modern proof assistants.

% The close correspondence between a typeset proof and a mechanized
% proof comes at the potential risk that the artifacts specific to
% theorem provers may become visible in the presented proof.
%However, for proofs by logical relation for
%dependent types, we find our approach advantageous for a few reasons.
Furthermore, while a proof assistant may reject perfectly valid definitions,
it helps us keep our definition precise and unambiguous. A precise definition
is crucial as the reasoning principles we are allowed to use is directly tied
to the definition, which is sometimes obscured by concise notations that
diverge too far from a formal proof.

Finally, our approach does not result in a verbose proof on paper, thanks to
the already short mechanization. While we do make conservative simplifications
to our typeset proof, such as avoiding the clunky syntax for well-founded
recursion in Coq, we keep the overall structure of our typeset proofs
consistent with our mechanization.

The key contributions of each section of our paper are as follows.
\scw{I'm still not happy with this overview / contributions list. }

In Section~\ref{sec:spec}, we introduce \lang{}, the dependent type theory of
interest, reminiscent of Martin-LÃ¶f style predicative type systems. A key
design choice that impacts our proofs is the use of an untyped conversion
rule, inspired by Pure Type Systems~\citet{barendregt1991introduction}, and
specified through parallel reduction to normal form~\citet{barendregt}.
Because we believe that a good coverage of features makes our proof applicable
to a broad range of type systems, \lang{} incorporates some of the most common
features of dependent type theory, including an intensional identity type, a
boolean type, large elimination, dependent elimination, and a full universe
hierarchy. While our use of untyped conversion is nonstandard for MLTT, we
discuss how our proof can be adjusted for systems with a typed, judgmental
equality.

In Section~\ref{sec:logreldep}, we formulate the consistency property and
motivate where a proof by logical relations is required. The most important
contribution of this section is the definition of the logical relation as an
inductively defined relation and demonstrate how to reason about this
definition. We also show that the logical relation respects evaluation
(referred to as the irrelevance property in \citet{martin-lof-a-la-coq}), and
prove that the logical relation is a partial function; that is, each type can
have at most one unique interpretation.

In Section~\ref{sec:logrelproof}, shows that our definitions can be the
subject of well-established reasoning techniques for logical relations. In
particular, we define a notion of semantic typing in terms of our logical
relation and prove the fundamental theorem, which states that syntactic typing
implies semantic typing. Consistency follows from this result as a corollary.

In Section~\ref{sec:extension}, extends the definition of the logical relation
to include terms with free variables, and proves that every well-typed term
has a $\beta$-normal form. After laying the foundation for handling type-level
computation in Section~\ref{sec:logreldep}, this extension requires mechanical
changes that directly mirror an analogous extension for a simply typed
language. We use this section to demonstrate the idea that once we have
established the base techniques, we can port ideas that have been studied in
the context of a simpler system to the dependently-typed setting.  We believe
it is possible to extend our logical relation to a Kripke-style and relational
model in a similar fashion.

In Section~\ref{sec:betaeta} we show how to incorporate the function $\eta$-law
into the conversion rule for \lang{}.

In Section~\ref{sec:logrelmech}, we discuss the details about our
mechanization, including our use of existing libraries such as
Autosubst 2~\citep{autosubst2} for handling bindings and
CoqHammer~\citep{czajka2018hammer} for general-purpose automation.

In Section~\ref{sec:relatedwork}, we discuss how our proof relates to
existing proofs by logical relations and other proof techniques for
proving consistency and normalization.

In Section~\ref{sec:discuss}, we explain the various factors that contribute
to our short proof.

We hope our success at creating a short and mechanized proof for a
relatively feature-complete language will encourage future researchers
to leverage the tool of logical relations in mechanized
proofs for dependent types.
% % For
% % example, \citet{geuvers1994short} requires impredicativity to encode
% % Calculus of Constructions, an impredicative dependent type theory, but
% % also relies on the classification property to define the logical
% % relation over well-formed types and kinds. Their simple
% % presentation of the logical relation as an inductively defined
% % function over types, reminiscent of logical relations for simply typed
% % languages,








% However, we make the
% typeset definitions as close as possible to our mechanization so the
% definitions and the proofs can be easily encoded in a proof
% assistant.
% We find the close correspondence
% between our typeset presentation and the Coq development advantageous
% for a couple of reasons. First, compared to other proof techniques,
% such as the use of preservation and progress to derive syntactic
% soundness, defining a logical relation for a dependently typed
% language is demanding on the strength of the metatheory.



% % Depending on its application, we care about certain metatheoretic
% % properties about a type system. As a programming language, we may care
% % about type soundness, which states that a well-typed never gets stuck
% % during evaluation.
% When a dependently type system is used as a program logic where terms
% encode proofs, we want our type system to be logically consistent,
% meaning that the empty type is not inhabited.

% The consistency proofs of various dependently typed systems, including Martin-Lof's
% type theory and the Calculus of Constructions, have long been
% available in the literature. In particular, recent works such as \citet{nbeincoq},
% \citet{decagda}, and \citet{martin-lof-a-la-coq} mechanize the
% correctness of the NbE algorithm, the decidability of type
% conversion, decidability of type
% checking respectively for dependently typed systems. From these
% properties, consistency can be derived as a corollary.

% The underlying technique of the forementioned
% works is proof by logical relation,
% which involves interpreting types as reducibility predicates,
% representing sets of terms satisfying certain properties with respect
% to the reduction relation. While the proof technique and the
% consistency result for dependent types are both well-established,
% there is a lack of rigorous and accessible material that shows
% how proof by logical relation can be applied to dependently typed
% systems.
% \scw{You are choosing to focus on mechanized logical relations proofs for
% dependent type theories, not consistency proofs for dependent type theories.
% Why? (And your title shuld match}


% Introductory materials about logical relations or standard textbooks such as
% \citet{skorstengaard2019introduction}, \citet{harper2016practical},
% and \citet{pierce2002types}
% talk about logical relations for simply or polymorphically typed
% languages, proving results such as termination for closed terms and parametricity.
% \scw{Are there some OPLSS notes from Amal Ahmed to also cite? Other modern textbooks?
% Does Aspinall and Hofmann's chapter of ATTAPL include a logical
% relation?}
% \yl{skorstengaard is from the OPLSS notes. Cited ATTAPL}
% \yl{Don't have a copy of }
% \scw{Seems like you should also mention POPLmark reloaded somehere too?}
% \citet{pierce2004advanced}, \citet{harperkripke}, and \citet{abel2019poplmark} show how
% a Kripke-style logical relation can be used to include scoping
% information in the logical relation and
% derive properties such as the existence of normal form or strong
% normalization for open and closed terms in simply typed languages.
% Overall, the introductory texts about logical relations
% cover systems and properties with varying degrees of complexity, from
% simply typed to polymorphicly typed, logical predicate to logical
% equivalence, closed terms to open terms.

% The glaring gap here is the
% lack of fully dependently typed systems where computations may appear
% at the type-level. It is far from obvious why proof by
% logical relation is even applicable to dependent types, since the type
% may very well-be a computation that is yet to be evaluated.
% While it is assuring that proof by logical relations for dependent
% types is available in mechanized forms, % the key to address the
% % complexities of dependent types is obscured in
% \citet{nbeincoq,decagda,martin-lof-a-la-coq} all involve relational,
% Kripke-style models that obscure the technique for addressing
% type-level computation. The added complexivity is evident
% from the size of their code base. All three developments involve 20
% thousand to 30 thousand lines of Coq or Agda code.

% The goal of this paper is to give a tutorial on proof by logical relation for
% dependent types in a simple and digestable format. \scw{This sentence should come as
% early as possible.} Dependently typed systems comes in many flavors and
% vary greatly in their expressiveness.
% In Section~\ref{sec:spec}, we introduce \lang{}, a dependently typed
% language that is small but relatively complete in features \scw{list these features explicitly:
% large eliminations, indexed types, others? \ldots} related to
% dependently types, including large elimination, a full universe
% hierarchy, an intensional identity type and a boolean base type, both
% of which are equipped with dependent elimination forms (e.g. J eliminator
% for the identity type). In particular, the inclusion of identity
% types, which is absent from \citet{decagda}, \citet{nbeincoq},
% helps demonstrate how indexed types are handled when defining the
% logical relation.

% % We choose boolean
% % types over natural numbers as our base type for simplicity, but include an
% % intensional identity type in our type system to show how indexed
% % types are treated in a logical relational proof. \scw{Talk about
% % identity type first.} Unlike
% % \citet{nbeincoq,decagda,martin-lof-a-la-coq} but similar to
% % \citet{anand2014towards}, we include an infinite hierarchy of
% % universes to not only support type-level computations, but also avoid
% % the unnecessary code duplication pointed out by \citet{nbeincoq} when
% % big and small types are treated non-uniformly.

% In Section~\ref{sec:logrelproof}, we use the standard technique that
% is commonly seen in ...

% Our consistency proof is short and fully mechanized. The proof scripts
% involve less than 1000 lines of manually written Coq code. In fact, what we find
% encouraging is that among the 1000
% lines of Coq code, 400 lines are related to the specification of the
% type system, semantics, and properties related to untyped lambda
% terms. The semantic type soundness proof through logical relation
% takes almost the same amount of code as our syntactic type soundness
% proof!
% Thanks to the conciseness of
% the proof, we are able to present it in detail in
% Sections~\ref{sec:logreldep} and \ref{sec:logrelproof}. Moreover, the
% structure of our mechanization closely corresponds to the proof we
% present in the text, enabling us to label at the footnote each lemma
% directly to their counterpart in the proof script for the readers to
% reference and validate.

% The technique we use is most similar to the one from \citet{nbeincoq},
% which leverages impredicativity to define the logical
% relation as a partial function.
% Rather than framing impredicativity as a
% mechanism for encoding induction
% recursion~\citep{induction-recursion-dybjer}, a scheme in which
% semantic models (including logical relations) for dependent types can
% be defined, we opt for a direct explanation through the informal
% language of sets, where impredicativity manifests in the form of
% second-order logical formulas and thus more intuitive to grasp
% for readers with a general mathematical background.

% A naive attempt at proving consistency through induction over the
% typing derivation would fail since the inductive hypothesis is not
% strong enough to derive the consistency result. Instead, one typically
% relies on the technique referred to as proof by logical relation to
% interpret types as reducibility predicates to strengthen the inductive
% hypothesis.




% This paper is specifically
% about establishing logical consistency for a fully dependently typed
% system with an infinite universe hierarchy and support for large
% elimination .
% The type system, presented in Section~\ref{sec:spec}, is
% most similar to Martin-Lof's predicate type theory with the minor
% difference that type conversion is based on untyped equality.


% Rather,
% our goal is to present the proof in a form that is digestable by a
% working type theorist and can be more readily mechanized in a proof
% assistant. Compared to existing efforts at mechanizing logical
% consistency or stronger properties such as existence of normal
% form~\citep{nbeincoq},
% decidable type checking~\citep{decagda}, our work is minimal since it requires very
% little scaffolding and therefore results in an extremely succinct
% proof of under 1000 lines of manually written Coq code for a dependent
% type theory that is reasonably complete in its features.

% The key technique that underlies our consistency proof is proof by
% logical relation. In
% Section~\ref{sec:spec}, we present the dependent type theory of
% interest. In Section~\ref{sec:logreldep}, we give the definition
% of the logical relation for the dependent type theory. Rather than
% presenting the logical relation as an inductive-recursive definition,
% we use the more elementary concept of a partial function to capture
% the interpretation of types. The alternative representation requires us
% to show that the set of equations indeed defines a partial function;
% that is, for each input, there should always be a unique
% output.
% From the interpretation function, we can define the semantic
% typing judgment for the set of lambda terms.
% In Section~\ref{sec:logrelproof}, we prove the fundamental theorem,
% which states that syntactic typing implies semantic typing. Once the
% fundamental theorem is established, logical consistency follows as a
% trivial corollary. In Section~\ref{sec:logrelmech}, we point out the
% specifics related to the Coq mechanization of the proof described in earlier
% section.
% Finally, in Section~\ref{sec:relatedwork}, we give a short survey of
% existing literature related to logical consistency about dependent
% type theory.


\section{Specification of a Dependent Type Theory}
\label{sec:spec}

\scw{This section needs to say:
  \begin{itemize}
\item definitional equality is untyped so that we can prove
  properties about it independent of the type system
\item definitional equality is based on parallel reduction so that we can take
  advantage of the algorithmic structure later. This definition is easier to
  invert because there are fewer derivation. That is important when reasoning
  about our logical relation.
\item can prove that parallel reduction is equivalent to other definitions of
  equality using standard means (cite Barendregt's book).  (we go halfway
  there by showing it is an equivalence relation). Can also prove equivalent
  to typed relation. (cite Siles, also CoreSpec?)
\item All of the proofs in this section are standard, well known, and use
  techniques that are well-suited for proof assistants. In fact, de Bruijn's
  paper that introduces de Bruijn indices was part of a mechanized confluence
  proof for the untyped lambda calculus.
\item extensions: forward reference to eta equivalence for functions in later
  section. type-directed equivalence is future work
  \end{itemize}
}

\begin{figure}[h]
\[
\begin{array}{lcll}
% \mathit{Natural\ numbers}\\
% [[i]],[[j]],[[n]] & \in &  [[SNat]] &  \\ \\
\mathit{Terms}\\
[[a]],[[b]],[[c]],[[p]],[[A]],[[B]] & ::= & [[Set i]]\ |\ [[var n]]\  |\ [[Void]]
                  & \mbox{universes, variables, empty type} \\
            & |   & [[Pi A B]]\ |\ [[\ a]]\ |\ [[a b]]
                  & \mbox{function types, abstractions, applications} \\
            & |   & [[a ~ b : A ]]\ |\  [[refl]]\ |\ [[J c a b p]]
                  & \mbox{equality types, reflexivity proof, J eliminator} \\
            & |   & [[Bool]]\ |\  [[true]]\ |\  [[false]]\ % |\  [[if a b0 b1]]
                  & \mbox{boolean type, true, false} \\
            & |   & [[if a b0 b1]]
                  & \mbox{conditional expression} \\ \\
% \mathit{Renaming}\\
% [[xi]] & \in & [[SNat -> SNat]] & \\ \\
\mathit{Substitutions}\\
[[rho]] & \in & [[SNat -> STm]] & \\ \\
\mathit{Typing Contexts}\\
 [[G]]       & ::= & [[empty]]\ |\ [[G ++ A]] &  \\ \\
\end{array}
\]
  \caption{Syntax of \lang \scw{Where does the name come from?}\yl{H =
    hierarchy though it needs a better name}}
  \label{fig:syntax}
\end{figure}


In this section, we present the dependent type theory whose logical
consistency will be proven in Section~\ref{sec:logrelproof}. For conciseness,
we refer to this system as \lang.

The syntax of \lang can be found in Figure~\ref{fig:syntax}.  As a dependent
type theory, terms and types are collapsed into the same syntactic
category. The type $[[Set i]]$ represent universe types and $[[var n]]$
represent de Bruijn variables~\cite{debruijn}.  While $[[i]],[[j]],$ and
$[[n]]$ are all metavariables representing natural numbers, we always use
$[[i]],[[j]]$ to represent universe levels and $[[n]]$ to represent term
variables.  We use de Bruijn indices for both our Coq development and the
informal presentation here because it is more amenable to automation
(Section~\ref{sec:automation}) and leaves no ambiguity about variable freeness
conditions. As a result, variables do not appear in binding forms, such as in
abstractions $[[ \ a ]]$ and dependent function types $[[Pi A B]]$.  This latter
form binds a new variable of type $[[A]]$ that can appear in the codomain of
the type $[[B]]$.  We use the notation $[[A -> B]]$ when the output type
$[[B]]$ is not dependent on the input variable.
We include in \lang{} the intensional identity type
$[[a ~ b : A]]$ whose proofs can be eliminated by the J-eliminator
$[[J c a b p]]$, where $[[p]]$ is an equality proof between $[[a]]$ and
$[[b]]$, and $[[c]]$ is the term whose type is to be casted.
Finally, \lang{} includes booleans, with standard syntax.
\scw{Example of
 what you can use identity types for? Or an example of a program that uses
J?}

% We find de Bruijn
% representation advantageous for specification since it leaves very
% little ambiguity about the variable freeness side
% conditions, making our proof more easily reproducible. Furthermore, as we discuss in
% Section~\ref{sec:automation}, de Bruijn representation is much more
% amenable to automated reasoning in proof assistants.

% \scw{Need to explain the notations in the text. What are these operations?
% What do readers need to understand about them? Help me understand
% the figure} \yl{resolved}
% \scw{As this is a tutorial paper, you'll need to explain more about how de Bruijn
% indices work.} \yl{resolved?}
% We omit most of the
% definitions of renaming and substitution and only show the definition
% of a few representative cases of substitution.
\begin{figure}[ht]
  \begin{equation*}
    \begin{split}
      \begin{array}{lll}
        % \mathit{IdentityRen} \\
        % [[id i]] & := & [[i]] \\ \\
        \multicolumn{3}{l}{\mbox{\emph{Identity substitution: }} \mathsf{id}_{\mathit{tm}}} \\
        [[idtm n]] & := & [[var n]] \\ \\
        \multicolumn{3}{l}{\mbox{\emph{Weakening substitution: }} \uparrow^{n}} \\
        [[up n m]] & := & \ottkw{v}_{[[n]] + [[m]]} \\ \\
        %
        % \mathit{ConsRen ([[xi .: n]])} \\
        % ([[xi .: n]])([[0]]) & := & [[n]] \\
        % ([[xi .: n]])([[Suc i]]) & := & [[xi i]] \\ \\
        %
        \multicolumn{3}{l}{\mbox{\emph{Extension operation: }} ([[rho .: a]]) } \\
        ([[rho .: a]])([[0]]) & := & [[a]] \\
        ([[rho .: a]])([[Suc n]]) & := & [[rho n]] \\ \\
      \end{array}
    \end{split}
    \qquad \qquad
    \begin{split}
      \begin{array}{lll}
        \multicolumn{3}{l}{\mbox{\emph{Lifting operation: }} \Uparrow\rho} \\
        [[( up rho ) 0]] & := & [[var 0]] \\
        [[( up rho ) Suc n]] & := & [[ rho n < up 1 > ]] \\ \\
        \multicolumn{3}{l}{\mbox{\emph{Substitution operation:}} ([[ a { rho } ]])} \\
        [[var n { rho }  ]] & := &  [[rho n]] \\
        [[(Pi A B) { rho }]] & := & [[Pi A { rho } B { up rho }]] \\
        [[(a b) { rho }]] & := & [[a { rho } (# b { rho } #)]] \\
        [[(\ a) { rho }]] & := & [[\ (a { up rho })]] \\
        \ldots
      \end{array}
    \end{split}
  \end{equation*}
  \caption{Auxiliary Functions over Syntax}
  \label{fig:auxdef}
\end{figure}


% Without providing
% the full definition of the renaming and substitution functions, it is
% impossible to tell the binding structure from the syntax
% alone. Therefore, we annotate the syntax in Figure~\ref{fig:syntax}
% with the de Bruijn depth of each term, though we note that the
% syntax we work with is unscoped and the choice does matter when
% we extend our logical relation to open terms in Section~\ref{sec:extension}.

% Figure~\ref{fig:auxdef} shows the auxiliary definitions over the term
% syntax, including renaming, substitution, and operations over
% the typing context or substitution.

The \lang language is expressive enough to support large
eliminations, the ability to compute a type using a term as input. For
example, the function $[[\ if var 0 Bool Bool -> Bool]]$ returns
either $[[Bool]]$ or $[[Bool -> Bool]]$ depending on whether the input
is $[[true]]$ or $[[false]]$.

We adapt from \citet{autosubst2} the notations for simultaneous renaming,
substitution, and other auxiliary definitions used in our paper, summarized in
Figure~\ref{fig:auxdef}. We need these definitions to specify the reduction
and typing relations for \lang{}. The metavariable $[[rho]]$ represents
substitutions, which are mappings from de Bruijn indices to terms.  One
example of a substitution is the function $\ottkw{id}_{tm}$, the identity
substitution that maps each index to the corresponding term variable.  The
$\uparrow^{[[n]]}$ substitution is more general and adds $[[n]]$ to the index
before injecting it as a term. The extension operation, $[[(rho .: a)]]$,
allows us to extend a substitution $[[rho]]$ with an extra element $[[a]]$;
the result maps the variable $[[var 0]]$ to $[[a]]$ and variables
$[[var Suc i]]$ to $[[rho i]]$.

The substitution operator, which takes the form $[[a {rho}]]$,
traverses the syntax of $[[a]]$ and replaces each variable $[[var i]]$
with the term $[[rho i]]$. When traversing under binders (e.g. in the
$[[(\ a) { rho }]]$ case), the $\Uparrow$ operator prevents $[[var
0]]$, the bound variable, from being replaced by
$[[rho]]$. From the definition of $[[up rho]]$, we see that it keeps
$[[var 0]]$ unchanged during substitution and replaces each $[[var
Suc i]]$ with $[[rho i {up 1}]]$. The shifting with $[[up 1]]$
is required so the variables in terms from the codomain of $[[rho]]$ skip over
the newly introduced binder to refer to the correct binding
location.

The substitution operator is referred to as simultaneous substitution as it
substitutes for all variables at once. It is possible to recover single
substitution by composing the extension operator and the identity
substitution: $[[a { b }]] := [[a { idtm .: b }]]$. In our proofs, we find it
more convenient to formulate simultaneous substitution directly rather than
recovering it from single substitution.  In particular, this shows up in the
definition of semantic typing in Section~\ref{sec:logrelproof}, which relies
on simultaneous substitution.

\subsection{Definitional equality via parallel reduction}

\begin{figure}[h]
\begin{minipage}{0.9\textwidth}
\drules[P]{$[[a => b]]$}{Parallel Reduction}{AppAbs, IfTrue, IfFalse, JRefl}
% \drules[PS]{$[[a =>+ b]]$}{Transitive Closure of Parallel Reduction}{Refl, Step}
% \drules[C]{$[[a <=> b]]$}{Convertibility}{Intro}
\end{minipage}
\caption{Parallel reduction ($\beta$-rules only) }
\label{fig:par}
\end{figure}

% \scw{motivate parallel reduction. Why are you telling us this now. Is this
%   an explanation of definitional equality and its properties?}
Before we specify the typing rules, we first specify the equational theory
used in its conversion rule (\rref{T-Conv} in Figure~\ref{fig:typing}). This
relation is often called ``definitional equality'' in dependent type theories
because it defines the equivalence that the syntactic type system works
``up-to''.

For \lang{}, we use an untyped equational theory, defined in an algorithmic
style using the notion of parallel reduction, written $[[a => b]]$, and shown
in Figure~\ref{fig:par}. (For brevity, reflexivity and congruence rules are
omitted from this figure). The notation $[[a =>+ b]]$ indicates the transitive
closure of parallel reduction.

\begin{definition}[Convertibility]
  Two terms $[[a0]]$ and $[[a1]]$ are \emph{convertible}, written
  $[[a0 <=> a1]]$, if there exists some term $[[b]]$ such that $[[a0 =>+ b]]$
  and $[[a1 =>+ b]]$.
\end{definition}

Convertibility is an equivalence relation. We sketch the sequence of lemmas
required to derive this property below and omit the details. The key step in
proving transitivity, is showing that parallel reduction satisfies the diamond
property.  Our technique for proving the properties about parallel reduction
is based on \citet{takahashi-parallel-reduction}. A modern exposition of the
same technique can be found in \citet{plfa22.08}.

\begin{lemma}[Par Refl\footnote{\dotv{join.v}{Par\_refl}}]
  \label{lemma:parrefl}
  For all terms $[[a]]$, $[[a => a]]$.
\end{lemma}
\begin{lemma}[Par cong\footnote{\dotv{join.v}{par\_cong}}]
  \label{lemma:parcong}
  If $[[a0 => a1]]$ and $[[b0 => b1]]$, then $[[a0 { b0 } => a1 { b1 }]]$.
\end{lemma}
\begin{corollary}[Par subst\footnote{\dotv{join.v}{par\_subst}}]
  \label{lemma:parsubst}
  If $[[a0 => a1]]$, then $[[a0 {b} => a1 {b}]]$ for arbitrary $[[b]]$.
\end{corollary}
\begin{lemma}[Par diamond\footnote{\dotv{join.v}{par\_confluent}}]
  \label{lemma:pardiamond}
  If $[[a => b0]]$ and $[[a => b1]]$, then there exists some term
  $[[c]]$ such that $[[b0 => c]]$ and $[[b1 => c]]$.
\end{lemma}
\begin{lemma}[Convertibility refl\footnote{\dotv{join.v}{Coherent\_reflexive}}]
  \label{lemma:coherencerefl}
  For all terms $[[a]]$, $[[a <=> a]]$.
\end{lemma}
\begin{lemma}[Convertibility sym\footnote{\dotv{join.v}{Coherent\_symmetric}}]
  \label{lemma:coherencesym}
  If $[[a <=> b]]$, then $[[b <=> a]]$.
\end{lemma}
\begin{lemma}[Convertibility trans\footnote{\dotv{join.v}{Coherent\_transitive}}]
  \label{lemma:coherencetrans}
  If $[[a0 <=> a1]]$ and $[[a1 <=> a2]]$, then $[[a0 <=> a2]]$.
\end{lemma}
% From Lemmas~\ref{lemma:coherencerefl}, \ref{lemma:coherencesym}, and
% \ref{lemma:coherencetrans}, we conclude that convertibility is indeed an
% equivalence relation.

Our definition of convertibility for \lang{} is unusual in that it is directly
defined via parallel reduction, instead of using the related notion of
$\beta$-equivalence~\cite{barendregt:pts,cic}. This choice does not change the
language definition; a detailed argument of the equivalence between
$[[a <=> b]]$ and untyped $\beta$-equivalence can be found in
\citet{barendregt:lambda-calculi-with-types} and
\citet{takahashi-parallel-reduction}. However, this choice simplifies later
proofs, as we discuss in Section~\ref{XXX}. \scw{Forward reference to further
  discussion, comparing with whnf reduction?}

Our definition of equality is untyped: the judgement does not require the two
terms to type check and have the same type. The use of an untyped relation for
type conversion is reminiscent of Barendregt's Pure Type
Systems~\citet{barendregt1991introduction} and makes our formulation different
from languages such as MLTT~\citep{Martin-Lof-1973}, where the judgmental
equality takes the form $\Gamma \vdash a \equiv b : A$, from which one can
usually derive $[[G |- a : A]]$ and $[[G |- b : A]]$ after proving subject
reduction. By working with an untyped judgement, we can establish its
properties independently from the type system and the logical relation, using
well-established syntactic approaches.

\citet{siles2012pure} shows the equivalence of Barendregt's Pure Type
System~\citep{barendregt1991introduction}, which employs untyped equality, and
its variant that uses typed judgmental equality. This assures us that we do
not lose generality working with a system with untyped
conversion. Furthermore, discuss how this definition can be extended with
$\eta$-equivalence of functions in Section~\ref{XXX}. Finally, we compare this
definition with type-directed approaches to equality in
Section~\ref{sec:discuss}.


\subsection{Syntactic Typing}

\begin{figure}[h]
\begin{minipage}{0.9\textwidth}
\drules[Ctx]{$[[ |- G]]$}{Context Well-Formedness}{Empty, Cons}
\drules[T]{$[[G |-  a : A]]$}{Typing}{Var, Set, Pi, Abs, App, Conv,
  Eq, Refl, J, If, Bool, True, False, Void}
\end{minipage}
\caption{Syntactic typing for \lang}
\label{fig:typing}
\end{figure}

Figure~\ref{fig:typing} gives the full typing rules for \lang{}. The premises
wrapped in \colorbox{lightgray}{gray} boxes can be shown to be admissible
syntactically, though some of them are required to strengthen the inductive
hypothesis of the fundamental theorem.

In \rref{T-Var}, $[[G n]]$ is the partial function defined by the equations
$[[ (G ++ A) 0 ]] := [[A]]$ and $[[ (G ++ A) Suc n ]] := [[G n]]$.  The
precondition $[[n < | G | ]]$, where $[[ | G | ]]$ represents the length of
the context $[[G]]$, ensures that $[[G n]]$ has a defined output. The type
$[[G n]]$ needs to be shifted by $[[Suc n]]$ since the types stored in the
context $[[G]]$ are scoped differently. In the typing judgment
$[[G |- a : A]]$, we want both $[[a]]$ and $[[A]]$ to have the same
scope. However, the closer a type is to the head of $[[G]]$, the smaller de
Bruijn it has since there is less variables in the context it can refer to
(see \rref{Ctx-Cons}). Shifting $[[G n]]$ by $[[Suc n]]$ weakens the type so
it is scoped consistently with the full context $[[G]]$ rather than a
truncated version of $[[G]]$.

Although the use of de Bruijn indices complicates the variable rule, the rules
that involve binding, such as \rref{T-Pi,T-Abs} are straightforward.

\Rref{T-Conv} uses the convertibility relation from earlier
as our equality judgment for type conversion.

The elimination form for booleans, \rref{T-If} demonstrates dependent pattern
matching.  The result type of this expression $[[A {a}]]$, is composed of some
\emph{motive} $[[A]]$, a type where its single free variable has been replaced
with the condition of the if expression. When typing the true branch, this
substitution replaces the variable by $[[true]]$, and similar for the false
branch. As a result, the type system communicates the information gained from
the run-time test to each of the branches of the expression.

A similar sort of dependent pattern matching occurs when eliminating identity
types. Such types are checked for well-formedness with \rref{T-Eq} and
introduced by \rref{T-Refl}. In \rref{T-J}, the elimination form, the subterm
$p$ is a proof of an equality between $[[a]]$ and $[[b]]$. The subterm $[[c]]$
is the body of the elimination form. In this rule, $[[B]]$ is called a
\emph{motive} and has two free variables.  The substitution for these
variables changes from $[[b]]$ to $[[a]]$ and from $[[p]]$ to $[[refl]]$,
witnessing the information gained through dependent pattern matching.  In the
typing rule, the terms $[[a]]$ and $[[A]]$ need to be shifted in the context
for a similar reason; an extra type $[[A]]$ appears after the $[[G]]$ and
therefore the terms $[[a]]$ and $[[A]]$ in the identity type both need to be
shifted to refer to the same binders.


% As a result, there is no loss of generality from

% It is trivial to embed a system with judgmental
% equality to a system with untyped equality by erasing typing
% information. As a result, it is easy to port our consistency result from our
% type system to a variant with typed judgmental equality
% as long as the typed system does not include $\eta$ laws
% that would require type annotations (e.g. the $\eta$-law for unit
% types).
% and we discuss in Section~\ref{sec:extension} how we can extend
% our proof to handle those rules.
% \scw{Maybe move more of this paragraph and the next to the discussion/related
%   work section, and add a forward pointer here.}
% \scw{Just say that like Coq, the definition of the system uses untyped
% equality}

% Working with a system with untyped equality has the huge benefit that
% the confluence result for untyped parallel reduction
% (Lemma~\ref{lemma:pardiamond}) is easily derivable without having to
% resort to the complex syntatic (resp. semantic) technique from
% \citet{siles2012pure} (resp. \citet{decagda}) to resolve
% the circularity of subject reduction and $\Pi$-injectivity.
% Section~\ref{sec:extension} explains how we
% generalize our technique to include $\eta$-law for functions and
% show the existence of normal form for well-typed (open and closed)
% terms, achieving a similar level of expressiveness of the type system
% and strength of metatheoretic property as \citet{decagda}.

% Finally, since our system has an infinite universe hierarchy, we can
% present the system Ã  la Russell by using the same judgment form
%$[[G |- a : A]]$ regardless of whether $[[a]]$ is a term or a type. There
% is no need to distinguish between big types and small types
% and duplicate our typing specification.
% \scw{Is there an advantage for Tarski universes even with infinite
% hierarchy? or no?}


% , the
% statement that $\Gamma \vdash [[Pi A0 B0]] \equiv [[Pi A1 B1]]$
% implies $\Gamma \vdash [[A0]] \equiv [[A1]]$ and
% $\Gamma, [[A0]]\vdash [[B0]] \equiv [[B1]]$.



% working with a system with untyped equality not only preserves the
% same level of generality,
% Of course,
% but also enables us to derive confluence
% (Lemma~\ref{lemma:parconfluent}) early on without having to use the
% intricate techniques from \citet{lemma:}







% TODO, where terms ... and ... are known to be
% well-typed. The equivalence of such systems and a system that uses
% untyped equality are explored in detail in ...

% Without fancy eta laws, it is easy to embed a typed language into an
% untyped language.


% We note that a more conventional presentation of
% \rref{T-Conv} would instead use full beta reduction as the base for
% the definition of coherence. However, since full beta reduction
% doesn't satisfy the diamond property, one typically needs parallel
% reduction as an auxilliary definition to derive the confluence of full
% beta reduction. Our formulation of \lang through parallel reduction
% is slightly more economical.

\section{Logical Relation}
% \scw{This section pre-supposes that we want to define a logical relation,
% but doesn't precisely state what we want to use it to prove, and why a logical
% relation is suitable. (And why the property you want to prove is difficult to
% show!) Should add more motivation here.}
\scw{We need to explicitly point out that the key ideas of this paper are
  discussed, here, in this section.
  We need to explicitly remark on why logical relations are difficult to
  define for dependent type theory and explain why this setting is more
  difficult than with simple types (STLC) or with polymorphic types (System F).
  \begin{itemize}
  \item Dependent function types (result type mentions argument value, so can't define
    relation by recursion over type structure)
  \item Definitional equality (not all types look like types)
  \item Identity types(?)
  \end{itemize}
  Should we be more explicit in our comparison with Girard's trick for polymorphic type?
  There, the definition stays recursive because it doesn't substitute for the variables
  in the function types. But that approach is not available in this setting, because not
  all quantified things are types. And we might need that information to interpret, say,
  identity types in the right way.
}
\yl{I don't think identity types and dependent function types should
  be listed as reasons why the logrel can't be a recursive
  function. System DE has both dependent function types and identity
  types but the logical fragment doesn't have type-level computation
  so it can be defined structurally by specifying some kind of size metric
}
\scw{ We also need to explicitly point out that our logical relation is untyped.
  This has two benefits: it allows semantic typing to be meaningful independent from
  syntactic typing (cite Derek, forward reference to next section) and it avoids
  significant bookkeeping, especially in the case of Kripke logical relations (we need to define
  what these are).
  Is there a cost to an untyped relation?
}

Before we define our logical relation, we first formally specify the
consistency property that we want to prove.
\begin{theorem}[Logical Consistency]
  \label{theorem:consistency}
  The judgment $[[empty |- a : Void ]]$ is not derivable.
\end{theorem}
The property can be formulated in a simply typed language, where
$[[Void]]$ is similarly defined as a type that has no term. A related
property, referred to as the termination property (for closed terms),
is commonly used in introductory materials such as
\citet{skorstengaard2019introduction}, \citet{pierce2002types}, and
\citet{harpertait} to motivate the need for a logical relation.

A naive attempt to proving Theorem~\ref{theorem:consistency} by
induction on the derivation $[[empty |- a : Void]]$ would succeed at
almost all cases except for \rref{T-App}. In the application
case, we are given $[[empty |- b : Pi A B]]$ and $[[empty |- a : A]]$, and
the equality that $[[B {a} = Bool]]$. Our goal is to show that
$[[empty |- b a : Void]]$ is not possible. However, note that there is
nothing we know of $[[b]]$ or $[[a]]$ from the induction hypothesis
because neither $[[Pi A B]]$ nor $[[A]]$ is equal to $[[Bool]]$.
We have no way of deriving a contradiction from $[[empty |- b a :
Void]]$. The takeaway from this failed attempt is that, in order to
derive the consistency, we need to know something about types other
than $[[Void]]$. From a pragmatic point of view, proof by logical
relation can be seen as a sophisticated way of strengthening the
induction hypothesis. From the strengthened property, the fundamental
theorem, we will be able to derive consistency as a corollary.

The complexity of applying proof by logical relation to dependent types stems
from the fact that the logical relation is much harder to define. In
simply typed languages, the logical relation is defined as a recursive
function over the type $[[A]]$.
In dependent types, the type
$[[A]]$ can take the form $[[(\ var 0) Bool]]$. To assign meaning to
this type, we need to first reduce it to $[[Bool]]$. However, we
cannot write a function that performs the reduction because we do not
know the termination of well-typed terms a priori. As a result, we
define the logical relation as an inductively defined relation,
reminiscent of how we specify the reduction graph of a partial
function; the functionality of the relation can later be recovered in Lemma~\ref{lemma:logreldeter}.

\subsection{Definition of the Logical Relation}
\label{sec:logreldep}
\begin{figure}[h]
\drules[I]{$[[Interp I i A S]]$}{Logical Relation}{Void, Bool, Eq, Pi, Set, Red}
\caption{Logical relation for \lang}
\label{fig:logrel}
\end{figure}
The logical relation for \lang{}, which takes the form $[[Interp I i A
S]]$, is defined as an inductively generated relation (Figure~\ref{fig:logrel}).
% The logical relation takes the form $[[Interp I i A S]]$.
Metavariables $[[A]]$ and $[[i]]$ stand for terms and natural
numbers respectively, as introduced earlier in
Figure~\ref{fig:syntax}.
% \scw{Many introductory texts define the relation as a recursive function
% over type structure, or step-indices. You use an inductive relation instead, why?}
%\yl{resolved}
% \scw{Can we view this inductive relation as the graph of the partial function
% that is defined recursively over types?} \yl{reolsved}
% \scw{What is this form extensible too? impredicative quantification? recursive
% types? } \yl{resolved? impredicativity is hard}
\scw{Is it worth observing here that this definition is not over sets of typed
terms. That it characterizes all terms that look like booleans (i.e. evaluate to
true or false) or all terms that look like proofs (i.e. evaluate to refl). The
fact that there is no connection between p and a and b in the I-Eq case is strange
looking. Need to explain.  }
The metavariables $[[I]]$ and $[[S]]$ are
sets with the following signatures.
\begin{equation*}
  \begin{split}
    [[I]] &\in [[ { j | j < i  } ->  PowerSet STm ]] \\
    [[S]] &\in [[PowerSet STm]]
  \end{split}
\end{equation*}
The notation $[[PowerSet STm]]$ denotes the powerset of the set of
\lang{} terms.
The function $[[I]]$ is a family of sets of terms indexed by
natural numbers strictly less than the parameter $[[i]]$, which
represents the current universe level.  In \rref{I-Set}, function
$[[I]]$ is used to define the meaning of
universes that are strictly smaller than the current level $[[i]]$. The
restriction $[[j < i]]$ in \rref{I-Set} is crucial for our system to
be predicative and we will explain the reason shortly.

To tie the knot and obtain an interpretation of all universe levels,
we define in Figure~\ref{fig:logrelrec} the final version of our interpretation judgment recursively
using the well-foundedness of $<$ relation on natural
numbers (recall that
the parameter $[[I]]$ of $[[Interp I i A S]]$ takes only natural
numbers strictly less than $[[i]]$ as its input).
The judgment $[[InterpR i A S]]$ now reads that the type $[[A]]$ is a
level-$[[i]]$ type \emph{semantically} inhabited by terms from the set
$[[S]]$.

\begin{figure}[h]
\begin{equation*}
    [[InterpR i A S]] := [[ Interp I i A S  ]], \text{where } [[I j]]
    := [[{A | exists S , InterpR j A S}]] \text{ for } [[j < i]]
\end{equation*}
\caption{Logical relation for all universe levels}
\label{fig:logrelrec}
\end{figure}
The definition of in Figure~\ref{fig:logrelrec} explains how the $[[j
< i]]$ constraint in \rref{I-Set} makes our system predicative; the
interpretation of the $[[i]]_{th}$ universe is only dependent on
universes strictly lower than $[[i]]$, which have been defined earlier.
Removing the ordering constraint would result in a
system where one can encode Girard's
paradox~\citep{girard-thesis}. Our proof would no longer work with the
restriction removed since the definition of $[[InterpR i A S]]$ would
not be well-founded when $[[Interp I i A S]]$ calls $[[I]]$ on
universe levels greater than or equal to $[[i]]$, which are yet to be defined.

By unfolding the definition in Figure~\ref{fig:logrelrec}, we
show that the same introduction rules for $[[Interp I i A S]]$ are
admissible for $[[InterpR i A S]]$, by
instantiating $[[I]]$ with $[[I i]] := [[{A | exists S , InterpR i A
  S}]]$, the same function $[[I]]$ used in the definition of $[[InterpR i A
S]]$. We give as example the following rules.
\begin{center}
\drule[]{IR-Void} \qquad \drule[]{IR-Set}
\end{center}

In most informal presentations, instead of defining the logical
relation in two steps as we have shown above, the rules for $[[InterpR
i A S]]$ are given directly, with the implicit understanding that the
relation is an inductive definition nested inside a recursive
function over the universe level $[[i]]$. We choose
the more explicit definition not only because it is directly definable
in existing proof assistants where inductive definitions must appear
at the top level, but also because it makes clear the induction
principle we are allowed to use when reasoning about $[[InterpR i A
S]]$.

% The paragraph below might be useful but I don't know how to phrase
% it well

% The most general format of the induction principle over
% $[[InterpR i A S]]$ is first by strong induction over the universe level $[[i]]$
% followed by structural induction over $[[Interp I i A S]]$. As
% examples, ... (\rref{I-Set} and \rref{I-Red}).

For the majority of the properties we are about to prove in this section, we
do not need any information about the parameterized function $[[I]]$.
Each property about $[[InterpR i A S]]$ follows as a corollary of
a property about $[[Interp I i A S]]$ with no or few assumptions imposed on
$[[I]]$. As a result, we usually state our lemmas in terms of
$[[Interp I i A S]]$ without duplicating them in terms of $[[InterpR i
A S]]$.

% To derive consistency, it suffices to restrict $[[S]]$ to the set of
% terms that reduce to closed terms.
\Rref{I-Void, I-Bool} capture terms that \emph{behave like} the inhabitants
of the $[[Void]]$ and $[[Bool]]$ types under an empty context. For
example, the $[[Void]]$ type should not have any inhabitants under the
empty context, where as the $[[Bool]]$ type corresponds to terms that
evaluate to $[[true]]$ or $[[false]]$. However, the characterization
of $[[Bool]]$ in our logical relation does not always correspond to
well-typed or even closed terms. For example, we have $[[if false var 0
true]]$ is ill-typed under the empty context but still belongs to the set $[[{ a | a =>+
  true \/ a =>+ false }]]$ since it evaluates to $[[true]]$.
The independence of syntactic typing in our logical relation allows
our semantic typing definition in Section~\ref{sec:logrelproof} to be
meaningful on its own. Furthermore, not having to embed scoping
information into the logical relation avoids extra bookkeeping and the
need for a Kripke-style logical relation.
\yl{Not sure what to cite from Derek Dreyer. I know his blog post
  about semantic type soundness but is there a good paper to cite? one
of the rust papers?}

% unsurprising; when considering only closed terms, the empty type
% should not be inhabited and therefore corresponds to the empty set,
% whereas the boolean type is semantically inhabited by terms that
% evaluate to the boolean values $[[true]]$ or $[[false]]$.
\Rref{I-Eq}
says that an equality type $[[a ~ b : A]]$ corresponds to the
set of terms that evaluate to $[[refl]]$ when $[[a <=> b]]$ holds and
otherwise corresponds to the empty set. Side conditions like $[[a <=>
b]]$ are typically required for indexed types, of which equality types
are an instance. \Rref{I-Red} enables us to reduce our types in order
to assign meanings. Recall the type expression $[[(\ var 0)
Bool]]$. \Rref{I-Red} says to know that
$[[Interp I i  (\ var 0) Bool S ]]$ for some $[[S]]$, it suffices to
show that $[[Interp I i Bool S]]$ since $[[(\var 0) Bool =>
Bool]]$. The derivation that $[[Interp I i (\ var 0) Bool { a | a =>+
  true \/ a =>+ false }]]$ therefore follows by composing \rref{I-Red}
and \rref{I-Bool}.


\Rref{I-Pi} is the most complicated rule in our logical
relation. Instead of explaining it directly, we consider the following
simplified admissible \rref{I-PiAlt} that follows directly from \rref{I-Pi}.
\begin{center}
  \drule[]{I-PiAlt}
\end{center}
\begin{lemma}[I-PiAlt admissibility]
  \label{lemma:piintroalt}
  \Rref{I-PiAlt} is admissible.
\end{lemma}
\begin{proof}
Immediate from \rref{I-Pi} with $[[R]]$ instantiated to the relation $[[{ (a
, S0 ) | a in S , Interp I i B { a } S0 }]]$.
\end{proof}
Compared to the \rref{I-Pi}, which contains the mysterious relation
$[[R]]$, \rref{I-PiAlt} directly captures the meaning of
a well-behaved dependent function type. The precondition of
\rref{I-PiAlt} says that
the function type $[[Pi A B]]$ has an interpretation if its input
type $[[A]]$ can be
interpreted as some set $[[S]]$, and for all terms $[[a in S]]$, the
type $[[B {a}]]$, obtained by substituting $[[a]]$ into the output type
$[[B]]$, has some semantic interpretation. In its conclusion, we say
that a term $[[b]]$ belongs to an interpretation of $[[Pi A B]]$ if
for all $[[a in S]]$, where $[[S]]$ is an interpretation $[[A]]$, the
application form $[[b a]]$ belongs to all possible interpretations of
$[[B {a}]]$ (the pre-condition ensures at least one interpretation
exists for each $[[B {a}]]$ where $[[a in S]]$).

In fact, while \rref{I-PiAlt} is an instantiation of \rref{I-Pi},
these two rules are equivalent in the sense that every derivation of
involving \rref{I-Pi} can be systematically replaced by
\rref{I-PiAlt}. This equivalence follows directly from the fact
that the logical relation is a partial function, a result we will show
in Lemma~\ref{lemma:logreldeter}. The preconditions of \rref{I-Pi},
when combined with the functionality of the logical relation, uniquely
determine the relation $[[R in S * PowerSet STm]]$ to be the relation
$[[{ (a , S0 ) | a in S , Interp I  i B { a } S0 }]]$. This result is
formally shown through the improved inversion lemma for function types
(Lemma~\ref{lemma:piinvalt}).

Unfortunately, we cannot define the function case of our logical
relation directly using \rref{I-PiAlt} since the occurrence of
$[[Interp I i B {a} S0]]$ in its conclusion not only violates the
syntactic strict positivity constraint required in proof assistants,
but is genuinely non-monotone when we rewrite the inductive definition
as an endofunction over the domain of relations.
Intuitively, the failure of monotonicity stems from the fact
that the witness picked in the precondition is not necessarily the
same witness being referred to in the post condition as the relation
grows, whereas the
relation $[[R]]$ in \rref{I-Pi} ``fixes'' the witnesses $[[S0]]$ and
prevents the set of witnesses from growing. While it might
be possible to restrict the domain with additional constraints such as
functionality and inversion properties to justify the well-definedness of our
inductive relation with \rref{I-PiAlt}, we opt for our current
formulation of \rref{I-Pi} so we immediately obtain a
well-defined inductive relation and a usable induction principle. The
slight disadvantage of \rref{I-Pi} is that we need to construct the
function $[[R]]$ each time we apply it, though this is mitigated by
the immediate admissibility of \rref{I-PiAlt} and the alternative $\Pi$ inversion
principle (Lemma~\ref{lemma:piinvalt}), which we derive after proving functionality.


\subsection{Properties about the Logical Relation}
In this section, we prove four important facts about
our logical relation: irrelevance (Lemma~\ref{lemma:logrelcoherence}),
functionality (Lemma~\ref{lemma:logreldeter}), cumulativity
(Lemma~\ref{lemma:logrelcumulativity}), and the backward closure
property (Lemma~\ref{lemma:logrelbackclos}).

First, we prove a family of simple properties, which we refer to as
inversion principles for our logical relation. Given $[[Interp I i A
S]]$ where $[[A]]$ is in some head form such as $[[Bool]]$ or $[[Pi A0
B0]]$, the inversion lemma allows us to say something about the set
$[[S]]$. Its proof is simple, but we sketch out the case for
functions to help readers confirm their understanding of \rref{I-Pi}.
\begin{lemma}[Inversion of the logical relation]
  \label{lemma:interpinv}\leavevmode
  \begin{enumerate}
  \item\footnote{\dotv{semtyping.v}{InterpExt\_Void\_inv}} If $[[Interp I i Void S]]$, then $[[S = emptyset]]$.
  \item\footnote{\dotv{semtyping.v}{InterpExt\_Bool\_inv}} If $[[Interp I i Bool S]]$, then $[[S = { a | a =>+ true \/ a =>+ false   }]]$.
  \item\footnote{\dotv{semtyping.v}{InterpExt\_Eq\_inv}} If $[[Interp I i a ~ b : A S]]$, then $[[S = { p | p =>+ refl , a <=> b  }]]$.
  \item\footnote{\dotv{semtyping.v}{InterpExt\_Fun\_inv}} If $[[Interp I i Pi A B S1]]$, then there exists $[[S]],[[R]]$ such that:
    \begin{itemize}
    \item $[[Interp I i A S ]]$
    \item $[[R in S * PowerSet STm]]$
    \item $[[forall a, (# a in S implies (# exists S0 , (a , S0) in R #) #)]]$
    \item $[[forall a, forall S0, (# ( a , S0 ) in R implies Interp I i B { a } S0 #)]]$
    \item $[[S1 = { b | forall a, forall S0, (# ( a , S0 ) in R implies b a in S0 #) }]]$
    \end{itemize}
  \item\footnote{\dotv{semtyping.v}{InterpExt\_Univ\_inv}} If $[[Interp I i Set j S]]$, then $[[j < i]]$ and $[[S = I j]]$.
  \end{enumerate}
\end{lemma}
\begin{proof}
  As mentioned earlier, we only show the inversion property for the
  function type.
  We start by inducting over the derivation of $[[Interp I i Pi A B S]]$. There
  are only two possible cases we need to consider.
  \begin{description}
  \item[\Rref{I-Pi}:] Immediate.
  \item[\Rref{I-Red}:] We are given that $[[Interp I i Pi A B S1]]$.
    We know that there exists some $[[A0]]$ and
    $[[B0]]$ such that $[[Pi A B => Pi A0 B0]]$ and $[[Interp I i Pi
    A0 B0 S1]]$. From the
    induction hypothesis, there exists $[[S]]$ and $[[R]]$ such that :
    \begin{itemize}
    \item $[[Interp I i A0 S ]]$
    \item $[[R in S * PowerSet STm]]$
    \item $[[forall a, (# a in S implies (# exists S0 , (a , S0) in R #) #)]]$
    \item $[[forall a, forall S0, (# ( a , S0 ) in R implies Interp I i B0 { a } S0 #)]]$
    \item $[[S1 = { b | forall a, forall S0, (# ( a , S0 ) in R implies b a in S0 #) }]]$
    \end{itemize}
    By inverting the derivation of $[[Pi A B => Pi A0 B0]]$, we derive $[[A => A0]]$ and
    $[[B => B0]]$. By Lemma~\ref{lemma:parsubst}, we have $[[B {a} => B0 {a} ]]$ for all
    $[[a]]$. As a result, by \rref{I-Red}, the same $[[S]]$ and
    $[[R]]$ additionally satisfies the following properties:
    \begin{itemize}
    \item $[[Interp I i A S ]]$
    \item $[[forall a, forall S0, (# ( a , S0 ) in R implies Interp I i B { a } S0 #)]]$
    \end{itemize}
    These properties are exactly what we need to finish the proof.
  \end{description}
\end{proof}

\Rref{I-Red} bakes into the logical relation the backward preservation
property. That is, given $[[Interp I i A S]]$, if $[[B =>+ A]]$, then
$[[Interp I i B S]]$ also holds. The following property shows that
preservation holds in the usual forward direction too.
\begin{lemma}[Preservation of the logical relation\footnote{\dotv{semtyping.v}{InterpExt\_preservation}}]
  \label{lemma:interppreservation}
  If $[[Interp I i A S]]$ and $[[A => B]]$, then $[[Interp I i B S]]$.
\end{lemma}
\begin{proof}
  We carry out the proof by induction over the derivation of $[[Interp
  I i A S]]$.

  The only interesting case is \Rref{I-Red}. Given that
  $[[A => B0]]$ and $[[Interp I i B0 S]]$, we need to show
  for all  $[[B1]]$ such that $[[A => B1]]$, we have $[[Interp I i B1
  S]]$. By the diamond property of parallel reduction
  (Lemma~\ref{lemma:pardiamond}), there exists some term $[[B]]$ such
  that $[[B0 => B]]$ and $[[B1 => B]]$. By the induction hypothesis,
  we deduce $[[Interp I i B S]]$ from $[[B0 => B]]$ and $[[Interp I i
  B0 S]]$. By \rref{I-Red} and $[[B1 => B]]$, we conclude that
  $[[Interp I i B S]]$.

  The remaining cases all fall from induction hypotheses and basic
  properties about convertibility and parallel reduction we have
  established in Section~\ref{sec:spec}.
\end{proof}
From Lemma~\ref{lemma:interppreservation} and \rref{I-Red}, we can easily
derive the following corollary that two convertible types can always interpret
into the same set. We adopt the terminology from \citet{martin-lof-a-la-coq}
and refer to this property as irrelevance.
\begin{corollary}[Irrelevance of logical relation\footnote{\dotv{semtyping.v}{InterpUnivN\_Coherent}}]
  \label{lemma:logrelcoherence}
  If $[[Interp I i A S]]$ and $[[A <=> B]]$, then $[[Interp I i B S]]$.
\end{corollary}
% \scw{Need a transition here}

Since the definition of our logical relation is an inductive relation,
it is not immediately obvious why each type $[[A]]$ can only uniquely
corresponds to one set $[[S]]$. The following lemma shows that our
logical relation is indeed functional.
\begin{lemma}[Logical relation is functional\footnote{\dotv{semtyping.v}{InterpExt\_deterministic}}]
  \label{lemma:logreldeter}
  If $[[Interp I i A S0]]$ and $[[Interp I i A S1]]$, then $[[S0 = S1]]$.
\end{lemma}
\begin{proof}
  The proof proceeds by induction over the derivation of the first
  premise $[[Interp I i A S0]]$.
  All cases that are not \rref{I-Red} follow immediately from the
  Lemma~\ref{lemma:interpinv}.

  For \rref{I-Red}, we are given that there exists some $[[B]]$ such
  that $[[A => B]]$ and $[[Interp I i B S0]]$. Our goal is to show
  that given $[[Interp I i A S1]]$ for some $[[S1]]$, we have $[[S0 =
  S1]]$. By the preservation property
  (Lemma~\ref{lemma:interppreservation}),
  we know that $[[Interp I i B S1]]$ since $[[A => B]]$. The statement
  $[[S0 = S1]]$ then immediately follows from the induction hypothesis.
\end{proof}

Lemma~\ref{lemma:logreldeter} enables us to show the following
improved inversion lemma for function types whose statement is free of
the relation $[[R]]$, analogous to the admissible rule \rref{I-PiAlt}.
\begin{lemma}[Pi Inversion Alt\footnote{\dotv{semtyping.v}{InterpExt\_Fun\_inv\_nopf}}]
  \label{lemma:piinvalt}
  Suppose $[[Interp I i Pi A B S]]$, then there exists some $[[S0]]$
  such that the following constraints hold:
  \begin{itemize}
  \item $[[Interp I i A S0]]$
  \item $[[forall a, (# a in S0 implies (# exists S1 , Interp I i B {a}
    S1 #) #)]]$
  \item $[[S = { b | forall a, (# a in S0 , forall
    S1, (# Interp I i B {a} S1,  b a in S1 #) #) }]]$
  \end{itemize}
\end{lemma}
\begin{proof}
  Immediate from Lemmas~\ref{lemma:interpinv} and \ref{lemma:logreldeter}.
\end{proof}

The next lemma shows that our logical relation satisfies
cumulativity. That is, if a type has an interpretation at a lower
universe level, then we can obtain the same interpretation at a higher
universe level.
\begin{lemma}[Logical relation cumulativity\footnote{\dotv{semtyping.v}{InterpExt\_cumulative}}]
  \label{lemma:logrelcumulativity}
  If $[[Interp I i0 A S]]$ and $[[i0 < i1]]$, then $[[Interp I i1 A S]]$.
\end{lemma}
\begin{proof}
  Trivial by structural induction over the derivation of $[[Interp I
  i0 A S]]$.
\end{proof}
Note that in the statement of Lemma~\ref{lemma:logrelcumulativity}, we
implicitly assume that $[[I]]$ is defined on the set of natural
numbers less than $[[i1]]$.

\begin{corollary}[Logical relation is functional with different levels\footnote{\dotv{semtyping.v}{InterpExt\_deterministic'}}]
  \label{lemma:logreldeterhet}
  If $[[Interp I i0 A S0]]$ and $[[Interp I i1 A S1]]$, then $[[S0 = S1]]$.
\end{corollary}
\begin{proof}
  Immediate from Lemma~\ref{lemma:logreldeter} and
  \ref{lemma:logrelcumulativity}.
\end{proof}

\begin{definition}[Sets closed under expansion]
  We say that a set of terms $[[S]]$ is closed under expansion if
  given $[[a in S]]$, then $[[b in S]]$ for all $[[b => a]]$.
\end{definition}
The final property we want to show is that the output set $[[S]]$ from
the logical relation is closed under expansion. Unlike the previous
lemmas, we directly state the lemma
in terms of $[[InterpR i A S]]$ rather than $[[Interp I i A S]]$
because we need to know something about $[[I]]$ for this property to
hold in the \rref{I-Set} case.

\yl{Can lift this lemma somewhere earlier in the section since it doesn't really
  depend on anything}
\begin{lemma}[Interpreted sets are closed under expansion\footnote{\dotv{semtyping.v}{InterpUnivN\_back\_clos}}]
  \label{lemma:logrelbackclos}
  If $[[InterpR i A S]]$, then the set $[[S]]$ is closed under expansion.
\end{lemma}
\begin{proof}
  By the definition of $[[InterpR i A S]]$ from
  Figure~\ref{fig:logrelrec}, we unfold $[[InterpR i A S]]$ by one
  step into $[[ Interp I i A S  ]]$ where $[[I i]] := [[{A | exists S
    , InterpR i A S}]]$.
  We then proceed by induction over the derivation of $[[Interp I i A S]]$.

  All cases are trivial except for the \rref{I-Set} case, where we
  want to show that the set $[[I j]]$ is closed under expansion for
  all $[[j < i]]$. However, by the definition of $[[I]]$, we know that
  $[[A in I j]]$ if only if there exists some $[[S]]$ such that
  $[[Interp I i A S]]$. By \rref{I-Red}, we must also have $[[B in I
  j]]$ for all $[[B => A]]$.
\end{proof}

\section{Semantic Typing and Consistency}
\label{sec:logrelproof}
\yl{todo: rename all variables from i,j to n}
\scw{Would it make sense to define the notation $a \in [\![A]\!]^i$ when
there exists some $S$ such that $[[InterpR i A S]]$ and $[[a in S]]$ ?}
% \begin{figure}[h]
% \[
% \begin{array}{lcl}

%       [[rho |= G]] &:= & \forall i\ j\ S, \text{ if }[[i < |G|]]\text{ and
%                      } [[InterpR j (G i < up Suc i > ) { rho } S ]] \text{, then } [[rho i in S]] \\
%       [[G |= a : A]] &:= & \forall [[rho]], \text{ if }[[rho |= G]]
%    \text{ then there exists some } [[j]] \text{
%                        and } [[S]] \text{ such that } [[InterpR j A {rho} S]]
%        \text{ and } [[a {rho} in S]] \\
%       [[|= G]] &:= & \forall [[i < |G|]], \exists [[j]], [[drop Suc i G |= G i : Set j]]
% \end{array}
% \]
%   \caption{Semantic Typing for \lang}
%   \label{fig:semtyping}
% \end{figure}x

% The logical relation we define in Figure~\ref{fig:logrel} does not
% include cases for variables. Likewise, for the base types such as
% boolean and equality, the output set $[[S]]$ contains only terms that
% evaluate to closed terms.

In this section, we show that all closed, well-typed terms are contained
within their type-indexed sets. In other words, $[[empty |- a : A]]$ implies
$[[InterpR i A S]]$ and $[[a in S]]$.  This result gives us consistency
because we know that $[[InterpR i Void S]]$ is defined, and that $[[S]]$ must
be the empty set. Therefore, if there were some closed, well-typed term of type
$[[Void]]$, it would need to be a member of the empty set, a contradiction.

To prove this result, we define a notion of semantic typing based on the
logical relation we have defined in Section~\ref{sec:logreldep} and prove the
fundamental lemma, which states that syntactic typing implies semantic typing.
Semantic typing extends our logical relation from being a (type-indexed)
family of predicates on closed terms, to a type-indexed family of predicates
on open terms.

The necessity of semantic typing as an extra layer of
definition on top of the logic relation can be understood in simply typed
languages~\citep{skorstengaard2019introduction, harpertait,
  pierce2002types}. In our setting, attempting to show that
$[[empty |- a : A]]$ implies $[[InterpR i A S]]$ and $[[a in S]]$ will fail in
\rref{T-Abs}, where the induction hypothesis is not helpful since the body of
the lambda term is typed under a non-empty context. Through the definition of
semantic typing, we can state a strengthened property that is actually
provable.

\begin{definition}[Semantic well-formed substitution\footnote{\dotv{soundness.v}{$\rho$\_ok}}]
Define $[[rho |= G]]$ when
\[ \forall n\ i\ S, \text{ if }[[n < |G|]]\text{ and
                     } [[InterpR i (G n < up Suc n > ) { rho } S ]] \text{, then } [[rho n in S]] \]
\end{definition}

% To generalize our logical relation to open
% terms, we define the semantic typing judgment by closing the open
% terms with a substitution whose codomain consists of terms that
% respect the interpretation of the types from the context.
% The full
% definitions of well-formed substitution ($[[rho |= G]]$), semantic
% typing ($[[ G |= a : A]]$), and semantic context well-formedness
% ($[[|= G]]$) are presented in Figure~\ref{fig:semtyping}.

The $[[rho |= G]]$ notation denotes the semantic well-formedness of a
substitution $[[rho]]$ with respect to a context $[[G]]$. Intuitively, for any
variable $[[n]]$ in the context (thus the restriction $[[n < | G |]]$),
$[[rho n]]$ is a term that inhabits all possible interpretations of the type
$[[G n]]$ from the context.


Since we are in a dependently typed system, there
may be variables in $[[G n]]$, too. The type $[[(G n < up Suc n > ) {
  rho }]]$ applies $[[rho]]$ to replace those variables. The shifting
operation $[[up Suc n]]$ can be viewed as an artifact of the de Bruijn
representation to lift the type $[[G n]]$ to the right scope before
substitution can be carried out.

Finally, despite the for all quantification over the interpreted set
$[[S]]$ and the universe level $[[i]]$ in the definition of $[[rho |=
G]]$, we only need show that there exists some $[[i]]$ and $[[S]]$
such that $[[InterpR i (G n < up Suc n > ) { rho } S]]$ and $[[rho n
in S]]$ since the logical relation is a partial function (Lemma~\ref{lemma:logreldeter}). This idea is encapsulated in the second of the two structural
law about $[[rho |= G]]$.
\begin{lemma}[Well-formed $[[rho]]$ empty\footnote{\dotv{soundness.v}{$\rho$\_ok\_nil}}]
  \label{lemma:rhowfempty}
  $[[rho |= G]]$ whenever $[[G]]$ is the empty context.
\end{lemma}
\begin{lemma}[Well-formed $[[rho]]$ cons\footnote{\dotv{soundness.v}{$\rho$\_ok\_cons}}]
  If $[[InterpR i A S]]$, $[[a in S]]$, and $[[rho |= G]]$, then
  $[[rho .: a |= G ++ A]]$.
\end{lemma}

We next define semantic well-typedness.

\begin{definition}[Semantic typing\footnote{\dotv{soundness.v}{SemWt}}]
Define $[[G |= a : A]]$  when
\[ \forall [[rho]], \text{ if }[[rho |=
                       G]]\text{ then there exists some } [[j]] \text{
                       and } [[S]] \text{ such that } [[InterpR j A
                       {rho} S]] \text{ and } [[a {rho} in S]]  \]
\end{definition}

This definition says the term $[[a]]$ can be semantically typed $[[A]]$ under
the context $[[G]]$ if for all substitutions $[[rho]]$ such that
$[[rho |= G]]$, the type $[[A { rho }]]$ can be interpreted as the set
$[[S]]$, and $[[a { rho } in S]]$. Our definition of semantic well-typedness
is standard, though dependent types add a small twist that we apply the
$[[rho]]$ to $[[A]]$ and require that $[[A { rho }]]$ has some interpretation.

Finally, we define semantic well-formedness for contexts, analogous to the
relation $[[|-G]]$.

\begin{definition}[Semantic context well-formedness\footnote{\dotv{soundness.v}{SemWff}}]
Define $[[|= G]]$ when
\[
   \forall [[n < |G|]],\text{ there exists some } [[i]] \text{ such that } [[drop Suc n G |= G n : Set i]] \]
\end{definition}

In this definition, we use the notation $[[drop n G]]$ to denote
the typing context obtained by dropping the last $[[n]]$ elements of
$[[G]]$. When $[[G]]$ has fewer than $[[i]]$ elements, $[[drop n G]]$ returns
the empty list. Intuitively, $[[|= G]]$ says that all
types in the context must correspond to some set according to the logical
relation. The truncation to the context $[[G]]$ is due to the telescopic
scoping of the types in the context. An alternative approach would be to define $[[|= G]]$
inductively, similar to $[[|- G]]$, but we find it easier to use this definition and
recover the structural rules as lemmas.
\begin{lemma}[Semantic context well-formedness empty]
  \label{lemma:semwffempty}
  $[[|= G]]$ holds when $[[G]]$ is empty.
\end{lemma}
\begin{lemma}[Semantic context well-formedness cons]
  \label{lemma:semwffcons}
  If $[[|= G]]$ and $[[G |= A : Set i]]$, then $[[|= G ++ A]]$.
\end{lemma}

The following lemma makes the statement $[[G |= A : Set i]]$ easier to
work with.
\begin{lemma}[Set Inversion\footnote{\dotv{soundness.v}{SemWt\_Univ}}]
  \label{lemma:setinv}
  The following two statements are equivalent:
  \begin{itemize}
  \item $[[G |= A : Set i]]$
  \item $\forall$ $[[rho]]$, if $[[rho |= G]]$, then there exists
    $[[S]]$ such that $[[InterpR i (A {rho}) S]]$
  \end{itemize}
\end{lemma}
\begin{proof}
  The forward direction is immediate by
  Lemma~\ref{lemma:interpinv}. We now consider the backward direction
  and show that $[[G |= A : Set i]]$ given the second bullet.

  Suppose $[[rho |= G]]$, then we know that there exists some $[[S]]$
  such that $[[InterpR i (A {rho}) S]]$. By the definition of semantic
  typing, it suffices to show that there exists some $[[j]]$ and
  $[[S0]]$ such that  $[[InterpR j Set i S0]]$ and $[[A {rho} in
  S0]]$.
  Pick $[[Suc i]]$ for $[[j]]$ and $[[ { A | exists S , InterpR i A S }
  ]]$ for $[[S0]]$ and it is trivial to verify the conditions hold.
\end{proof}



% The semantic context well-formedness judgment ($[[|= G]]$), unlike its syntactic
% counterpart $[[|- G]]$, is defined through a $\forall$ quantified statement rather
% than inductively over the context. \scw{why is that the case?} It is easy to recover the same
% structural rules:
% \scw{point out that this lemma is the semantic analogue to Ctx-Cons. What about
% Ctx-empty?}
% \begin{proof}
%   By the definition of semantic context well-formedness, the goal is
%   to show that given $[[i < | G ++ A |]] = [[Suc |G|]]$, $[[drop Suc i   (G ++ A) |= (G ++ A) i : Set j]]$. The statement can be easily
%   proven by case analysis on whether $[[i]]$ is zero.
% \end{proof}

Next, we show some non-trivial cases of the fundamental theorem as
top-level lemmas. For example, we can define the semantic analogue to the
syntactic typing rule for variables (\rref{T-Var}).
\begin{lemma}[ST-Var]
  \label{lemma:stvar}
  If $[[|= G]]$ and $[[n < |G|]]$, then $[[G |= var n : G n < up Suc n  >]]$.
\end{lemma}
\begin{proof}
  Suppose $[[rho |= G]]$. By the definition of semantic typing, we
need to show that there exists some $[[i]]$ and $[[S]]$ such that
  \begin{itemize}
  \item $[[InterpR i G n < up Suc n > { rho } S]]$
  \item $[[rho n in S]]$
  \end{itemize}
  From the definition of $[[|= G]]$, we know that there exists some
  $[[i]]$ such that $[[drop Suc n G |= G n : Set i]]$. This is not
  immediately useful since $[[rho |= G]]$, not the truncated
  context. We claim, without giving the proof, that from $[[drop Suc n
  G |= G n  : Set i]]$, we can derive $[[G |= G n {up Suc n} : Set
  i]]$. A rigorous justification would require us to formally state
  and show renaming/weakening lemma for semantic typing. We instead
  provide an informal justification since the proof of renaming
  is uninteresting and only requires unfolding definitions, but its
  statement introduces unnecessary line noise related to shifting.

  Intuitively, a substitution $[[rho]]$
  that closes over a context should always induce a truncated
  substitution for each truncated context. As a result, if
  some term $[[b]]$ is semantically well-typed under some truncated
  context $[[G]]$, then it must also be semantically well-typed under
  the context $[[G]]$ up to shifting.
%
  Knowing that $[[G |= G n {up Suc n} : Set i]]$ holds, we can then
  apply Lemma~\ref{lemma:setinv} to show that
  $[[InterpR i G n < up Suc n > { rho } S]]$. It now
  suffices to show $[[rho n in S]]$, but that is immediate from the
  definition of $[[rho |= G]]$.
\end{proof}

% Next, we show some non-trivial cases of the fundamental theorem as
% top-level lemmas.
% We first formulate the definition of valid renamings and prove that
% semantic typing satisfies renaming so we can weaken the context when
% reasoning about the variable case of the fundamental lemma
% (Lemma~\ref{lemma:stvar}). Intuitively, given a valuation $[[rho |= G ++ D]]$, it is easy to show that we can extract some valuation
% $[[rho0]]$ such that $[[rho0 |= G]]$, where $[[rho0]]$ is obtained by
% ``truncating'' $[[rho]]$. As a result, if we know that $[[G |= a :A]]$, then we can conclude that $[[G ++ D |= a0 : A0 ]]$, where
% $[[a0]]$ and $[[A0]]$ are obtained by shifting $[[a]]$ and $[[A]]$
% after weakening the context; this implication holds because $[[rho |=G ++ D]]$ induces a context $[[rho0]]$ such that $[[rho0 |= G]]$ so we
% can make use of the premise $[[G |= a : A]]$ to derive what we need
% for the conclusion. We recommend the readers to skip the proofs of
% Lemmas~\ref{lemma:validtruncate} through \ref{lemma:semrenaming}
% during the first read as long as they have an intuitive understanding
% of what the renaming property is meant to capture.

% \scw{Make this a definition? Would it be useful to create notation
%   for the relation, such as $[[xi]]:[[G]]\Rightarrow[[D]]$? }
% We say that $[[xi]]$ is
% valid from the context $[[G]]$ to the context $[[D]]$ if the
% following condition holds.
% \[ \forall i \text{, if } i < | [[G]] |\text{, then }[[ ren xi i < |D| ]] \text{ and }
%   [[D ren xi  i < up Suc ren xi i > = G i < up Suc i > < xi >]] \]

% \begin{lemma}[Truncate is valid]
%   \label{lemma:validtruncate}
%   If $[[i < |G|]]$, then $[[up i]]$ is a valid renaming from $[[drop i   G]]$ to $[[G]]$.
% \end{lemma}
% \begin{proof}
%   By the definition of a valid renaming, we must show that given $[[j   < |drop i G|]] = [[|G|]] - [[i]]$, then the following conditions hold:
%   \begin{itemize}
%   \item $[[ren up i j]] = i + j  < [[| G | ]]$
%   \item $[[G ren up i j < up Suc ren up i j > = drop i G j < up Suc j > < up i >]]$
%   \end{itemize}
%   The first bullet point is immediate from the fact that $[[j]] <
%   [[|G|]] - [[i]]$. The second bullet follows from unfolding the
%   definitions, and the fact that $[[drop i G j]] = [[G]](i + j)$ when
%   $[[i]] + [[j]] < [[|G|]]$.
% \end{proof}

% \begin{lemma}[Renaming for $[[rho |= G]]$]
%   \label{lemma:renamingval}
%   If $[[rho |= D]]$ and $[[xi]]$ is a valid renaming from $[[G]]$ to
%   $[[D]]$, then we have $[[rho0 |= G]]$ where $[[rho0 i = rho ren xi i]]$.
% \scw{could you use $[[rho]]\circ[[xi]]$ for $[[rho0]]$?}
% \end{lemma}
% \begin{proof}
%   Unfolding the definition of $[[rho0 |= G]]$, the goal is to show
%   that for all $i,j,$ and $S$, if $[[i < |G|]]$ and $[[InterpR j (G i   < up Suc i > ) { rho0 } S ]] \text{, then } [[rho0 i]] = [[rho ren xi i in S]]$.

%   By the definition of $[[rho0]]$ and the validity of $[[xi]]$, we
% have $[[G i < up Suc i > { rho0 }]] = [[G i < up Suc i > < xi > { rho } ]] = [[D ren xi i < up Suc ren xi i > { rho }]]$. From $[[rho |= D]]$ and $[[ren xi i < | D |]]$, we have $[[InterpR j D ren xi i < up Suc ren xi i > { rho } S]]$ and $[[rho ren xi i in S]]$.
% \end{proof}

% \begin{lemma}[Renaming for $[[G |= a : A]]$]
%   \label{lemma:semrenaming}
%   If $[[G |= a : A]]$ and $[[xi]]$ is a valid renaming from $[[G]]$ to
%   $[[D]]$, then $[[D |= a < xi > : A < xi > ]]$.
% \end{lemma}
% \begin{proof}
%   Immediate from the definition of semantic typing and Lemma~\ref{lemma:renamingval}.
% \end{proof}

% \scw{Need a transition here that you are starting to explain the semantic typing
% rules.}


\begin{lemma}[ST-Set]
  \label{lemma:stset}
  If $[[i < j]]$, then $[[G |= Set i : Set j]]$.
\end{lemma}
\begin{proof}
  Immediate by Lemma~\ref{lemma:setinv} and \rref{IR-Set}.
\end{proof}

\begin{lemma}[ST-Pi]
  \label{lemma:stpi}
  If $[[G |= A : Set i]]$ and $[[G ++ A |= B : Set i]]$, then $[[G |= Pi
  A B : Set i]]$.
\end{lemma}
\begin{proof}
  Applying Lemma~\ref{lemma:setinv} to the
  conclusion, it now suffices to show that given $[[rho |= G]]$, there
  exists some $[[S]]$ such that $[[InterpR i Pi A{rho} B{up rho} S]]$.
  From Lemma~\ref{lemma:setinv} and $[[G |= A : Set i]]$, we know that
  there exists some set $[[S0]]$ such that $[[InterpR i A {rho} S0]]$.
From $[[G ++ A |= B : Set i]]$, we know that there must
exists $[[S]]$ such that $[[InterpR i B {rho .: a} S]]$ for every $[[a
in S0]]$. The conclusion immediately follows from the admissible \rref{I-PiAlt}.
\end{proof}

\begin{lemma}[ST-Abs]
  \label{lemma:stabs}
  If $[[G |= Pi A B : Set i]]$ and $[[G ++ A |= b : B]]$, then $[[G |=
  \ A b : Pi A B]]$.
\end{lemma}
\begin{proof}
  By unfolding the definition of $[[G |= \ A b : Pi A B]]$, we need to
  show that given some $[[rho |= G]]$, there exists some $[[i]]$ and
  $[[S]]$ such that $[[InterpR i Pi A {rho} B {up rho} S]]$ and $[[\
  A{rho} b{up rho} in S]]$.

  By Lemma~\ref{lemma:setinv} and the premise $[[G |= Pi A B : Set
  i]]$, there exists some set $[[S]]$ such that
  $[[InterpR i Pi A {rho} B {up rho} S]]$. It now suffices to show that
  $[[\A{rho} b{up rho} in S
  ]]$. By Lemma~\ref{lemma:piinvalt}, the alternative inversion
  principle for \rref{I-Pi}, there exists some $[[S0]]$ such
  that all following conditions hold:
  \begin{itemize}
  \item $[[InterpR i A{rho} S0]]$
  \item $[[forall a, (# a in S0 implies (# exists S1 , InterpR i B
    {rho .: a}
    S1 #) #)]]$
  \item $[[S = { b | forall a, (# a in S0 , forall
      S1, (# InterpR i B {rho .: a} S1,  b a in S1 #) #) }]]$
  \end{itemize}
  To show that $[[\A{rho} b{up rho} in S]]$, we need to prove
  that given $[[a in S0]]$,
  $[[Interp I i B {rho .: a} S1]]$, we have  $[[( \A{rho} b{up rho} )
  a in S1]]$.
  By Lemma~\ref{lemma:logrelbackclos}, the set $[[S1]]$ is closed
  under expansion. Since $[[( \A{rho} b{up rho} )
  a => b {up rho} {a}]] = [[b {rho .: a}]]$, it suffices to show that
  $[[b {rho .: a} in S1]]$, which is immediate from $[[G ++ A |= b :
  B]]$ and the fact that the logical relation is deterministic and
  cumulative (Lemma~\ref{lemma:logreldeterhet}).
\end{proof}

\begin{lemma}[ST-App]
  \label{lemma:stapp}
  If $[[G |= b : Pi A B]]$ and $[[G |= a : A]]$, then $[[G |= b a : B {a}]]$.
\end{lemma}
\begin{proof}
Suppose $[[rho |= G]]$. The goal is to show that there exists some
$[[i]]$ and $[[S1]]$
such that  $[[b {rho} a {rho} in S1 ]]$ and $[[InterpR i B {a} {rho}
S1]]$, or equivalently, $[[InterpR i B {rho .: a {rho}} S1]]$ since
$[[B {a}{rho}]] = [[B {rho .: a {rho}}]]$. By the premise $[[G |= b :
Pi A B]]$, Lemma~\ref{lemma:setinv}, and Lemma~\ref{lemma:piinvalt},
there exists some $[[i]]$ and $[[S0]]$ such that:
  \begin{itemize}
  \item $[[InterpR i A{rho} S0]]$
  \item $[[forall a0, (# a0 in S0 implies (# exists S1 , InterpR i B
    {rho .: a0}
    S1 #) #)]]$
  \item $[[forall a0, (# a0 in S0 , forall
      S1, (# InterpR i B {rho .: a0} S1,  b {rho} a0 in S1 #) #)]]$
  \end{itemize}
  Instantiating the variable $[[a0]]$ from the last two bullets with
  the term $[[a {rho}]]$, the conclusion immediately follows.
\end{proof}

\begin{theorem}[The Fundamental Theorem\footnote{\dotv{soundness.v}{soundness}}]
  \label{theorem:soundness}\leavevmode
  \begin{itemize}
  \item If $[[G |- a : A]]$, then $[[G |= a : A]]$.
  \item If $[[|- G]]$, then $[[|= G]]$.
  \end{itemize}
\end{theorem}
\begin{proof}
  Proof by mutual induction over the derivation of $[[G |- a :
  A]]$ and $[[|- G]]$.   The cases related to context well-formedness immediately follows
  from Lemmas~\ref{lemma:semwffempty} and \ref{lemma:semwffcons}. The semantic typing rules
(Lemmas~\ref{lemma:stvar},~\ref{lemma:stset},~\ref{lemma:stpi},~\ref{lemma:stabs},~\ref{lemma:stapp})
  can be used to discharge their syntactic counterparts
  (e.g. Lemma~\ref{lemma:stabs} for case \rref{T-Abs}). The remaining
  cases not covered by the lemmas are similar to the ones already
  shown.
\end{proof}

Recall the logical consistency property
(Theorem~\ref{theorem:consistency}), which states that the judgment
$[[empty |- a : Void ]]$ is not derivable. We now give a proof of the
property using the fundamental lemma.

\begin{proof}
  Suppose $[[empty |- a : Void]]$ is derivable, then by the
  fundamental lemma, we have $[[empty |= a : Void]]$, which states
  that for all $[[rho |= empty]]$, and for all $[[j]]$, $[[S]]$ such
  that $[[InterpR j Void S]]$, we have $[[a {rho} in S]]$. By
  Lemma~\ref{lemma:rhowfempty}, any $[[rho]]$ we pick trivially
  satisfies $[[rho |= G]]$. For convenience, we pick $[[rho]]$ as
  $[[idtm]]$, though any $[[rho]]$ would work since
  $[[empty |- a : Void]]$ ensures there is no free variable in
  $[[a]]$. We have $[[a {idtm}]] = [[a in S]]$. By the $[[Void]]$
  case of the inversion property (Lemma~\ref{lemma:interpinv}), we
  know that $[[S]]$ must be the empty set and therefore contradicts
  the assumption that $[[a in S]]$.
\end{proof}


\section{Existence of $\beta$-normal forms}
\label{sec:extension}
In this section, we show how the logical relation from
Section~\ref{sec:logreldep} can be extended to show the existence of $\beta$
normal forms for (open and closed) well-typed terms.  In other words, we prove
that it is possible to repeatedly use the parallel reduction relation to
reduce any term to its unique normal form, where no further (non-identity)
reductions can be applied. This result can be used to show that our type
conversion relation is decidable, as computation of the normal form will
always terminate.

The goal of this section is also to demonstrate that our logical relations
proof technique can be extended to reason about the reduction properties of
open terms, not just the reduction of terms after closing substitutions.
Reasoning about open terms is particularly important for dependently-typed
languages because type checking involves working with open terms.
\scw{
  Add when we can find a reference:
  However, even non dependently-typed languages employ such techniques,
  especially in the case of relational semantics.
}
While this extension employs well-known techniques, it continues to be short and
demonstrates the robustness of our initial framework.

We begin this part with a description of the $\beta$-normal forms
of \lang{}.

\begin{figure}[h]
  \[
    \begin{array}{llcl}
       \beta\text{-}\mathit{neutral\ terms} &
      [[e]] & ::= & [[i]]\ |\ [[e f]]\ |\ [[J e f f f]]\ |\ [[if e f
                    f]] \\ \\
      \beta\text{-}\mathit{normal\ terms} &
      [[f]] & ::= & [[e]]\ |\ [[Set i]]\ |\ [[Void]]\ |\ [[Pi f f]]\
                    |\ [[f ~ f : f]]\\
            & & |   & [[\ f]]\ |\ [[refl]]\ |\ [[Bool]]\ |\ [[true]]\ |\ [[false]]
    \end{array}
  \]
  \caption{$\beta$-neutral and normal forms}
  \label{fig:nenf}
\end{figure}

The syntactic forms $[[e]]$ and $[[f]]$ (Figure~\ref{fig:nenf}) capture the
neutral terms and normal forms with respect to $\beta$-reduction\scw{Why not say parallel reduction here? We can be specific and say that that the only reductions available for these terms are identity reductions and cite
\footnote{\dotv{normalform.v}{nf\_refl}} }. Instead of the
metavariables $e$ and $f$, we also
use the judgment forms $[[ne a]]$ and $[[nf a]]$ to indicate that there exists
$[[e]]$ or $[[f]]$ such that $[[a = e]]$ or $[[a = f]]$.

The predicates $[[wne a]]$ and $[[wn
a]]$ describe terms that can evaluate into $\beta$-neutral or
$\beta$-normal form through parallel reduction and are defined as
follows.
\[
\begin{array}{llcl}
\mbox{\emph{weakly normalizes to a neutral form}} & [[wne a]] &\iff& \exists [[e]], [[a =>+ e]] \\
\mbox{\emph{weakly normalizes to a normal form}}  & [[wn a]]  &\iff& \exists [[f]], [[a =>+ f]] \\
\end{array}
\]

\begin{figure}[h]
  \drules[I]{$[[Interp I i A S]]$}{Logical Relation}{Ne, VoidNew, BoolNew, EqNew}
  \caption{Extended logical relation (new and changed rules) }
  \label{fig:logrelopen}
\end{figure}

The updated logical relation is shown in
Figure~\ref{fig:logrelopen}.~\footnote{\dotv{semtypingopen.v}{InterpExt}}
There is one new rule in this figure, \rref{I-Ne}. In a non-empty context, a
type itself may evaluate to a neutral term and in turn can only be inhabited
by neutral terms.  Otherwise, the rest of the rules in this figure are updates
to the analogous rules in Figure~\ref{fig:logrel}. Note that, we omit the
rules for the function and universe cases because they are identical to the
original version.

% The idea of a term blocked from $\beta$ reduction is
% captured by $[[e]]$, the set of neutral terms. We augment the
% interpretation of booleans and the empty types with terms that
% evaluate to neutral terms. Furthermore, types that are neutral terms
% can also be assigned a meaning since they may be inhabited by other
% neutral terms.
The changes to \rref{I-Bool} and \rref{I-Void}
follow the same pattern: an open term of type $[[Bool]]$ does not necessarily
reduce to $[[true]]$ or $[[false]]$, but may reduce to a variable, or more
generally, a neutral term. Likewise, while the $[[Void]]$ type remains
uninhabited under an empty context, it may be inhabited when there is a
variable in the context that has type $[[Void]]$ or that can be eliminated to
type $[[Void]]$.

The rule for equality type $[[a ~ b : A]]$ is augmented with the precondition that
$[[a]]$, $[[b]]$, and $[[A]]$ are all normal forms because
otherwise our model would include equality types that are themselves
not normalizing.
\scw{I don't see this precondition in the figure!}
Furthermore, the side condition $[[a <=> b]]$ is only
required/available when the equality proof reduces to $[[refl]]$. If the proof
term reduces to a neutral term, then there is nothing we need to show/can learn
about the relationship between $[[a]]$ and $[[b]]$.

Because we are working with open terms, we need a few additional syntactic
lemmas about reduction. First, a renaming $\xi$ is a generalization of
weakening when working with de Bruijn indices. It consistently renumbers the
variables that appears in terms. If a renamed term has been reduced, we can
always recover the result of the reduction without the renaming.
%
\scw{This lemma is only used to prove \texttt{wn\_antirenaming}, which is then
used more generally. Maybe we should replace it with that?}
\begin{lemma}[Par anti-renaming\footnote{\dotv{normalform.v}{Par\_antirenaming}}]
  \label{lemma:parantirenaming} If $[[a < xi > => b0]]$, then there
exists some $[[b]]$ such that $[[b < xi > = b0]]$ and $[[a => b]]$.
\end{lemma}

We can show that parallel reduction preserves $\beta$-normal and
neutral forms.
\begin{lemma}[Par preserves $\beta$-neutral and normal forms\footnote{\dotv{normalform.v}{nf\_ne\_preservation}}]
  \label{lemma:parnenf}
  If $[[a => b]]$, then
  \begin{itemize}
  \item $[[ne a]]$ implies $[[ne b]]$
  \item $[[nf a]]$ implies $[[nf b]]$
  \end{itemize}
\end{lemma}
Lemma~\ref{lemma:parnenf} could have been strengthened to say that if
$[[ne a]]$ or $[[nf a]]$ and $[[a => b]]$, then $[[a = b]]$. Since
$\ottkw{ne}$ and $\ottkw{nf}$ captures terms free of $\beta$ redexes, parallel
reduction can not take any real reduction steps and can only step into a term
itself. However, for the purpose of our proof, Lemma~\ref{lemma:parnenf} is
sufficient.  In fact, all the properties we have shown in
Section~\ref{sec:logreldep} and \ref{sec:logrelproof} before the fundamental
lemma can be proven in the same order, where the new cases due to \rref{I-Ne}
and the augmentation of neutral terms to \rref{I-Void, I-Eq, I-Bool} can be
immediately discharged by Lemma~\ref{lemma:parnenf}.

Furthermore, Lemma~\ref{lemma:parnenf}, in its current weaker form, would
still hold after we extend our equational theory with the function $\eta$
rule, where parallel reduction can take $\eta$ steps but still preserves
$\beta$-normal form.

We also need to know that the $[[wne a]]$ and $[[wn a]]$ relations can be
justified compositionally. For example, an application has a neutral form when
the function has a neutral form and the argument has a normal form.

\begin{lemma}[Wne application\footnote{\dotv{normalform.v}{wne\_app}}]
  \label{lemma:wnewn}
  If $[[wne a]]$ and $[[wn b]]$, then $[[wne (a b)]]$.
\end{lemma}
\begin{proof}
  Immediate by lexicographical induction over the length of the reduction sequences in
  $[[wne a]]$ and $[[wn b]]$.
\end{proof}

Furthermore, if we know that an application of a term to a variable
has a normal form, then we know the term must have a normal form.
\begin{lemma}[Wn extensionality\footnote{\dotv{normalform.v}{ext\_wn}}]
  \label{lemma:extwn}
  If $[[wn (a var i)]]$, then $[[wn a]]$.
\end{lemma}
\begin{proof}
  By induction over the length of the reduction sequence in $[[wn (a
  var i)]]$. The conclusion follows from Lemmas~\ref{lemma:parantirenaming} and
  \ref{lemma:parnenf}.
\end{proof}


Before we can prove the fundamental theorem and derive the normalization
property as its corollary, we need to additionally formulate and prove an
\emph{adequacy property} about the logical relation.  This property, that the
interpretation of each type is a \emph{reducibility candidate}, allows us to
conclude that every term in each interpretation has a normal form. In the
previous section, we only needed a property of the interpretation of the
$[[Void]]$ type. However, for this section, we need to know something about
the interpretation of every type.

Furthermore, to prove this adequacy property, we need to strengthen it to also
give us more information about neutral terms as we proceed by induction. In
particular, we need to know that all terms that reduce to neutral forms are
contained within the interpretation.
\scw{Also, cite where this form of proof originally
appeared? This part is standard.}
Therefore, we formally define when a set is a \emph{reducibility candidate}
(shortened as $CR$) as follows. Our definition of $CR$ is inspired by
\citet{girard1989proofs}, but not identical since we only care about
weak normalization.
\begin{definition}[Reducibility Candidates (CR)\footnote{\dotv{semtypingopen.v}{CR}}]
  Let $[[S]]$ be a set of lambda terms. We say that $[[S]] \in CR$
  if and only if conditions $CR_1$ and $CR_2$ hold.
  \begin{itemize}
  \item $[[S]] \in CR_1 \iff\ [[forall a, (#  wne a implies a in S #)]]$
  \item $[[S]] \in CR_2 \iff\ [[forall a, (# a in S implies wn a #)]]$
  \end{itemize}
\end{definition}

We now state and prove the adequacy lemma.
\begin{lemma}[Adequacy\footnote{\dotv{semtypingopen.v}{adequacy}}]
  \label{lemma:adequacy}
  If $[[InterpR i A S]]$, then we have $[[S]] \in CR$.
\end{lemma}
\begin{proof}
  We start by strong induction over $[[i]]$. We are given the
  induction hypothesis that for all $[[j < i]]$, $[[InterpR j A S]]$
  implies $[[S]] \in CR$. Our goal is to show $[[InterpR i A S]]$
  implies $[[S]] \in CR$.

  By its definition in Figure~\ref{fig:logrelrec}, we have the
  equality $[[InterpR i A S]] = [[Interp I i A S]]$  where $[[I i]] :=
  [[{A | exists S , InterpR i A S}]]$.
  We then proceed by structural over the derivation of $[[Interp I i A
  S]]$. The only interesting cases are \rref{I-Pi} and \rref{I-Set}.
  The function case requires Lemmas~\ref{lemma:extwn} and
  \ref{lemma:wnewn} we have shown earlier.

  The \rref{I-Set} case is the most involved. We need to show that
  for all $[[j < i]]$, the set $[[{ A | exists S, InterpR j A S  }]]
  \in CR$. We immediately know that $[[{A | exists S, InterpR j A S
  }]] \in CR_1$ by \rref{I-Ne}. It remains to show that $[[{A | exists S, InterpR j A S
  }]] \in CR_2$, or equivalently, for all $[[A]]$, $[[InterpR j A S]]$
  implies $[[wn A]]$. Suppose $[[InterpR j A S]]$ for an arbitrary
  $[[A]]$. We have $[[InterpR j A S]]=[[Interp I j A S]]$ where $[[I]]$
  has the same definition from earlier but its domain restricted to
  numbers less than $[[j]]$. We perform another induction on
  the derivation of $[[Interp I j A S]]$. All cases are trivial except for the case for
  \rref{I-Pi}. Our induction hypothesis immediately gives us $[[wn
  A]]$. To derive $[[wn (Pi A B)]]$, it remains to show $[[wn B]]$. We
  use the outermost induction hypothesis to show that $[[var 0]]$
  semantically inhabits $[[A]]$, from which we derive $[[wn (B {var 0})]]$
  and conclude $[[wn B]]$ through antirenaming (Lemma~\ref{lemma:parantirenaming}).
\end{proof}

% \begin{lemma}[Adequacy: $CR_1$ for type]
%   \label{lemma:cr1ty}
%   If $[[wne A]]$, then we have $[[Interp I i A {a | wne a }]]$.
% \end{lemma}
% \begin{proof}
%   Immediately from \rref{I-Ne} and \rref{I-Red}.
% \end{proof}

% \begin{lemma}[Adequacy: $CR$ for interpreted sets]
%   \label{lemma:crel}
%   If $[[I]](j) \in CR$ for all $[[j < i]]$ and $[[Interp I i A S]]$, then $[[S]] \in CR$.
% \end{lemma}
% \begin{proof}
%   By induction over the derivation of $[[Interp I i A S]]$. The base
%   cases are all immediate.

%   In the function case ($[[Pi A B]]$), we use the induction
%   hypothesis to show that variables, which are special cases of
%   neutral terms, semantically inhabit the input type $[[A]]$. We apply the
%   function to an arbitrary variable and we can then use
%   Lemma~\ref{lemma:extwn} to conclude the $CR_2$ property.

%   To show
%   the $CR_1$ property, we need to prove that given a neutral term $[[b]]$
%   such that $[[wne b]]$,
%   and a term $[[a]]$ that semantically inhabits $[[A]]$, $[[b a]]$ gives
%   us a term that semantically inhabits $[[B {a}]]$. From the induction
%   hypothesis, $[[A]]$ also satisfies $CR_2$ and therefore $[[wn a]]$
%   holds. By Lemma~\ref{lemma:wnewn}, we have $[[wne b a]]$. By $CR_2$
%   from the induction hypothesis, since every term that evaluates to
%   some neutral form semantically inhabits $[[B {a}]]$. Done.
% \end{proof}


% \begin{lemma}[Adequacy: $CR_2$ for type]
%   \label{lemma:cr2ty}
%   If $[[I]](j) \in CR$ for all $[[j < i]]$ and $[[Interp I i A S]]$, then $[[wn A]]$ holds.
% \end{lemma}
% \begin{proof}
%   By induction over the derivation of $[[Interp I i A S]]$. The
%   function case uses Lemma~\ref{lemma:crel} and Lemma~\ref{lemma:extwn}.
% \end{proof}

% \begin{lemma}[Adequacy: $CR_2$ for types (Rec)]
%   \label{lemma:cr2tyrec}
%   If $[[InterpR i A S]]$, then $[[wn A]]$.
% \end{lemma}
% \begin{proof}
%   By strong induction over $[[i]]$ and Lemma~\ref{lemma:cr2ty}.
% \end{proof}

% \begin{lemma}[Adequacy: $CR$ for terms (Rec)]
%   \label{lemma:crelrec}
%   If $[[InterpR i A S]]$, then $[[S]] \in CR$.
% \end{lemma}
% \begin{proof}
%   After unfolding the definition of $[[InterpR i A S]]$, trivial by
%   Lemmas~\ref{lemma:cr1ty}, \ref{lemma:crel} and \ref{lemma:cr2tyrec}.
% \end{proof}

The formulation of the valuation and semantic well-typedness from
Section~\ref{sec:logrelproof} and the fundamental lemma remains
unchanged.
The proof of the fundamental lemma\footnote{\dotv{soundnessopen.v}{soundness}} is still carried out by induction
over the typing derivation, where the additional neutral term related
cases are handled by Lemma~\ref{lemma:adequacy}, the adequacy property.

The normalization property then follows as a corollary of the
fundamental theorem.
\begin{corollary}[Existence of $\beta$-normal form\footnote{\dotv{soundnessopen.v}{mltt\_normalizing}}]
  \label{corollary:exbetanf}
  If $[[G |- a : A]]$, then $[[wn a]]$ and $[[wn A]]$.
\end{corollary}
\begin{proof}
  By the fundamental lemma, we know that $[[G |= a : A]]$. That is,
  for all $[[rho |= G]]$, there exists some $[[i]]$ and $[[S]]$ such
  that $[[InterpR i A {rho} S]]$ and $[[a {rho} in S]]$.
  We pick the valuation $[[rho]] = [[idtm]]$ (defined in Figure~\ref{fig:auxdef}), which injects
  natural numbers as term variables. The side condition $[[idtm |=
  G]]$ is satisfied since Lemma~\ref{lemma:adequacy} says neutral terms,
  including variables, semantically inhabit any $[[S0]]$ where
  $[[S0]]$ is the interpretation of some type. With our choice of
  $[[rho]]$, we have $[[A {rho}]] = [[A {idtm}]] = [[A]]$ and $[[a {rho}]] = [[a{idtm}]] = [[a]]$. Then we
  know that $[[InterpR i A S]]$ and $[[a in S]]$ for some $[[i]]$ and
  $[[S]]$. By Lemma~\ref{lemma:adequacy}, we
  conclude that $[[wn a]]$ and $[[wn A]]$ respectively.
\end{proof}

\yl{commented out the following paragraph because I accidentally wrote
the same thing twice. Will do a comparison and if this is better
written I'll replace the part from the $\beta\eta$ section with it}
% Due to the non-deterministic nature of parallel reduction, we need to take a
% few more steps to convert the existence of $\beta$-normal form into a decision
% procedure for type conversion. More specifically, we can show that a
% deterministic evaluation strategy such as leftmost-outermost reduction can
% always find the $\beta$-normal form if there exists one. Then the termination
% of that strategy immediately follows from Corollary~\ref{corollary:exbetanf}
% However, we omit such proofs since they can can be formulated on untyped
% lambda terms and thus are orthogonal to the specifics of dependently typed
% systems. Instead, we redirect readers to \citet{factorization-essentially,
%   takahashi-parallel-reduction} for the details.

The extension of our logical relation to prove normalization of open
\emph{and} closed terms closely mirrors the progression from
normalization of closed terms~\citep{harpertait} to normalization of
open terms~\citep{harperkripke} in the simply typed lambda calculus.
Indeed, a mechanization of the latter proof appears in ~\citet{abel2019poplmark}.
In this setting, as above, adequacy must be proven before the
fundamental theorem so we can handle elimination rules such as
\rref{T-If} and \rref{T-App} where the scrutinee is a neutral term. % In
% \citet{abel2019poplmark}, a variant of Lemma~\ref{lemma:extwn} is used
% in the exact same way to show the normalization of lambda forms
%
Dependent types make the adequacy proof slightly more complicated because we
also need to know that every \emph{type} has a normal form, not just
terms. This complicates our proof specifically in the \rref{I-Set} case for
our adequacy property (Lemma~\ref{lemma:adequacy}).

Overall, despite the dependently typed setting, it is in fact reassuring that
once we have laid the foundational technique for handling dependent types in
our logical relation, the extension to open terms mostly boil down to
properties that can be independently derived from the logical relation through
syntactic means.

\section{Existence of $\beta\eta$-normal forms}
\label{sec:betaeta}
We can easily incorporate the function $\eta$ law to the equational
theory of \lang{} by adding the following parallel reduction rule.
\begin{center}
  \drule[width=2.5in]{P-AbsEta}
\end{center}
% \Rref{P-AbsEta} effectively adds the $\eta$ law for functions to our
% equational theory since convertibility ($[[a <=> b]]$), the untyped relation
% used for type conversion, is built on top of parallel reduction.
We can recover the same confluence result about parallel reduction
using the standard techniques from
\citet{barendregt:lambda-calculi-with-types,
takahashi-parallel-reduction}, though anti-renaming
(Lemma~\ref{lemma:parantirenaming}) needs to be proven before the
diamond property (Lemma~\ref{lemma:pardiamond}). Another complication
is that confluence and anti-renaming now requires induction on a size
metric of lambda terms so the $\eta$ case has a useful induction hypothesis.

Note that the specification of our logical relation does not require
any changes. We can continue using $\ottkw{ne}$ and $\ottkw{nf}$ to
represent $\beta$-neutral and normal forms. By reproving the
fundamental lemma, we learn that every well-typed term as a
$\beta$-normal form. Lemma~\ref{lemma:parnenf} still holds with our
extended parallel reduction. In the presence of the $\eta$ reduction
rule, Lemma~\ref{lemma:parnenf} tells us that $\eta$ reduction
preserves $\beta$-normal forms (i.e. does not produce new
$\beta$-redexes). Furthermore, since the $\eta$ reduction rule for
functions strictly decreases the size of the term, the existence of
$\beta\eta$ normal form trivially follows.
\begin{corollary}[Existence of $\beta\eta$-normal form]
\label{corollary:exbetaeta}
If $[[G |- a : A]]$, then $[[a]]$ has $\beta\eta$-normal form.
\end{corollary}

In \citet{nbeincoq,decagda,martin-lof-a-la-coq}, a relational model is
needed to justify the $\eta$-law for functions. Instead, we prove
confluence for our parallel reduction extended with $\eta$-law for functions
and continue using a logical predicate (i.e. a unary logical relation) to justify
$\eta$-law as part of our equational theory.
A well-known issue with our approach is the failure of syntactic
confluence when the lambda term contains type annotations. A simple
counterexample is $[[\- B ((\- A a) {up 1} var 0)]]$; depending on
whether \rref{P-AbsEta} is performed on the whole term or
\rref{P-AppAbs} is used on the inner $\beta$ redex, we end up with the
terms $[[\- B a]]$ or $[[\- A a]]$, where $[[A]]$ and $[[B]]$ are not
necessarily syntactically equal terms. \citet{choudhury:ddc} resolve
this problem by stating their confluence result in terms of an
equivalence relation that quotients out parts of the terms that are
computationally irrelevant; the annotations of lambda terms are
ignored since the behavior of a lambda term is not affected by its
type annotation. We believe the same approach is applicable to our
proof if we add type annotations to our lambda terms.

The bigger issue is extensions such as $\eta$-laws for unit and
products. Surjective pairing, for example, is an equational law that
is known to cause trouble since it is not confluent for untyped lambda
terms~\citet{KLOP198997}. The relational, type-annotated, and Kripke-style models from
\citet{nbeincoq,decagda,martin-lof-a-la-coq} can be more easily
extended to support these rules.
We note, however, that the issue with $\eta$ rules is not exclusive to dependently
typed languages and has been studied in more limited languages that
are either simply
typed~\citep{pierce2004advanced,pfenning1997computation} or
dependently typed but without large
elimination~\citep{harper2005equivalence,
abel2005untypedconvsurjective}. Common workarounds include
type-directed conversion and shifting the focus to obtaining
$\eta$-long forms~\citet{Abel12}.
We believe our simple proof will help readers
see how techniques from these simpler settings generalize to fully
dependently typed languages and better understand the more complex
mechanized developments.

Finally, due to some technical
details, our mechanized proof about the existence of $\beta\eta$ form does not
immediately induce a decision procedure for type conversion in
\lang{}. We discuss this issue and its workaround in
Section~\ref{sec:conversionalgo}.
\section{Mechanization}
\label{sec:logrelmech}
\begin{figure}[h]
  \begin{minipage}{0.9\textwidth}
  \begin{tabular}{ l |  c  | c | c }
    & Consistency & Normalization & Syntactic metatheory \\
    \hline
    % Library (Autosubst 2)  & 491 & - \\
    Syntactic typing (specification) &  68 & - & - \\
    Renaming & 46 & -  & - \\
    Untyped reduction & 349 & - & - \\
    Neutral and normal forms & N/A & 269 & N/A \\
    Logical relation & 331 & 426 & N/A \\
    Semantic typing and soundness & 169 & 199 & N/A \\
    Syntactic soundness & N/A & N/A  & 660 \\
    \hline
    Total & 963 & 1357 & 1123 \\
  \end{tabular}
  \end{minipage}
  \caption{Statistics of the Coq Development}
  \label{fig:linecount}
\end{figure}

Figure~\ref{fig:linecount} shows the number of non-blank, non-comment lines of
code\footnote{calculated by the \texttt{cloc} tool} for each file of our
development, including the base consistency proof from
Section~\ref{sec:logreldep} and \ref{sec:logrelproof} and the extension to
normalization for open and closed terms from Section~\ref{sec:extension}.

Because the normalization and the consistency development share the same
syntactic and typing specification, they differ in only the categories
that are relevant to the logical relation. We use - as a marker that
the line count is the same.

Autosubst 2 takes our syntax specification in higher-order abstract
syntax and generates Coq syntax specification, renaming and
substitution functions, and lemmas and tactics that allow reasoning
about those functions. The auto-generated syntax file by Autosubst 2
and library header files are omitted from the figure.

Orthogonal to the development of our consistency and normalization
proof, we have also proven the syntactic soundness of our system through subject
reduction and progress. The syntactic soundness proof shares the
definition of renaming with our semantic soundness proof, which is
factored out as a separate file under the Renaming (common) category.
\scw{Should add this line count as another column, for comparison. I've done so,
but may need to update the numbers. }

\subsection{Artifacts Specific to Coq}
In this section, we discuss the Coq encoding of the definitions and proofs presented
in Section~\ref{sec:logrelproof} and the artifacts of this encoding that are
specific to Coq.

% The inductive
% definition of the logical relation in Figure~\ref{fig:logrel} requires
% the impredicativity of Coq's \texttt{Prop} sort since\scw{or ``so that''?} in \rref{I-Pi},
% the function $[[F]]$ can be later instantiated into the logical
% relation itself (e.g. in the proof of Lemma~\ref{lemma:piintroalt}).

In our proof presented in Section~\ref{sec:logreldep}, the relation
$[[R]]$ in \rref{I-Pi} requires Coq's impredicative \texttt{Prop} sort
since $[[R]]$ can later be instantiated into something defined in
terms of the logical relation itself (e.g. in
Lemma~\ref{lemma:piintroalt}). \scw{I'm having trouble connecting the rule in
the figure with rule \texttt{InterpExtFun} in the coq development. Would it make
sense to include the definition of ProdSpace? What is the Coq type of R?}
\yl{I think I might just inline the definition of ProdSpace and then
  rename the variables from the Coq code to match the ones from the paper}

In the Coq mechanized proof, the definition of $[[Interp I i A S]]$ has type
\texttt{Prop}, when \texttt{I} has type \texttt{nat -> tm -> Prop} and \texttt{S}
has type \texttt {tm -> Prop}.  However, if desired, we could consistently
replace the use of \texttt{Prop} with Coq's predicative sort
\texttt{Type}. This variation of the definition could be used to define the
interpretation for any \emph{finite} number of universes. The use of
\texttt{Type} becomes troublesome only when we attempt to define
$[[InterpR i A S]]$, the top-level logical relation defined in
Figure~\ref{fig:logrelrec} that recursively calls itself at smaller universe
levels. Therefore, the one feature of \lang{} that truly requires impredicativity
is its countable universe hierarchy. \scw{I'm not sure the last part of this sentence
adds much: ``Although, lemmas such as the
admissibility of \rref{I-PiAlt} (Lemma~\ref{lemma:piintroalt}) not only simply
our mechanization, but also give better intuition on what our logical relation
means.'' Yes, we need impredicativity to define these lemmas, but without impredicativity
our logical relation means something else.}

The definition of $[[Interp I i A S]]$ has an almost one-to-one
correspondence to the Coq definition. The main difference is the
specification of $[[I]]$. In
Section~\ref{sec:logreldep}, we define $[[I]]$ as a function over
numbers less than $[[i]]$, the universe level. In Coq, we only require
$[[I]]$ to be function with the set of natural numbers as its domain.
In the Coq encoding of $[[InterpR i A S]]$ (Figure~\ref{fig:logrelrec}), we define $[[I]]$ as follows.
\begin{equation*}
  \begin{split}
    [[I]]   &\in [[SNat -> PowerSet STm]] \\
    [[I j]] &=
     \begin{cases}
      \ [[{A | exists S , InterpR j A S}]] & \text{when } j < i \\
      \ [[emptyset]] & \text{otherwise}
    \end{cases}
  \end{split}
\end{equation*}
Since $[[I]]$ is only applied to numbers strictly less than $[[i]]$ in
\rref{I-Set}, we can retroactively show that the set we return in the $j
\geq i$ case is junk data that does not affect the result of the logical
relation. This property allows us to recover the simple equation for $[[InterpR i A S]]$ shown in Figure~\ref{fig:logrelrec}.

Finally, in set theory, to show that two sets $[[S0]]$ and $[[S1]]$
are equal, it suffices to show the extensional property that $\forall
x, x \in [[S0]] \iff x \in [[S1]]$. We leverage this fact
occasionally in our presented proofs.
In Coq, sets of terms ($[[PowerSet STm]]$) is encoded as the type \texttt{tm ->
Prop}, a predicate over \lang{} terms.
In axiom-free Coq, predicates do not come with the extensionality
property. Given two predicates $P$ and $Q$, we can not conclude that
$P = Q$ when given a proof of $\forall
x, P(x) \iff Q(x)$. While
predicate extensionality is not necessary in our development, we
assume it as an axiom since it is known to be consistent with Coq's
metatheory and helps bridge the gap between our mechanization and the
proofs we present.


% In Coq, there is a distinction between computable functions and
% relations that can later be proven to be functional. The former can be
% viewed as a strict subset of the latter in axiom-free Coq. To be more
% precise, given a relation \texttt{R : A -> B -> Prop} subject to the
% totality and functionality constraints ($\forall$ \texttt{a} $\in$
% \texttt{A}, there exists a unique \texttt{b} $\in$ \texttt{B} such
% that \texttt{R a b} is inhabited), we do not immediately obtain a function
% \texttt{F : A -> B} such that $\forall$ \texttt{a} $\in$ \texttt{A},
% \texttt{R a (F a)} is inhabited. However, the functional side
% conditions of a relation is clunky to express and tend to block
% automation. A simple workaround is to assume the axiom of unique choice, which
% is known to be consistent with Coq and allows us to induce a function \texttt{F
% : A -> B} once we have shown the relation \texttt{R : A -> B -> Prop}
% is functional. This approach would make our Coq development match
% the text version of our proof from Section~\ref{sec:logrelproof} more
% closely.

% However, we choose instead an axiom-free workaround and define
% \rref{I-Pi} as follows in our Coq mechanization.
% \begin{center}
%   \drule[]{I-PiCoq}
% \end{center}
% It should be easy to verify that the preconditions of
% \rref{I-Pi}, \rref{I-PiAlt}, and \rref{I-PiCoq} are all
% equivalent. After establishing Lemma~\ref{lemma:logreldeter}, it is
% possible to further show that the conclusions of the rules are
% equivalent, too.\scw{If it is easy, you should have already done it.
% Unless it is really long and boring.}

% This formulation allows us to derive Lemma~\ref{lemma:piintroalt}
% before we even show that our logical relation is
% functional/deterministic, but does not affect the proof structure
% otherwise.
% We choose to keep this discrepancy between the Coq development and the
% description of the logical relation presented in Section~\ref{sec:logreldep} since the
% skolemization process is more intuitively expressed in terms of
% function symbols rather than relation symbols. Otherwise, we do not
% see a clear advantage of \rref{I-PiCoq} over \rref{I-Pi} in set
% theory, where there is no distinction between computable functions and
% functions in general. \scw{not sure I follow this last bit}

\subsection{Automation}
\label{sec:automation}
Our Coq mechanization heavily uses automation, though instead of
defining custom tactics, we rely mostly on off-the-shelf tools such as
Autosubst 2~\citep{autosubst2} and CoqHammer~\citep{czajka2018hammer}.

We use the Autosubst 2 framework to specify our syntax in HOAS and
produce Coq syntax files in de Bruijn representation. Additionally,
Autosubst 2 provides a powerful tactic \texttt{asimpl} that
can be used to prove the equivalence of two terms constructed using
the primitive operators provided by the framework. This greatly
simplifies the reasoning about substitution in our development as
almost all substitution related properties about the syntax are
immediately discharged by \texttt{asimpl}.

For other automation tasks that are not specific to binding, we use
the powerful \texttt{sauto} tactic provided by CoqHammer to write
short and declarative proofs. For example, here is a one-line proof of
the triangle property about parallel reduction, from which the diamond
property (Lemma~\ref{lemma:pardiamond}) follows as a corollary.
The triangle property states
that if $[[a => b]]$, then $[[b]]\Rightarrow [[a]]^*$, where $[[a]]^*$
is the Takahashi translation~\citep{takahashi-parallel-reduction}
which roughly corresponds to simultaneous reduction of the redexes in
$[[a]]$, excluding the new redexes that appear as a result of
reduction.
\begin{minted}{coq}
Lemma par_triangle a : forall b, (a â‡’ b) -> (b â‡’ tstar a).
Proof.
  apply tstar_ind; hauto lq:on inv:Par use:Par_refl,par_cong ctrs:Par.
Qed.
\end{minted}
In prose, the triangle property can be proven by induction over the graph of
\mintinline{coq}{tstar a}, the Takahashi translation. Options \texttt{inv:Par}
and \texttt{ctrs:Par} say that the proof involves inverting and constructing
of the derivations of parallel reduction. The option
\texttt{use:Par\_refl,par\_cong} allows the automation tactic to use the
reflexivity and congruence properties of parallel reduction as lemmas.

The flag \texttt{lq:on} tunes CoqHammer's search algorithm.  While this flag
appears arcane, when developing our proof scripts we never specify this option
manually. Instead, we first invoke the \texttt{best} tactic provided by
CoqHammer, specifying only the \texttt{inv}, \texttt{ctrs}, and lemmas that we
want to use. The \texttt{best} tactic then iterates through possible
configurations and provides us with a replacement with the tuned performance
flags that save time for future re-execution of the proof script.

The automation provided by CoqHammer not only gives us a proof that is shorter
and more resilient to changes, but also gives useful documentation for readers
who wish to understand the mechanized proof. Although automation performs
extensive search, it does not use lemmas or invert derivations that are not
specified in the \texttt{use} or \texttt{inv} flag.

\subsection{Extraction of a conversion algorithm}
\label{sec:conversionalgo}
A constructive proof of the existence of $\beta\eta$-normal form
for well-typed terms (Corollary~\ref{corollary:exbetaeta}) induces a
normalization algorithm. From this normalization procedure, we can
derive a normalize-and-compare algorithm. Given two well-typed terms
$[[a]]$ and $[[b]]$, to know whether $[[a <=> b]]$, we apply the
normalization algorithm on $[[a]]$ and $[[b]]$ to obtain $\beta\eta$
normal forms $[[f0]]$ and $[[f1]]$. The algorithm then returns true
exactly when $[[f0]]$ and $[[f1]]$ are syntactically equal. This
algorithm is referred to as normalize-and-compare by
\citet{pierce2004advanced}.

The soundness of the algorithm is immediate. The completeness of the
algorithm is justified the confluence property of the untyped
reduction relation. Suppose $[[a <=> b]]$, $[[a =>+ f0]]$, $[[b =>+
f1]]$ but $[[f0]]$ is syntactically distinct from $[[f1]]$. By the transitivity of convertibility, we have $[[f0 <=> f1]]$.
Because $[[f0]]$ and $[[f1]]$ are both in
$\beta\eta$-normal forms and can only reduce to themselves, we must
have $[[f0 = f1]]$. Contradiction.

In our development, since our countable universe hierarchy
relies on impredicativity from the metatheory, we encode our
properties in Coq's \texttt{Prop} sort, which is not very suitable for
code execution. On the other hand, due to our heavy reliance on
automated proof search, even if we were able to extract an algorithm from \texttt{Prop},
the algorithm would be unpredictable because its definition depends on
the specific choices made by the proof search algorithm.

However, with a little more effort, it is possible to recover a
precise algorithm. The first step is to define a deterministic
small-step reduction relation that is normalizing; that is, the
relation can always find a normal form if there exists one. A good
candidate is the leftmost-outermost reduction strategy. Its
normalizing property is standard and can be proven using the
factorization technique discussed in
\citet{takahashi-parallel-reduction, factorization-essentially}. By
composing the existence of normal form and the fact that the
deterministic relation is normalizing, we can derive the
accessibility of the deterministic reduction relation
(\mintinline{coq}{Acc} in Coq), and use the accessibility proof as
an induction metric to define an executable algorithm\footnote{Coq's
  singleton elimination principle allows \mintinline{coq}{Acc}, a
  \texttt{Prop} data type with a single constructor, to be eliminated
  to construct runtime relevant data}.

\section{Related Work}
\label{sec:relatedwork}

\def\rot{\rotatebox}
\newcommand\header[1]{\rotatebox{90}{{#1}}}

\begin{figure}[h]

% \begin{minipage}{0.8\textwidth}
  \begin{tabular}{ l |  l  | l | l | l }
      & \header{Universes} & \header{Inductives} & \header{Conversion}
      & \header{Large Elim} \\
    \hline
    \lang{} & $\mathbb{N}$ & Id, Bool & U & {\boxedsymbols âœ“} \\
    % \hline
    $\lambda^\theta$ & 0 & Id, Nat & U & {\boxedsymbols âœ—}\\
    NBE-in-Coq & 1 & Nat & T & {\boxedsymbols âœ—} \\
    % \hline
    $\lambda^{\Pi U\mathbb{N}}$ & 1 & Nat & T & {\boxedsymbols âœ“} \\
    % \hline
    MLTT-a-la-Coq & 1 & Id, Nat & T & {\boxedsymbols âœ“} \\
    % \hline
    Core Nuprl & $\mathbb{N}$ & W-Types & E & {\boxedsymbols âœ“} \\
    \hline
    CIC & $\mathbb{I}$,$\mathbb{N}$ & General & U & {\boxedsymbols âœ“}\\
    CoreSpec & \\
    PCUIC & \\
    %   & \lang{} & \citet{anand2014towards} &
    %                                          \citet{barras2012semantical}
    % & \citet{martin-lof-a-la-coq}  \\
    % \hline
    % Universe & Countable & Countable & Impredicative + Countable & One\\
    % % \hline
    % % Large Elimination & {\boxedsymbols âœ“} & {\boxedsymbols âœ“} & {\boxedsymbols âœ“} \\
    % \hline
    % Inductive Types & Id, Bool & W types & General inductive types & Nat \\
    % \hline
    % Convertibility & Untyped & Untyped,Extensional & Untyped & Typed \\
  \end{tabular}
% \end{minipage}

  \begin{tabular}{ll}
  \\
    $\lambda^\theta$  & \citet{casinghino:combining-proofs-programs} (logical fragment only) \\
    NBE-in-Coq& \citet{nbeincoq} \\
    $\lambda^{\Pi U\mathbb{N}}$ &\citet{decagda} \\
    MLTT-a-la-Coq &\citet{martin-lof-a-la-coq} \\
    Core Nuprl &\citet{anand2014towards} \\
    CIC &\citet{barras2012semantical} \\
    CoreSpec & \\
    PCUIC & \\

  \\
  Universes: &Countable ($\mathbb{N}$), Zero (0), One (1), Impredicative ($\mathbb{I}$) \\
  Conversion:& Typed (T), Untyped (U), Extensional (E) \\
  \end{tabular}

  \caption{Feature matrix for dependently typed languages with
    mechanized proofs by logical relation}
  \label{fig:featurematrix}
\end{figure}

% \scw{Maybe it would be useful to include a chart here, so that readers can
%   easily keep track of the features of the various languages.  i.e. which ones
%   include large eliminations? type-directed equivalence? impredicative prop?
%   inductive datatypes? what are their line counts?}
% \yl{resolved}

\subsection{Logical relations}
Proof by logical relations does not come with a precise definition. In
the most general sense, a logical relation can be viewed as a
practical technique that uses a type-indexed relation to assign
meanings to types and strengthen the induction hypothesis for the
property of interest. The original idea of this technique can be
traced back to
\citet{tait1967:reducibility}. \citet{tait1967:reducibility} maps
types to sets of terms satisfying certain properties related to reduction.
The same idea is explained in \citet{girard1989proofs} and extended to
prove the strong normalization property of System F.

Tait's method has been successfully applied to dependently typed
languages.  \citet{Martin-Lof-1973}, \citet{luo1990extended},
\citet{geuvers1994short}, and
\citet{barendregt:lambda-calculi-with-types} are some of the earlier
works that prove strong
normalization for different dependently type systems using Tait's notion of
reducibility.

\scw{Should give Martin L\"of credit for first consistency proof.}
% \scw{What techniques do these three proofs use? How is it different from
% your proof? What about Luo, which
% introduced a universe hierarchy? What about categories with families, or
% other ways of showing consistency?}
% \yl{resolved}

% Some of these proofs are still reapplied in more recent works. For
% example, the technique for proving strong normalization by
% \citet{geuvers1994short} is adapted by \citet{moon2021graded} to show
% the normalization property for a dependently typed system extended with
% modalities.

The pen and paper representation of the logical relation proofs
can be challenging to adapt to a theorem prover since a lot of details
are hidden behind the concise notations.
As an example, \citet{geuvers1994short} presents the interpretation for types as
an inductively defined total function over the set of syntactically
well-formed types. Despite the notation for the logical relation as a
simply typed function that takes a type and returns some set, the
interpretation function in reality is a dependent function whose
return type depends on the derivation of the well-typedness of its
input. The well-typedness derivation and the proof of the
classification theorem are needed relevantly in the body
of the interpretation function to decide whether an argument of an
application should be erased during interpretation. Due to the
impredicativity of the object language, \citet{geuvers1994short}'s
proof cannot be encoded in Agda, which has a predicative
metatheory. Due to the use of proof-relevant derivations, even in
Coq, a proof assistant that supports impredicativity, one would need
to constantly juggle between the impredicative but irrelevant sort
\texttt{Prop} sort and the predicative but relevant sort
\texttt{Type}.

More recent works such as \citet{Abel12}
and\citet{abel2008betaeta} make their definitions more explicit and
precise and thus easier to encode in proof assistants. Our definition
of logical relation is reminiscent of their definition of a
semantic universe hierarchy, though our logical relation is defined to
be closed under expansion with respect to parallel reduction rather
than weak head reduction. Furthermore, \citet{Abel12} and
\citet{abel2008betaeta} use the semantic universe hierarchy as a
measure to define Kripke-style logical relations, from which they
derive the correctness of their conversion algorithms. In our work, we
use the semantic universe hierarchy directly in our definition of
semantic typing because it is sufficient
for deriving consistency and later normalization.

\subsection{Mechanized logical relations about dependent types}
In Figure~\ref{fig:featurematrix}, we give an overview of features of
the object languages from mechanized logical relations about dependent
types. The table is far from exhaustive. For example,
\citet{casinghino:combining-proofs-programs} and
\citet{anand2014towards} both have support for partial
programs. However, we include features that we believe to be most
impactful to the definition of the logical relation.

\citet{casinghino:combining-proofs-programs} introduce $\lambda^\theta$, a dependently typed
programming language that uses modality to distinguish between logical
proofs and programs. % The programmatic fragment
% includes recursive data types and supports general recursion at the
% cost of introducing divergence.
% However, the $\lambda^\theta$
% language is limited in its expressiveness since it does not support
% type-level computation or polymorphism and therefore is not a fully dependently
% typed language according to \citet{abel2013normalization}.
The consistency proof of $\lambda^\theta$'s logical fragment has been
mechanized in Coq through a step-indexed logical relation;
step-indexing is required to model the programmatic fragment, which
interacts with the logical fragment.
The lack of polymorphism and type-level computation means their
logical relation can be defined recursively for well-formed types using
a size metric, which has been explored in~\citet{liu2023dependently}.

\citet{decagda} mechanizes in Agda the decidability of type
conversion rule for a dependently typed language with one predicative
universe level and typed judgmental equality with function
$\eta$-law. They
use a Kripke-style logical relation parameterized over a
type-directed equivalence relation satisfying certain
properties to facilitate the reuse of their definition. The
logical relation is defined using the induction-recursion scheme,
which is available in Agda but not in Coq.
\citet{martin-lof-a-la-coq} manages to encode the logical relation
from \citet{decagda} in the predicative fragment of Coq and further
extends the decidability of type conversion result
from~\citet{decagda} to the decidability type checking of a
bidirectional type system.

\citet{anand2014towards} mechanizes the metatheory of
Nuprl~\citep{constable1986implementing} in Coq. The metatheory is an
extensional type theory with features such as dependent functions,
inductive types, and a full universe hierarchy. \citet{nbeincoq}
mechanizes the normalization-by-evaluation algorithm in Coq for a
dependently typed language with one predicative universe, similar to
\citet{decagda} and \citet{martin-lof-a-la-coq}. However, since their
type system has no elimination form for natural numbers, the
only base type from the object language, large elimination is not
supported despite the one predicative universe.
Both \citet{anand2014towards} and \citet{nbeincoq} leverage the
impredicative \texttt{Prop} sort of Coq to define the interpretation
of dependent function types and thus are closely related to our
mechanization. \citet{anand2014towards} further shows it is possible
to encode a finite universe hierarchy without the use of
either impredicativity or induction-recursion.
% \yl{commented out because I think this paragraph is too subjective}
% However, instead of explaining the inductive
% logical relation as a convoluted workaround to the lack of
% induction-recursion in Coq, we give a self-contained explanation of
% our logical relation.

\subsection{Other mechanized metatheory of dependent types}


Finally, \citet{barras2010sets, Wang2013SemanticsOI} assign
set-theoretic semantics to dependent type theory in Coq. Unlike the
previous mechanization efforts, which primarily focus on predicative
type theory and more direct reducibility models,
\citet{barras2010sets, Wang2013SemanticsOI} tackle extensions of
$CC^\omega$, a system that incorporates a predicative universe on top
of the impredicative sort in Calculus of Constructions. We choose to
focus on a simple term model so we do not have to take the extra step
of mechanizing mathematical objects such as sets and domains.

There are other mechanized developments for dependently typed systems
that only involve properties that are derivable through syntactic
means. For example, \citet{coqcoqcorrect2019} proves the correctness
of a type checker for the Polymorphic, Cumulative Calculus of
Inductive Constructions (PCUIC), Coq's core calculus, assuming the
strong normalization property of the object
language. \citet{weirich:systemd} define System D, a core calculus of
dependent Haskell, and prove the syntactic type soundness of the type
system. Compared to properties such as consistency, normalization, and
parametricity, syntactic type soundness is less intimidating for
dependent types since one is most unlikely to run into issues related
to the strength of the metatheory.

\section{Discussion}
\label{sec:discuss}
\yl{I'm not sure how strong of a statement we can make about our proof
  technique. We've already demonstrated how to address type-level dependency
  when defining a logical relation through a simple example. Claiming that our
  proof structure is better seems quite ambitious, but I think there's a
  middle point where we claim that adding moderate features like typed
  reduction doesn't instantly make our code size expand all the way from 1000
  to 20,000 without saying the other developments are just verbose for no good
  reason}
\scw{I think we can find reasons for much of the differences. Am I missing any?
While it would be difficult to assign numbers to each of the deltas, I think it
is believable that when put together they add up to a lot.
\begin{itemize}
\item We don't include inductive or coinductive datatypes. We don't include
cumulativity. We don't include Prop. We don't include universe polymorphism.
\item We state our equality algorithmically instead of declaratively. On one
  hand, this gives us automatic inversion principles when working with
  definition. Furthermore, we don't need to prove the equivalence between an
  algorithmic version and a declarative specification.
\item Our equality requires a simple decision algorithm and isn't type directed.
\item We don't prove decidability of type checking. (And, it is not provable
  for our system, because we lack type annotations on functions. We should
  point this out.)
\item Our logical relation is unary and untyped. The latter means that we don't
  require the bookkeeping of a Kripke logical relation when reasoning about
  open terms. I don't know why unary relations are shorter.
\item CoqHammer leads to short proofs.
\end{itemize}
}
\yl{ Just one more technical point to add, though it's in the text already:
  the logical relation is closed backward by full reduction rather
  than weak-head/deterministic reduction. This requires an early
  confluence result to show that the logrel is
  deterministic/functional but simplifies everything else
  (e.g. conversion is justified immediately by our preservation
  theorem, but that is not the case if you use weak head reduction).\\ \\
  Also, regarding the first point, cumulativity only exists in
  Barras's work. Inductive, (maybe coinductive?), can be found in
  nuprl, metacoq, and maybe Barras's work.\\ \\
  The 20,000 - 30,000 LoC mechanization are all about small languages
  with pretty much the same features as our language except for your
  second and third bullet point. martin-lof a la coq, Abel's work, and
  nbe in coq aren't that richer in feature otherwise. None includes
  cumulativity (they only have one predicative universe)\\ \\
  The 400,000 NuPRL in Coq probably falls into a different category
  because they are trying to mechanize a full practical language}
\scw{The Coq-Coq-Correct paper (extended version) includes a (predicative) universe hierarchy, universe polymorphism, inductive/coinductive types. But they don't show consistency. Their development is 300k LOC.}

The short consistency proof we present achieves the goal of
demonstrating the technique of proof by logical relation for dependently typed
languages. However, what remains unanswered is what makes our development
significantly shorter compared to others. Are we proving simpler results, for
smaller languages, are we making more use of automation, or is our proof
technique genuinely more efficient?
% focus on the following question: why is our proof,
% even with its extension to the existence $\beta\eta$-normal form, so much
% shorter than the other mechanized results from \citet{decagda,
% nbeincoq, martin-lof-a-la-coq}?


% First, the metatheoretic properties that we prove are indeed simpler.  Unlike
% developments that mechanize the correctness of a type-directed conversion
% algorithm, we only show the existence of normal forms for open and closed
% terms and state our properties in terms of an untyped reduction relation. This
% avoids a lot of the scaffolding related to the specification of the algorithm
% and the proof obligations that the algorithm is sound and complete with
% respect to the declarative specification of the type system.
% As a result, our logical relation, unlike the ones from \citet{decagda,
%   nbeincoq, martin-lof-a-la-coq, anand2014towards}, maps from types to
% predicates rather than relations. \scw{How does this follow? Why do we need unary relations where they need binary relations?} The need for a relational model is
% directly related to the metatheoretic property one wants to
% prove. \citet{anand2014towards} requires a relational model to capture
% the extensionality of their type system, whereas \citet{decagda,
%   martin-lof-a-la-coq, nbeincoq} uses a relational model to derive the
% injectivity of $\Pi$ types and justify the validity of
% $\eta$-conversion among other properties.
% Since \lang{} uses an untyped conversion rule, type conversion can be
% done through the \emph{normalize-and-compare}
% strategy described in \citet{pierce2004advanced}. The decidability of
% normalize-and-compare is implied by the existence of
% $\beta\eta$-normal form, which follows from our logical
% predicate.

First, the metatheoretic properties that we prove are indeed
simpler. Compared to Core Nuprl\citet{anand2014towards}, our system
lacks extensionality, which would require a relational model to
justify consistency. Compared to the systems from
\citet{decagda,nbeincoq, martin-lof-a-la-coq}, the conversion rule for
\lang{} is untyped and therefore we do not
need a Kripke-style relational model to prove $\Pi$-injectivity
among other properties. Furthermore, we prove the existence of normal
forms, which induces a simple \emph{normalize-and-compare}
procedure for type
conversion~\citet{pierce2004advanced}. \citet{nbeincoq, decagda}, on
the other hand, need
to show how their algorithmic conversion procedure is sound and complete
with respect to their respective declarative equational theory.
\scw{I'm getting confused by this paragraph. Does this reorganization sense:
  Our language is simpler than Nuprl, because it doesn't have extensional
  equality. It is simpler than Agda, because it doesn't have type-directed
  equality. Both of these cases require the definition of a binary logical
  relation, that defines a notion of semantic equality between terms. This
  relation justifies the injectivity of $\Pi$ types and justify the validity
  of $\eta$-conversion among other properties.}  \scw{Furthermore our proof is
  also simpler because we don't need prove the correctness of the NBE
  algorithm, which is used to show the decidability of Agda's type-directed
  equivalence. Therefore, we don't need to define this algorithm and show that
  it is sound and complete with respect to the type-directed
  equality. Instead, to show the decidability of our untyped equivalence, we
  need only show that terms have $\beta\eta$ normal forms. }
\yl{Makes sense. Though Abel's work doesn't use nbe but a recursive
  binary algorithm. Rewrote the paragraph above and commented out the original}


Second, the definition of our logical relation does
contribute to a more concise proof.
In \rref{I-Red, I-Bool}, we choose parallel reduction, a full
reduction relation, to close over our semantic interpretation of types
and terms. Parallel reduction is non-deterministic, but it satisfies
useful structural properties such as congruence
(Lemma~\ref{lemma:parcong}) and the diamond property
(Lemma~\ref{lemma:pardiamond}). We pay the price of using a
non-deterministic reduction relation when we want to prove that our
logical relation is a partial function; because of \rref{I-Red}, we
can have $[[A => B0]]$ and $[[A => B1]]$, where $[[B0]]$ and $[[B1]]$
each have their separate interpretations that we have to prove to be
equal. Fortunately, this complexity is reconciled by the
diamond property, which is easy to derive syntactically.
\citet{decagda,nbeincoq} employ a deterministic weak
head reduction relation. The use of a deterministic reduction relation
makes the functionality of a logical relation trivial to prove, but
the downside is that weak head reduction (denoted by $\leadsto^{wh}$)
or leftmost-outermost reduction (denoted by $\leadsto^{lo}$) does
not satisfy even the weaker substitution property
(Lemma~\ref{lemma:parsubst}). % That is, given a term $[[A]]$
% and $a \leadsto^{lo} b$, we do not necessarily have $[[A {a}]]
% \leadsto^{lo} [[A {b}]]$ since the variable might appear to the
% right of some redex.
With this alternative formulation, we would have to prove how the
deterministic reduction relates to a full non-deterministic reduction
relation to prove the fundamental theorem. This would amount
to proving the factorization theorem of the deterministic reduction
relation with respect to full non-deterministic reduction. Instead,
using parallel reduction in \rref{I-Red} allows us to delay the
factorization property until we need to extract a normalization
algorithm from our fundamental theorem (Section~\ref{sec:conversionalgo}).



% In terms of our proof technique, the choice of parallel reduction, a full reduction
% relation, to close over our semantic interpretation in \rref{I-Red,I-Bool} has a non-negligible effect on the
% size of our development.

% we close over our semantically valid types
% and terms in \rref{I-Red, I-Bool} using the non-deterministic parallel
% reduction relation, while \citet{decagda,nbeincoq} employ a deterministic weak
% head reduction relation. Our use of a non-deterministic reduction strategy
% means that we need confluence to prove the functionality of our logical
% relation. However, the benefit is that it immediately gives us a semantic
% justification of the conversion rule (Lemma~\ref{lemma:logrelcoherence}).
% In particular, we obtain the confluence
% result of reduction at a very early stage before we even define our
% logical relation.

With untyped conversion,
we sidestep the relational, Kripke-style logical relation found in
other mechanized proofs. \scw{Need to define Kripke-style. Also the other
proofs need Kripke style because they are defining typed relations, not untyped
relations. }
However, our early dependence on confluence
before the fundamental theorem is established can be alarming.
In a system with type-directed reduction,
confluence is not immediately available because it
depends on $\Pi$-injectivity, which is usually only proven after the
fundamental theorem.\scw{confluence depends on Pi injectivity? I thought
it was only needed for subject reduction}\yl{it's
transitive. Confluence depends on subject reduction, which in turn
depends on pi injectivity. Maybe it's worth spelling out the details}
Fortunately, there are syntactic workarounds for the $\Pi$-injectivity
problem that allow us to recover confluence property independently
from the logical relation. \citet{siles2012pure} generalize the
notion of Type Parallel One Step Reduction from \citet{adams2006pure}
to syntactically prove $\Pi$-injectivity for arbitrary Pure Type
Systems. \citet{weirich:systemd} add $\Pi$-injectivity to their
equational theory, thus allowing subject reduction to be proven
independently from confluence. By adopting these techniques that allow
us to derive confluence early even for systems with type-directed
reduction, we believe our proof technique can significantly shorten
the existing logical relation proofs for systems with typed
judgmental. We leave that as part of our future work.
% Therefore, we believe that even in a
% system where type-directed reduction is required (e.g. a system with
% the unit $\eta$-law) in the logical relation, the proof can still be carried
% out in a structure similar to the one we have presented.
% \scw{Not sure that I understand this paragraph}
% \yl{Reworded slightly to emphasize it's future work that we haven't
%   done and it is speculative}

\ifextended
Finally, despite our earlier claim that our metatheoretic properties
are not as strong as some of the related work, we can strengthen our
results through syntactic means. For example, the
normalize-and-compare strategy does not induce an efficient algorithm
for type conversion, like the ones from \citet{decagda} and
\citet{martin-lof-a-la-coq}. However, with the standard syntactic
techniques from \citet{takahashi-parallel-reduction,
factorization-essentially}, we can prove that leftmost-outermost
reduction is a normalizing reduction strategy, from which we can
separately show the correctness a more efficient algorithm that
reduces the two terms to weak head normal form before recursively
comparing their subcomponents. We believe factoring such properties
out of a logical relation is valuable, as it helps us identify the
part of our proof that requires extra strength from the metatheory.
\scw{Why don't we just use leftmost-outermost reduction in the first place?
Do we even need nondeterministic parallel reduction?}
\yl{The conversion uses full reduction. Nondeterministic reduction
  makes it harder to show that convertible types have the same
  meaning. Maybe it would require us to prove factorization in our
  development but it definitely simplifies the determinism proof
  (confluence is no longer required before the fundamental
  lemma). }
\fi

\section{Conclusion}
\label{sec:conclusion}
In this work, we show a short and mechanized proof of consistency
through proof by logical relation for a fully dependently typed
language with a full universe hierarchy, an intensional identity type,
and large elimination. We show the extensibility of our approach by
proving the existence of $\beta\eta$-normal forms with only small
and mechanical changes to our proof development. Our Coq mechanization
leverages existing Coq libraries for reasoning about metatheory and
general-purpose automation, allowing us to significantly reduce the
verbosity typically associated with mechanized proofs and recover a
declarative proof style that is usually only available in pen and
paper. Our development shows that proof by logical relation for
dependent types should be more accessible since it does not always
require months of effort to implement. We hope our proof can inspire
researchers to more actively mechanize results such as consistency,
normalization for dependent type theory.





% Type soundness can be proven through a syntactic
% approach~\citep{syntacticsoundness} as a corollary of two properties:
% progress and preservation. % The syntactic type soundness proof
% % varies in complexity depending on the underlying type
% % system. For example, a type system that tracks information flow would
% % require additional structural rules related to security levels. In
% % this paper, we focus on one specific type of complexity: the
% In Figure~\ref{fig:stlcsoundness}, we summarize the structure of the
% syntactic type soundness proof for the simply typed lambda
% calculus. Each lemma can be proven by structural induction over the
% typing derivation, while using the previous established results as
% lemmas for specific cases that do not immediately follow from the
% induction hypothesis. If we make our language more complex by adding
% full dependent type support, the overall structure remains almost
% identical.


% NbE in Coq

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{refs}

%%
%% If your work has an appendix, this is the place to put it.

\end{document}
\endinput
%%
%% End of file `sample-acmsmall.tex'.
